{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31c6e812",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "#dataset = api.load(\"text8\")\n",
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"    \n",
    "import tensorflow as tf\n",
    "from Vocabulary import *\n",
    "import time\n",
    "tf.keras.backend.clear_session()\n",
    "import csv\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "232f3a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSV_writer:\n",
    "    def __init__(self,name,mode):\n",
    "        self.csvfile = open('{name}.csv'.format(name=name), mode, newline='') \n",
    "        fieldnames = ['Optimizer', 'learning_rate','epoch','loss']\n",
    "        self.writer = csv.DictWriter(self.csvfile, fieldnames=fieldnames)\n",
    "        if(mode == \"w\"):\n",
    "            self.writer.writeheader()\n",
    "    \n",
    "    def write(self,opt,learning_rate,epoch,loss):\n",
    "        lr = \"{x:.6e}\".format(x=learning_rate)\n",
    "        loss = int(loss)\n",
    "        self.writer.writerow({'Optimizer': opt, 'learning_rate': lr,'epoch':epoch,'loss':loss})\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bee2c207",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(self,vocab,amount_split,vector_size = 300):\n",
    "        self.vector_size = vector_size\n",
    "        self.tf_bias = None\n",
    "        self.tf_context_bias = None\n",
    "        self.weights = None\n",
    "        self.tf_context_weights = None\n",
    "        self.tf_co_occurences = None\n",
    "        self.zeilen = 0\n",
    "        self.spalten = 0\n",
    "        self.amount_split = amount_split\n",
    "        self.block_length = math.ceil(vocab.get_size()/amount_split)\n",
    "\n",
    "    \n",
    "    def prepare(self,filename):\n",
    "        self.f = h5py.File(\"S:\\\\{filename}.hdf5\".format(filename=filename), \"w\")#plus experiment name\n",
    "        #initalize all the HDF files\n",
    "        self.HDF_weights = self.f.create_dataset(\"weights\", (vocab_size, self.vector_size))\n",
    "        self.HDF_context_weights = self.f.create_dataset(\"context-weights\",(self.vector_size,vocab_size))\n",
    "        self.HDF_bias = self.f.create_dataset(\"bias\", (vocab_size,1))\n",
    "        self.HDF_context_bias = self.f.create_dataset(\"context_bias\", (1,vocab_size))\n",
    "\n",
    "        self.hf = h5py.File(\"S:\\\\text8-filtered100-coocurences.hdf5\", \"r\")\n",
    "        self.HDF_coocurrence = self.hf.get('matrix')\n",
    "        self.init_matrices()\n",
    "        \n",
    "    \n",
    "    def init_matrices(self,chunk_size=10000):\n",
    "        random.seed(1)\n",
    "        np.random.seed(1)\n",
    "        tf.random.set_seed(1)\n",
    "        self.init_hdf_matrix(self.HDF_weights,-0.5,0.5,chunk_size)\n",
    "        self.init_hdf_matrix(self.HDF_context_weights,-0.5,0.5,chunk_size)\n",
    "        self.init_hdf_matrix(self.HDF_bias,-0.5,0.5,chunk_size)\n",
    "        self.init_hdf_matrix(self.HDF_context_bias,-0.5,0.5,chunk_size)\n",
    "    \n",
    "    def init_hdf_matrix(self,hdf_data,min_value,max_value,block_length):\n",
    "        if len(hdf_data) > len(hdf_data[0]):\n",
    "            iterations = int(math.ceil(len(hdf_data) / block_length))\n",
    "            for i in range(iterations):\n",
    "                current_size = min(block_length,len(hdf_data)-block_length*i)\n",
    "                hdf_data[i*block_length:(i+1)*block_length , :] = np.random.rand(current_size,len(hdf_data[0]))/self.vector_size\n",
    "        else:\n",
    "            iterations = int(math.ceil(len(hdf_data[0]) / block_length))\n",
    "            for i in range(iterations):\n",
    "                current_size = min(block_length,len(hdf_data[0])-block_length*i)\n",
    "                hdf_data[:,i*block_length:(i+1)*block_length] = np.random.rand(len(hdf_data),current_size)/self.vector_size\n",
    "            \n",
    "    \n",
    "    def load_blocks(self,zeilen,spalten):\n",
    "        co_ocurences = self.HDF_coocurrence[zeilen*self.block_length:(zeilen+1)*self.block_length,spalten*self.block_length:(spalten+1)*self.block_length]\n",
    "    \n",
    "        self.tf_co_occurences = tf.convert_to_tensor(co_ocurences,dtype=tf.dtypes.float32)\n",
    "        co_occurence = None\n",
    "        #Use normal matrix, if epsilon Shift, than add one to co-ocurence table to fix scaling and log\n",
    "        self.tf_bias = tf.Variable(initial_value=self.HDF_bias[zeilen*self.block_length:(zeilen+1)*self.block_length,:],dtype=tf.dtypes.float32)\n",
    "        self.tf_context_bias = tf.Variable(initial_value=self.HDF_context_bias[:,spalten*self.block_length:(spalten+1)*self.block_length],dtype=tf.dtypes.float32)\n",
    "        self.tf_weights =  tf.Variable(initial_value=self.HDF_weights[zeilen*self.block_length:(zeilen+1)*self.block_length,:],dtype=tf.dtypes.float32)\n",
    "        self.tf_context_weights = tf.Variable(initial_value=self.HDF_context_weights[:,spalten*self.block_length:(spalten+1)*self.block_length],dtype=tf.dtypes.float32)\n",
    "    \n",
    "    def save_blocks(self,zeilen,spalten):\n",
    "        self.HDF_bias[zeilen*self.block_length:(zeilen+1)*self.block_length,:] = self.tf_bias.numpy()\n",
    "        self.HDF_context_bias[0,spalten*self.block_length:(spalten+1)*self.block_length] = self.tf_context_bias.numpy()\n",
    "        self.HDF_weights[zeilen*self.block_length:(zeilen+1)*self.block_length,:] = self.tf_weights.numpy()\n",
    "        self.HDF_context_weights[:,spalten*self.block_length:(spalten+1)*self.block_length] = self.tf_context_weights.numpy()\n",
    "    \n",
    "    def _close_files(self):\n",
    "        self.f.close()\n",
    "        self.hf.close()\n",
    "    \n",
    "    def train_splitted(self,epochs,optimizer):\n",
    "        self.epsilon = tf.constant(1e-5) * tf.ones((self.block_length,self.block_length),dtype=tf.dtypes.float32)\n",
    "\n",
    "        lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        0.01,\n",
    "        decay_steps= self.amount_split*self.amount_split * 10,\n",
    "        decay_rate=0.5,\n",
    "        staircase=True)\n",
    "        \n",
    "        #print(optimizer._learning_rate)\n",
    "        print(optimizer.learning_rate)\n",
    "        \n",
    "        for epoch in range(0,epochs):\n",
    "            cur_loss = 0\n",
    "            for zeilen in range(0,self.amount_split):#CHANGE THIS BACK !!!!!!!!!!!!!!!!!!!\n",
    "                for spalten in range(0,self.amount_split):\n",
    "                    tic = time.perf_counter()\n",
    "                    #print(\"zeilen\"+str(zeilen)+\"spalten\"+str(spalten))\n",
    "                    self.zeilen = zeilen\n",
    "                    self.spalten = spalten\n",
    "                \n",
    "                    self.load_blocks(zeilen,spalten)\n",
    "\n",
    "                    train = optimizer.minimize(self.loss, var_list=[self.tf_bias,self.tf_context_bias,\n",
    "                                                              self.tf_weights,self.tf_context_weights])\n",
    "                    cur_loss += self.loss()\n",
    "        \n",
    "                    self.save_blocks(zeilen,spalten)\n",
    "            print(\"epoch\" + str(epoch)+\"loss:\"+str(cur_loss.numpy()))\n",
    "            csv_writer.write(optimizer.get_config()['name'],optimizer.learning_rate.numpy(),epoch+1,cur_loss.numpy())\n",
    "        self._close_files()\n",
    "        return None\n",
    "\n",
    "    def loss(self):\n",
    "        ones_symetrical = tf.ones((self.block_length,self.block_length), dtype=tf.dtypes.float32, name=None)\n",
    "    \n",
    "        co_occurences = None\n",
    "        #Append zero matrices if necessary\n",
    "        if(self.zeilen == self.amount_split - 1):\n",
    "            difference = self.block_length - self.tf_bias.shape[0]\n",
    "            add_to_bias   = tf.zeros((difference,1),dtype=tf.dtypes.float32)\n",
    "            add_to_co     = tf.zeros((difference,self.tf_context_bias.shape[1]),dtype=tf.dtypes.float32)\n",
    "            co_occurences = tf.concat([self.tf_co_occurences,add_to_co],axis=0)\n",
    "            add2_weights  = tf.zeros((difference,self.vector_size),dtype=tf.dtypes.float32)\n",
    "            weights       = tf.concat([self.tf_weights,add2_weights],axis = 0)\n",
    "            bias_matrix   = tf.concat([self.tf_bias,add_to_bias],axis = 0) * ones_symetrical\n",
    "        else:\n",
    "            bias_matrix   = self.tf_bias * ones_symetrical\n",
    "            weights       = self.tf_weights\n",
    "            co_occurences = self.tf_co_occurences\n",
    "    \n",
    "        if(self.spalten == self.amount_split - 1):\n",
    "            difference = self.block_length - self.tf_context_bias.shape[1]\n",
    "            add_to_con_bias = tf.zeros((1,difference),dtype=tf.dtypes.float32)\n",
    "            add_to_co       = tf.zeros((self.block_length,difference),dtype=tf.dtypes.float32)\n",
    "            if co_occurences == None:\n",
    "                co_occurences   = tf.concat([self.tf_co_occurences,add_to_co],axis=1)\n",
    "            else:\n",
    "                co_occurences   = tf.concat([co_occurences,add_to_co],axis=1)\n",
    "                add2_co_weights = tf.zeros((self.vector_size,difference),dtype=tf.dtypes.float32)\n",
    "                context_weights = tf.concat([self.tf_context_weights,add2_co_weights],axis = 1)\n",
    "                context_bias_matrix = tf.concat([self.tf_context_bias,add_to_con_bias],axis=1) * ones_symetrical\n",
    "        else:\n",
    "            if co_occurences == None:\n",
    "                co_occurences   = self.tf_co_occurences\n",
    "            context_weights     = self.tf_context_weights\n",
    "            context_bias_matrix = self.tf_context_bias * ones_symetrical\n",
    "          \n",
    "                                                          \n",
    "        bias_terms = context_bias_matrix + bias_matrix\n",
    "    \n",
    "        weight_matrix = tf.matmul(weights,context_weights)\n",
    "        log_X = tf.math.log(co_occurences + self.epsilon)\n",
    "        inner_sum = bias_terms + weight_matrix - log_X\n",
    "        squared_sum = tf.math.square(inner_sum)\n",
    "        weighted_sum = self.cut_function2(co_occurences) * squared_sum\n",
    "        reduced = tf.math.reduce_sum(weighted_sum)\n",
    "        return reduced\n",
    "    \n",
    "    alpha = tf.constant(0.75,dtype=tf.dtypes.float32)\n",
    "    XMAX = tf.constant(100.0,dtype=tf.dtypes.float32)  \n",
    "    def cut_function2(self,value):\n",
    "        clipped = tf.clip_by_value(value, clip_value_min = 0.0, clip_value_max=100.0)\n",
    "        return tf.pow(clipped / self.XMAX, self.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0009e852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED309A6880>\n",
      "{'name': 'Adam', 'learning_rate': 0.0001, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "epoch0loss:6659503.0\n",
      "epoch1loss:6658689.5\n",
      "epoch2loss:6657983.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F11D00>\n",
      "{'name': 'Adam', 'learning_rate': 0.0002, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0002>\n",
      "epoch0loss:6658409.0\n",
      "epoch1loss:6656741.0\n",
      "epoch2loss:6655272.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F11B20>\n",
      "{'name': 'Adam', 'learning_rate': 0.00030000000000000003, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0003>\n",
      "epoch0loss:6657293.0\n",
      "epoch1loss:6654728.5\n",
      "epoch2loss:6652441.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F1A070>\n",
      "{'name': 'Adam', 'learning_rate': 0.0004, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0004>\n",
      "epoch0loss:6656156.5\n",
      "epoch1loss:6652650.5\n",
      "epoch2loss:6649492.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F1A910>\n",
      "{'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0005>\n",
      "epoch0loss:6654999.5\n",
      "epoch1loss:6650508.5\n",
      "epoch2loss:6646422.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F11EB0>\n",
      "{'name': 'Adam', 'learning_rate': 0.0006000000000000001, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0006>\n",
      "epoch0loss:6653821.5\n",
      "epoch1loss:6648304.5\n",
      "epoch2loss:6643232.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED309A6310>\n",
      "{'name': 'Adam', 'learning_rate': 0.0007000000000000001, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0007>\n",
      "epoch0loss:6652620.5\n",
      "epoch1loss:6646034.0\n",
      "epoch2loss:6639925.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F1AA30>\n",
      "{'name': 'Adam', 'learning_rate': 0.0008000000000000001, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0008>\n",
      "epoch0loss:6651401.0\n",
      "epoch1loss:6643700.5\n",
      "epoch2loss:6636499.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ECA178CA00>\n",
      "{'name': 'Adam', 'learning_rate': 0.0009000000000000002, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0009>\n",
      "epoch0loss:6650159.0\n",
      "epoch1loss:6641305.0\n",
      "epoch2loss:6632955.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F1AB50>\n",
      "{'name': 'Adam', 'learning_rate': 0.0010000000000000002, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "epoch0loss:6648898.0\n",
      "epoch1loss:6638844.5\n",
      "epoch2loss:6629291.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F1A490>\n",
      "{'name': 'Adam', 'learning_rate': 0.0011000000000000003, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0011>\n",
      "epoch0loss:6647615.0\n",
      "epoch1loss:6636321.0\n",
      "epoch2loss:6625511.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F11CD0>\n",
      "{'name': 'Adam', 'learning_rate': 0.0012000000000000003, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0012>\n",
      "epoch0loss:6646309.5\n",
      "epoch1loss:6633733.5\n",
      "epoch2loss:6621610.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F264F0>\n",
      "{'name': 'Adam', 'learning_rate': 0.0013000000000000004, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0013>\n",
      "epoch0loss:6644984.0\n",
      "epoch1loss:6631082.5\n",
      "epoch2loss:6617592.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F26AF0>\n",
      "{'name': 'Adam', 'learning_rate': 0.0014000000000000004, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0014>\n",
      "epoch0loss:6643639.0\n",
      "epoch1loss:6628369.0\n",
      "epoch2loss:6613457.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED30C53F10>\n",
      "{'name': 'Adam', 'learning_rate': 0.0015000000000000005, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0015>\n",
      "epoch0loss:6642271.5\n",
      "epoch1loss:6625591.0\n",
      "epoch2loss:6609204.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F34160>\n",
      "{'name': 'Adam', 'learning_rate': 0.0016000000000000005, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0016>\n",
      "epoch0loss:6640882.5\n",
      "epoch1loss:6622750.0\n",
      "epoch2loss:6604834.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F34730>\n",
      "{'name': 'Adam', 'learning_rate': 0.0017000000000000006, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0017>\n",
      "epoch0loss:6639474.0\n",
      "epoch1loss:6619846.5\n",
      "epoch2loss:6600347.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED309A64C0>\n",
      "{'name': 'Adam', 'learning_rate': 0.0018000000000000006, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0018>\n",
      "epoch0loss:6638043.0\n",
      "epoch1loss:6616880.5\n",
      "epoch2loss:6595744.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F34D30>\n",
      "{'name': 'Adam', 'learning_rate': 0.0019000000000000006, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0019>\n",
      "epoch0loss:6636592.0\n",
      "epoch1loss:6613849.0\n",
      "epoch2loss:6591023.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F3D340>\n",
      "{'name': 'Adam', 'learning_rate': 0.0020000000000000005, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.002>\n",
      "epoch0loss:6635120.0\n",
      "epoch1loss:6610756.5\n",
      "epoch2loss:6586185.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F1ACA0>\n",
      "{'name': 'Adam', 'learning_rate': 0.0021000000000000003, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0021>\n",
      "epoch0loss:6633628.0\n",
      "epoch1loss:6607601.0\n",
      "epoch2loss:6581233.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F3D970>\n",
      "{'name': 'Adam', 'learning_rate': 0.0022, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0022>\n",
      "epoch0loss:6632114.0\n",
      "epoch1loss:6604380.5\n",
      "epoch2loss:6576164.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F3DF70>\n",
      "{'name': 'Adam', 'learning_rate': 0.0023, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0023>\n",
      "epoch0loss:6630579.5\n",
      "epoch1loss:6601100.0\n",
      "epoch2loss:6570978.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F34100>\n",
      "{'name': 'Adam', 'learning_rate': 0.0024, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0024>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0loss:6629025.0\n",
      "epoch1loss:6597756.0\n",
      "epoch2loss:6565678.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F4B5B0>\n",
      "{'name': 'Adam', 'learning_rate': 0.0024999999999999996, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0025>\n",
      "epoch0loss:6627448.5\n",
      "epoch1loss:6594350.5\n",
      "epoch2loss:6560262.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F4BBB0>\n",
      "{'name': 'Adam', 'learning_rate': 0.0025999999999999994, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0026>\n",
      "epoch0loss:6625852.5\n",
      "epoch1loss:6590880.0\n",
      "epoch2loss:6554732.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F3D6A0>\n",
      "{'name': 'Adam', 'learning_rate': 0.0026999999999999993, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0027>\n",
      "epoch0loss:6624234.0\n",
      "epoch1loss:6587347.5\n",
      "epoch2loss:6549088.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED361931C0>\n",
      "{'name': 'Adam', 'learning_rate': 0.002799999999999999, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0028>\n",
      "epoch0loss:6622596.0\n",
      "epoch1loss:6583754.0\n",
      "epoch2loss:6543327.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED361937C0>\n",
      "{'name': 'Adam', 'learning_rate': 0.002899999999999999, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0029>\n",
      "epoch0loss:6620937.0\n",
      "epoch1loss:6580098.0\n",
      "epoch2loss:6537453.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED30C53490>\n",
      "{'name': 'Adam', 'learning_rate': 0.0029999999999999988, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.003>\n",
      "epoch0loss:6619255.5\n",
      "epoch1loss:6576380.5\n",
      "epoch2loss:6531467.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36193DC0>\n",
      "{'name': 'Adam', 'learning_rate': 0.0030999999999999986, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0031>\n",
      "epoch0loss:6617556.5\n",
      "epoch1loss:6572601.5\n",
      "epoch2loss:6525365.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED3619F400>\n",
      "{'name': 'Adam', 'learning_rate': 0.0031999999999999984, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0032>\n",
      "epoch0loss:6615835.0\n",
      "epoch1loss:6568759.0\n",
      "epoch2loss:6519151.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F1A7C0>\n",
      "{'name': 'Adam', 'learning_rate': 0.0032999999999999982, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0033>\n",
      "epoch0loss:6614092.5\n",
      "epoch1loss:6564854.5\n",
      "epoch2loss:6512825.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED3619F9D0>\n",
      "{'name': 'Adam', 'learning_rate': 0.003399999999999998, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0034>\n",
      "epoch0loss:6612329.0\n",
      "epoch1loss:6560889.5\n",
      "epoch2loss:6506385.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED3619FFA0>\n",
      "{'name': 'Adam', 'learning_rate': 0.003499999999999998, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0035>\n",
      "epoch0loss:6610546.0\n",
      "epoch1loss:6556863.0\n",
      "epoch2loss:6499832.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F3D5B0>\n",
      "{'name': 'Adam', 'learning_rate': 0.0035999999999999977, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0036>\n",
      "epoch0loss:6608741.5\n",
      "epoch1loss:6552773.5\n",
      "epoch2loss:6493169.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED361AC5E0>\n",
      "{'name': 'Adam', 'learning_rate': 0.0036999999999999976, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0037>\n",
      "epoch0loss:6606916.5\n",
      "epoch1loss:6548624.0\n",
      "epoch2loss:6486393.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED361ACBB0>\n",
      "{'name': 'Adam', 'learning_rate': 0.0037999999999999974, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0038>\n",
      "epoch0loss:6605071.5\n",
      "epoch1loss:6544413.0\n",
      "epoch2loss:6479505.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F26A60>\n",
      "{'name': 'Adam', 'learning_rate': 0.0038999999999999972, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0039>\n",
      "epoch0loss:6603204.5\n",
      "epoch1loss:6540141.5\n",
      "epoch2loss:6472508.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED361B41F0>\n",
      "{'name': 'Adam', 'learning_rate': 0.0039999999999999975, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.004>\n",
      "epoch0loss:6601318.0\n",
      "epoch1loss:6535808.0\n",
      "epoch2loss:6465400.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED361B47C0>\n",
      "{'name': 'Adam', 'learning_rate': 0.004099999999999998, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0041>\n",
      "epoch0loss:6599411.0\n",
      "epoch1loss:6531414.5\n",
      "epoch2loss:6458180.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED361ACA60>\n",
      "{'name': 'Adam', 'learning_rate': 0.004199999999999998, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0042>\n",
      "epoch0loss:6597483.0\n",
      "epoch1loss:6526958.5\n",
      "epoch2loss:6450851.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36193E80>\n",
      "{'name': 'Adam', 'learning_rate': 0.004299999999999998, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0043>\n",
      "epoch0loss:6595534.0\n",
      "epoch1loss:6522442.5\n",
      "epoch2loss:6443413.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36193D60>\n",
      "{'name': 'Adam', 'learning_rate': 0.0043999999999999985, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0044>\n",
      "epoch0loss:6593565.5\n",
      "epoch1loss:6517865.0\n",
      "epoch2loss:6435866.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED3619F610>\n",
      "{'name': 'Adam', 'learning_rate': 0.004499999999999999, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0045>\n",
      "epoch0loss:6591575.5\n",
      "epoch1loss:6513229.5\n",
      "epoch2loss:6428210.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED361AC550>\n",
      "{'name': 'Adam', 'learning_rate': 0.004599999999999999, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0046>\n",
      "epoch0loss:6589566.0\n",
      "epoch1loss:6508532.5\n",
      "epoch2loss:6420444.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED361ACE20>\n",
      "{'name': 'Adam', 'learning_rate': 0.004699999999999999, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0047>\n",
      "epoch0loss:6587536.5\n",
      "epoch1loss:6503775.5\n",
      "epoch2loss:6412571.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36193BE0>\n",
      "{'name': 'Adam', 'learning_rate': 0.0048, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0048>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0loss:6585485.0\n",
      "epoch1loss:6498958.5\n",
      "epoch2loss:6404590.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED3619FB80>\n",
      "{'name': 'Adam', 'learning_rate': 0.0049, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0049>\n",
      "epoch0loss:6583413.5\n",
      "epoch1loss:6494081.0\n",
      "epoch2loss:6396502.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F4B730>\n",
      "{'name': 'Adam', 'learning_rate': 0.005, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.005>\n",
      "epoch0loss:6581322.5\n",
      "epoch1loss:6489142.5\n",
      "epoch2loss:6388307.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED361ACA30>\n",
      "{'name': 'Adam', 'learning_rate': 0.0051, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0051>\n",
      "epoch0loss:6579208.5\n",
      "epoch1loss:6484146.5\n",
      "epoch2loss:6380006.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F4BF70>\n",
      "{'name': 'Adam', 'learning_rate': 0.005200000000000001, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0052>\n",
      "epoch0loss:6577076.5\n",
      "epoch1loss:6479089.5\n",
      "epoch2loss:6371599.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F4BC40>\n",
      "{'name': 'Adam', 'learning_rate': 0.005300000000000001, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0053>\n",
      "epoch0loss:6574923.0\n",
      "epoch1loss:6473973.0\n",
      "epoch2loss:6363086.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED3619FC70>\n",
      "{'name': 'Adam', 'learning_rate': 0.005400000000000001, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0054>\n",
      "epoch0loss:6572750.5\n",
      "epoch1loss:6468798.5\n",
      "epoch2loss:6354466.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED361AC190>\n",
      "{'name': 'Adam', 'learning_rate': 0.005500000000000001, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0055>\n",
      "epoch0loss:6570556.0\n",
      "epoch1loss:6463564.0\n",
      "epoch2loss:6345745.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F3D1F0>\n",
      "{'name': 'Adam', 'learning_rate': 0.005600000000000002, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0056>\n",
      "epoch0loss:6568342.0\n",
      "epoch1loss:6458270.0\n",
      "epoch2loss:6336916.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F4BE50>\n",
      "{'name': 'Adam', 'learning_rate': 0.005700000000000002, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0057>\n",
      "epoch0loss:6566107.0\n",
      "epoch1loss:6452918.5\n",
      "epoch2loss:6327984.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F3DE20>\n",
      "{'name': 'Adam', 'learning_rate': 0.005800000000000002, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0058>\n",
      "epoch0loss:6563851.5\n",
      "epoch1loss:6447507.5\n",
      "epoch2loss:6318950.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F3DA00>\n",
      "{'name': 'Adam', 'learning_rate': 0.0059000000000000025, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0059>\n",
      "epoch0loss:6561577.0\n",
      "epoch1loss:6442037.0\n",
      "epoch2loss:6309812.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED3619F700>\n",
      "{'name': 'Adam', 'learning_rate': 0.006000000000000003, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.006>\n",
      "epoch0loss:6559282.5\n",
      "epoch1loss:6436509.5\n",
      "epoch2loss:6300571.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F3D340>\n",
      "{'name': 'Adam', 'learning_rate': 0.006100000000000003, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0061>\n",
      "epoch0loss:6556966.0\n",
      "epoch1loss:6430923.0\n",
      "epoch2loss:6291228.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F343A0>\n",
      "{'name': 'Adam', 'learning_rate': 0.006200000000000003, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0062>\n",
      "epoch0loss:6554631.0\n",
      "epoch1loss:6425278.0\n",
      "epoch2loss:6281784.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F4B1C0>\n",
      "{'name': 'Adam', 'learning_rate': 0.0063000000000000035, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0063>\n",
      "epoch0loss:6552275.0\n",
      "epoch1loss:6419575.5\n",
      "epoch2loss:6272240.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED3619FFD0>\n",
      "{'name': 'Adam', 'learning_rate': 0.006400000000000004, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0064>\n",
      "epoch0loss:6549900.0\n",
      "epoch1loss:6413813.5\n",
      "epoch2loss:6262594.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F349D0>\n",
      "{'name': 'Adam', 'learning_rate': 0.006500000000000004, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0065>\n",
      "epoch0loss:6547503.0\n",
      "epoch1loss:6407997.5\n",
      "epoch2loss:6252848.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F4BE20>\n",
      "{'name': 'Adam', 'learning_rate': 0.006600000000000004, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0066>\n",
      "epoch0loss:6545086.5\n",
      "epoch1loss:6402120.0\n",
      "epoch2loss:6243002.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F345E0>\n",
      "{'name': 'Adam', 'learning_rate': 0.0067000000000000046, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0067>\n",
      "epoch0loss:6542649.5\n",
      "epoch1loss:6396187.0\n",
      "epoch2loss:6233057.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F348E0>\n",
      "{'name': 'Adam', 'learning_rate': 0.006800000000000005, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0068>\n",
      "epoch0loss:6540194.5\n",
      "epoch1loss:6390196.0\n",
      "epoch2loss:6223013.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED361AC9D0>\n",
      "{'name': 'Adam', 'learning_rate': 0.006900000000000005, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0069>\n",
      "epoch0loss:6537718.0\n",
      "epoch1loss:6384148.5\n",
      "epoch2loss:6212870.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED3619F8B0>\n",
      "{'name': 'Adam', 'learning_rate': 0.007000000000000005, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.007>\n",
      "epoch0loss:6535221.0\n",
      "epoch1loss:6378044.0\n",
      "epoch2loss:6202631.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F26550>\n",
      "{'name': 'Adam', 'learning_rate': 0.007100000000000006, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0071>\n",
      "epoch0loss:6532703.0\n",
      "epoch1loss:6371882.0\n",
      "epoch2loss:6192294.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F4B5E0>\n",
      "{'name': 'Adam', 'learning_rate': 0.007200000000000006, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0072>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0loss:6530166.5\n",
      "epoch1loss:6365664.5\n",
      "epoch2loss:6181862.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F26850>\n",
      "{'name': 'Adam', 'learning_rate': 0.007300000000000006, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0073>\n",
      "epoch0loss:6527610.5\n",
      "epoch1loss:6359389.0\n",
      "epoch2loss:6171333.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F26D00>\n",
      "{'name': 'Adam', 'learning_rate': 0.007400000000000006, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0074>\n",
      "epoch0loss:6525034.0\n",
      "epoch1loss:6353059.0\n",
      "epoch2loss:6160708.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F34B20>\n",
      "{'name': 'Adam', 'learning_rate': 0.007500000000000007, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0075>\n",
      "epoch0loss:6522438.0\n",
      "epoch1loss:6346672.0\n",
      "epoch2loss:6149987.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F4B5E0>\n",
      "{'name': 'Adam', 'learning_rate': 0.007600000000000007, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0076>\n",
      "epoch0loss:6519821.0\n",
      "epoch1loss:6340230.0\n",
      "epoch2loss:6139173.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36193340>\n",
      "{'name': 'Adam', 'learning_rate': 0.007700000000000007, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0077>\n",
      "epoch0loss:6517183.5\n",
      "epoch1loss:6333731.5\n",
      "epoch2loss:6128266.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F26280>\n",
      "{'name': 'Adam', 'learning_rate': 0.0078000000000000074, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0078>\n",
      "epoch0loss:6514527.5\n",
      "epoch1loss:6327177.0\n",
      "epoch2loss:6117264.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F3D070>\n",
      "{'name': 'Adam', 'learning_rate': 0.007900000000000008, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0079>\n",
      "epoch0loss:6511851.5\n",
      "epoch1loss:6320568.0\n",
      "epoch2loss:6106170.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F3DDF0>\n",
      "{'name': 'Adam', 'learning_rate': 0.008000000000000007, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.008>\n",
      "epoch0loss:6509156.5\n",
      "epoch1loss:6313902.5\n",
      "epoch2loss:6094983.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F34340>\n",
      "{'name': 'Adam', 'learning_rate': 0.008100000000000007, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0081>\n",
      "epoch0loss:6506440.5\n",
      "epoch1loss:6307182.0\n",
      "epoch2loss:6083707.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F26040>\n",
      "{'name': 'Adam', 'learning_rate': 0.008200000000000006, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0082>\n",
      "epoch0loss:6503704.5\n",
      "epoch1loss:6300408.0\n",
      "epoch2loss:6072338.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED3619FFD0>\n",
      "{'name': 'Adam', 'learning_rate': 0.008300000000000005, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0083>\n",
      "epoch0loss:6500950.5\n",
      "epoch1loss:6293579.0\n",
      "epoch2loss:6060878.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F26070>\n",
      "{'name': 'Adam', 'learning_rate': 0.008400000000000005, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0084>\n",
      "epoch0loss:6498176.0\n",
      "epoch1loss:6286695.0\n",
      "epoch2loss:6049329.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F340D0>\n",
      "{'name': 'Adam', 'learning_rate': 0.008500000000000004, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0085>\n",
      "epoch0loss:6495381.5\n",
      "epoch1loss:6279757.5\n",
      "epoch2loss:6037691.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED3619F7C0>\n",
      "{'name': 'Adam', 'learning_rate': 0.008600000000000003, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0086>\n",
      "epoch0loss:6492565.5\n",
      "epoch1loss:6272764.0\n",
      "epoch2loss:6025964.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F34190>\n",
      "{'name': 'Adam', 'learning_rate': 0.008700000000000003, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0087>\n",
      "epoch0loss:6489731.5\n",
      "epoch1loss:6265718.5\n",
      "epoch2loss:6014149.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F26F40>\n",
      "{'name': 'Adam', 'learning_rate': 0.008800000000000002, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0088>\n",
      "epoch0loss:6486878.5\n",
      "epoch1loss:6258618.0\n",
      "epoch2loss:6002245.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F261F0>\n",
      "{'name': 'Adam', 'learning_rate': 0.008900000000000002, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0089>\n",
      "epoch0loss:6484006.0\n",
      "epoch1loss:6251465.5\n",
      "epoch2loss:5990258.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F3D460>\n",
      "{'name': 'Adam', 'learning_rate': 0.009000000000000001, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.009>\n",
      "epoch0loss:6481113.0\n",
      "epoch1loss:6244258.0\n",
      "epoch2loss:5978183.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED3619FFA0>\n",
      "{'name': 'Adam', 'learning_rate': 0.0091, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0091>\n",
      "epoch0loss:6478201.0\n",
      "epoch1loss:6236998.0\n",
      "epoch2loss:5966022.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36193FA0>\n",
      "{'name': 'Adam', 'learning_rate': 0.0092, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0092>\n",
      "epoch0loss:6475266.5\n",
      "epoch1loss:6229685.5\n",
      "epoch2loss:5953777.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F34E50>\n",
      "{'name': 'Adam', 'learning_rate': 0.0093, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0093>\n",
      "epoch0loss:6472316.0\n",
      "epoch1loss:6222318.5\n",
      "epoch2loss:5941447.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED361934C0>\n",
      "{'name': 'Adam', 'learning_rate': 0.009399999999999999, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0094>\n",
      "epoch0loss:6469346.5\n",
      "epoch1loss:6214901.0\n",
      "epoch2loss:5929035.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED361934F0>\n",
      "{'name': 'Adam', 'learning_rate': 0.009499999999999998, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0095>\n",
      "epoch0loss:6466355.0\n",
      "epoch1loss:6207430.5\n",
      "epoch2loss:5916538.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F3DDF0>\n",
      "{'name': 'Adam', 'learning_rate': 0.009599999999999997, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0096>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0loss:6463345.5\n",
      "epoch1loss:6199907.0\n",
      "epoch2loss:5903960.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F34760>\n",
      "{'name': 'Adam', 'learning_rate': 0.009699999999999997, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0097>\n",
      "epoch0loss:6460317.0\n",
      "epoch1loss:6192331.0\n",
      "epoch2loss:5891301.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F4B1F0>\n",
      "{'name': 'Adam', 'learning_rate': 0.009799999999999996, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0098>\n",
      "epoch0loss:6457266.5\n",
      "epoch1loss:6184705.5\n",
      "epoch2loss:5878560.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F26F40>\n",
      "{'name': 'Adam', 'learning_rate': 0.009899999999999996, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0099>\n",
      "epoch0loss:6454199.5\n",
      "epoch1loss:6177027.5\n",
      "epoch2loss:5865740.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F3D340>\n",
      "{'name': 'Adam', 'learning_rate': 0.009999999999999995, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "epoch0loss:6451113.5\n",
      "epoch1loss:6169299.5\n",
      "epoch2loss:5852840.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F4B100>\n",
      "{'name': 'Adam', 'learning_rate': 0.010099999999999994, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0101>\n",
      "epoch0loss:6448005.5\n",
      "epoch1loss:6161518.0\n",
      "epoch2loss:5839861.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED3619F4C0>\n",
      "{'name': 'Adam', 'learning_rate': 0.010199999999999994, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0102>\n",
      "epoch0loss:6444880.0\n",
      "epoch1loss:6153686.5\n",
      "epoch2loss:5826805.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F34D90>\n",
      "{'name': 'Adam', 'learning_rate': 0.010299999999999993, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0103>\n",
      "epoch0loss:6441735.5\n",
      "epoch1loss:6145804.5\n",
      "epoch2loss:5813670.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F34D30>\n",
      "{'name': 'Adam', 'learning_rate': 0.010399999999999993, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0104>\n",
      "epoch0loss:6438569.5\n",
      "epoch1loss:6137871.5\n",
      "epoch2loss:5800460.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F26760>\n",
      "{'name': 'Adam', 'learning_rate': 0.010499999999999992, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0105>\n",
      "epoch0loss:6435387.0\n",
      "epoch1loss:6129888.0\n",
      "epoch2loss:5787172.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F3D700>\n",
      "{'name': 'Adam', 'learning_rate': 0.010599999999999991, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0106>\n",
      "epoch0loss:6432184.5\n",
      "epoch1loss:6121856.0\n",
      "epoch2loss:5773811.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED361ACCD0>\n",
      "{'name': 'Adam', 'learning_rate': 0.01069999999999999, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0107>\n",
      "epoch0loss:6428962.5\n",
      "epoch1loss:6113772.5\n",
      "epoch2loss:5760374.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F34820>\n",
      "{'name': 'Adam', 'learning_rate': 0.01079999999999999, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0108>\n",
      "epoch0loss:6425721.0\n",
      "epoch1loss:6105640.0\n",
      "epoch2loss:5746864.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F3DAC0>\n",
      "{'name': 'Adam', 'learning_rate': 0.01089999999999999, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0109>\n",
      "epoch0loss:6422461.0\n",
      "epoch1loss:6097459.0\n",
      "epoch2loss:5733281.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED3619F910>\n",
      "{'name': 'Adam', 'learning_rate': 0.010999999999999989, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.011>\n",
      "epoch0loss:6419182.0\n",
      "epoch1loss:6089228.0\n",
      "epoch2loss:5719625.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F26FA0>\n",
      "{'name': 'Adam', 'learning_rate': 0.011099999999999988, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0111>\n",
      "epoch0loss:6415885.0\n",
      "epoch1loss:6080948.0\n",
      "epoch2loss:5705899.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F34820>\n",
      "{'name': 'Adam', 'learning_rate': 0.011199999999999988, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0112>\n",
      "epoch0loss:6412567.0\n",
      "epoch1loss:6072619.0\n",
      "epoch2loss:5692101.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED30C531C0>\n",
      "{'name': 'Adam', 'learning_rate': 0.011299999999999987, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0113>\n",
      "epoch0loss:6409232.0\n",
      "epoch1loss:6064243.0\n",
      "epoch2loss:5678233.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED30C53EB0>\n",
      "{'name': 'Adam', 'learning_rate': 0.011399999999999987, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0114>\n",
      "epoch0loss:6405877.0\n",
      "epoch1loss:6055818.5\n",
      "epoch2loss:5664298.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F4B340>\n",
      "{'name': 'Adam', 'learning_rate': 0.011499999999999986, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0115>\n",
      "epoch0loss:6402502.0\n",
      "epoch1loss:6047344.5\n",
      "epoch2loss:5650293.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED361936D0>\n",
      "{'name': 'Adam', 'learning_rate': 0.011599999999999985, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0116>\n",
      "epoch0loss:6399110.0\n",
      "epoch1loss:6038824.5\n",
      "epoch2loss:5636220.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F4B5B0>\n",
      "{'name': 'Adam', 'learning_rate': 0.011699999999999985, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0117>\n",
      "epoch0loss:6395697.5\n",
      "epoch1loss:6030256.0\n",
      "epoch2loss:5622079.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED361AC940>\n",
      "{'name': 'Adam', 'learning_rate': 0.011799999999999984, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0118>\n",
      "epoch0loss:6392268.0\n",
      "epoch1loss:6021640.0\n",
      "epoch2loss:5607874.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED361933A0>\n",
      "{'name': 'Adam', 'learning_rate': 0.011899999999999984, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0119>\n",
      "epoch0loss:6388818.0\n",
      "epoch1loss:6012978.0\n",
      "epoch2loss:5593604.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED30C53460>\n",
      "{'name': 'Adam', 'learning_rate': 0.011999999999999983, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.012>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0loss:6385351.5\n",
      "epoch1loss:6004268.5\n",
      "epoch2loss:5579269.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F4BFD0>\n",
      "{'name': 'Adam', 'learning_rate': 0.012099999999999982, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0121>\n",
      "epoch0loss:6381864.5\n",
      "epoch1loss:5995512.5\n",
      "epoch2loss:5564869.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F4BDF0>\n",
      "{'name': 'Adam', 'learning_rate': 0.012199999999999982, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0122>\n",
      "epoch0loss:6378359.0\n",
      "epoch1loss:5986711.0\n",
      "epoch2loss:5550409.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36193B20>\n",
      "{'name': 'Adam', 'learning_rate': 0.012299999999999981, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0123>\n",
      "epoch0loss:6374835.5\n",
      "epoch1loss:5977863.0\n",
      "epoch2loss:5535885.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED30C53F70>\n",
      "{'name': 'Adam', 'learning_rate': 0.01239999999999998, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0124>\n",
      "epoch0loss:6371291.5\n",
      "epoch1loss:5968969.0\n",
      "epoch2loss:5521299.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F34850>\n",
      "{'name': 'Adam', 'learning_rate': 0.01249999999999998, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0125>\n",
      "epoch0loss:6367731.0\n",
      "epoch1loss:5960030.0\n",
      "epoch2loss:5506655.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED361ACF70>\n",
      "{'name': 'Adam', 'learning_rate': 0.01259999999999998, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0126>\n",
      "epoch0loss:6364151.0\n",
      "epoch1loss:5951044.5\n",
      "epoch2loss:5491949.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F34730>\n",
      "{'name': 'Adam', 'learning_rate': 0.012699999999999979, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0127>\n",
      "epoch0loss:6360553.5\n",
      "epoch1loss:5942015.0\n",
      "epoch2loss:5477186.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F34130>\n",
      "{'name': 'Adam', 'learning_rate': 0.012799999999999978, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0128>\n",
      "epoch0loss:6356936.0\n",
      "epoch1loss:5932941.0\n",
      "epoch2loss:5462365.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36193DC0>\n",
      "{'name': 'Adam', 'learning_rate': 0.012899999999999977, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0129>\n",
      "epoch0loss:6353300.5\n",
      "epoch1loss:5923822.5\n",
      "epoch2loss:5447487.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED361ACF10>\n",
      "{'name': 'Adam', 'learning_rate': 0.012999999999999977, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.013>\n",
      "epoch0loss:6349646.0\n",
      "epoch1loss:5914660.0\n",
      "epoch2loss:5432553.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F3D9A0>\n",
      "{'name': 'Adam', 'learning_rate': 0.013099999999999976, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0131>\n",
      "epoch0loss:6345974.0\n",
      "epoch1loss:5905452.0\n",
      "epoch2loss:5417563.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F34EE0>\n",
      "{'name': 'Adam', 'learning_rate': 0.013199999999999976, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0132>\n",
      "epoch0loss:6342284.5\n",
      "epoch1loss:5896201.5\n",
      "epoch2loss:5402521.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F3D610>\n",
      "{'name': 'Adam', 'learning_rate': 0.013299999999999975, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0133>\n",
      "epoch0loss:6338574.5\n",
      "epoch1loss:5886906.5\n",
      "epoch2loss:5387423.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F3DA00>\n",
      "{'name': 'Adam', 'learning_rate': 0.013399999999999974, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0134>\n",
      "epoch0loss:6334847.0\n",
      "epoch1loss:5877570.5\n",
      "epoch2loss:5372273.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED361ACA60>\n",
      "{'name': 'Adam', 'learning_rate': 0.013499999999999974, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0135>\n",
      "epoch0loss:6331102.0\n",
      "epoch1loss:5868190.0\n",
      "epoch2loss:5357073.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F3DEB0>\n",
      "{'name': 'Adam', 'learning_rate': 0.013599999999999973, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0136>\n",
      "epoch0loss:6327338.5\n",
      "epoch1loss:5858766.5\n",
      "epoch2loss:5341820.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED3619FC40>\n",
      "{'name': 'Adam', 'learning_rate': 0.013699999999999973, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0137>\n",
      "epoch0loss:6323557.0\n",
      "epoch1loss:5849300.5\n",
      "epoch2loss:5326518.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F349A0>\n",
      "{'name': 'Adam', 'learning_rate': 0.013799999999999972, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0138>\n",
      "epoch0loss:6319757.0\n",
      "epoch1loss:5839793.5\n",
      "epoch2loss:5311167.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED3619FB20>\n",
      "{'name': 'Adam', 'learning_rate': 0.013899999999999971, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0139>\n",
      "epoch0loss:6315938.0\n",
      "epoch1loss:5830244.5\n",
      "epoch2loss:5295769.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED3619FDF0>\n",
      "{'name': 'Adam', 'learning_rate': 0.01399999999999997, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.014>\n",
      "epoch0loss:6312101.5\n",
      "epoch1loss:5820653.5\n",
      "epoch2loss:5280322.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED361ACE20>\n",
      "{'name': 'Adam', 'learning_rate': 0.01409999999999997, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0141>\n",
      "epoch0loss:6308247.5\n",
      "epoch1loss:5811022.0\n",
      "epoch2loss:5264830.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F3DFD0>\n",
      "{'name': 'Adam', 'learning_rate': 0.01419999999999997, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0142>\n",
      "epoch0loss:6304374.0\n",
      "epoch1loss:5801347.0\n",
      "epoch2loss:5249293.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F26F40>\n",
      "{'name': 'Adam', 'learning_rate': 0.014299999999999969, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0143>\n",
      "epoch0loss:6300482.5\n",
      "epoch1loss:5791636.0\n",
      "epoch2loss:5233711.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F4B430>\n",
      "{'name': 'Adam', 'learning_rate': 0.014399999999999968, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0144>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0loss:6296575.0\n",
      "epoch1loss:5781881.5\n",
      "epoch2loss:5218086.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED361AC280>\n",
      "{'name': 'Adam', 'learning_rate': 0.014499999999999968, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0145>\n",
      "epoch0loss:6292648.5\n",
      "epoch1loss:5772085.5\n",
      "epoch2loss:5202419.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F268B0>\n",
      "{'name': 'Adam', 'learning_rate': 0.014599999999999967, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0146>\n",
      "epoch0loss:6288704.0\n",
      "epoch1loss:5762252.5\n",
      "epoch2loss:5186709.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED30C53FD0>\n",
      "{'name': 'Adam', 'learning_rate': 0.014699999999999967, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0147>\n",
      "epoch0loss:6284742.5\n",
      "epoch1loss:5752379.0\n",
      "epoch2loss:5170960.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F26220>\n",
      "{'name': 'Adam', 'learning_rate': 0.014799999999999966, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0148>\n",
      "epoch0loss:6280762.5\n",
      "epoch1loss:5742466.5\n",
      "epoch2loss:5155172.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36193F70>\n",
      "{'name': 'Adam', 'learning_rate': 0.014899999999999965, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0149>\n",
      "epoch0loss:6276763.5\n",
      "epoch1loss:5732514.5\n",
      "epoch2loss:5139343.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F26B80>\n",
      "{'name': 'Adam', 'learning_rate': 0.014999999999999965, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.015>\n",
      "epoch0loss:6272748.5\n",
      "epoch1loss:5722523.0\n",
      "epoch2loss:5123479.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F3DA00>\n",
      "{'name': 'Adam', 'learning_rate': 0.015099999999999964, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0151>\n",
      "epoch0loss:6268714.5\n",
      "epoch1loss:5712495.0\n",
      "epoch2loss:5107577.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F3DAC0>\n",
      "{'name': 'Adam', 'learning_rate': 0.015199999999999964, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0152>\n",
      "epoch0loss:6264663.5\n",
      "epoch1loss:5702427.0\n",
      "epoch2loss:5091639.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F3D8E0>\n",
      "{'name': 'Adam', 'learning_rate': 0.015299999999999963, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0153>\n",
      "epoch0loss:6260594.5\n",
      "epoch1loss:5692324.0\n",
      "epoch2loss:5075666.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED3619FFA0>\n",
      "{'name': 'Adam', 'learning_rate': 0.015399999999999962, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0154>\n",
      "epoch0loss:6256509.0\n",
      "epoch1loss:5682181.0\n",
      "epoch2loss:5059662.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F348E0>\n",
      "{'name': 'Adam', 'learning_rate': 0.015499999999999962, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0155>\n",
      "epoch0loss:6252403.5\n",
      "epoch1loss:5671999.5\n",
      "epoch2loss:5043623.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F344C0>\n",
      "{'name': 'Adam', 'learning_rate': 0.015599999999999961, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0156>\n",
      "epoch0loss:6248283.0\n",
      "epoch1loss:5661784.0\n",
      "epoch2loss:5027553.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F26D30>\n",
      "{'name': 'Adam', 'learning_rate': 0.01569999999999996, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0157>\n",
      "epoch0loss:6244143.5\n",
      "epoch1loss:5651531.5\n",
      "epoch2loss:5011453.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F269A0>\n",
      "{'name': 'Adam', 'learning_rate': 0.01579999999999996, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0158>\n",
      "epoch0loss:6239986.5\n",
      "epoch1loss:5641243.0\n",
      "epoch2loss:4995324.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED3619F820>\n",
      "{'name': 'Adam', 'learning_rate': 0.01589999999999996, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0159>\n",
      "epoch0loss:6235813.0\n",
      "epoch1loss:5630918.0\n",
      "epoch2loss:4979165.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F34B80>\n",
      "{'name': 'Adam', 'learning_rate': 0.01599999999999996, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.016>\n",
      "epoch0loss:6231621.5\n",
      "epoch1loss:5620556.0\n",
      "epoch2loss:4962979.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED30C53E20>\n",
      "{'name': 'Adam', 'learning_rate': 0.016099999999999958, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0161>\n",
      "epoch0loss:6227413.0\n",
      "epoch1loss:5610160.5\n",
      "epoch2loss:4946766.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F3DFA0>\n",
      "{'name': 'Adam', 'learning_rate': 0.016199999999999957, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0162>\n",
      "epoch0loss:6223188.0\n",
      "epoch1loss:5599729.0\n",
      "epoch2loss:4930529.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED3619FB20>\n",
      "{'name': 'Adam', 'learning_rate': 0.016299999999999957, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0163>\n",
      "epoch0loss:6218944.0\n",
      "epoch1loss:5589262.5\n",
      "epoch2loss:4914266.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36193340>\n",
      "{'name': 'Adam', 'learning_rate': 0.016399999999999956, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0164>\n",
      "epoch0loss:6214682.0\n",
      "epoch1loss:5578763.5\n",
      "epoch2loss:4897981.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F3DFD0>\n",
      "{'name': 'Adam', 'learning_rate': 0.016499999999999956, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0165>\n",
      "epoch0loss:6210404.5\n",
      "epoch1loss:5568229.0\n",
      "epoch2loss:4881674.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F26EE0>\n",
      "{'name': 'Adam', 'learning_rate': 0.016599999999999955, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0166>\n",
      "epoch0loss:6206110.5\n",
      "epoch1loss:5557660.5\n",
      "epoch2loss:4865345.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36193F70>\n",
      "{'name': 'Adam', 'learning_rate': 0.016699999999999954, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0167>\n",
      "epoch0loss:6201799.0\n",
      "epoch1loss:5547059.5\n",
      "epoch2loss:4848996.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F3D7C0>\n",
      "{'name': 'Adam', 'learning_rate': 0.016799999999999954, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0168>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0loss:6197469.5\n",
      "epoch1loss:5536425.5\n",
      "epoch2loss:4832629.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED3619FA60>\n",
      "{'name': 'Adam', 'learning_rate': 0.016899999999999953, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0169>\n",
      "epoch0loss:6193122.5\n",
      "epoch1loss:5525757.0\n",
      "epoch2loss:4816243.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED30C53F40>\n",
      "{'name': 'Adam', 'learning_rate': 0.016999999999999953, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.017>\n",
      "epoch0loss:6188759.0\n",
      "epoch1loss:5515057.0\n",
      "epoch2loss:4799841.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F264F0>\n",
      "{'name': 'Adam', 'learning_rate': 0.017099999999999952, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0171>\n",
      "epoch0loss:6184378.5\n",
      "epoch1loss:5504325.0\n",
      "epoch2loss:4783422.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED361938B0>\n",
      "{'name': 'Adam', 'learning_rate': 0.01719999999999995, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0172>\n",
      "epoch0loss:6179981.5\n",
      "epoch1loss:5493561.0\n",
      "epoch2loss:4766989.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED361AC040>\n",
      "{'name': 'Adam', 'learning_rate': 0.01729999999999995, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0173>\n",
      "epoch0loss:6175568.5\n",
      "epoch1loss:5482766.0\n",
      "epoch2loss:4750544.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F3DD90>\n",
      "{'name': 'Adam', 'learning_rate': 0.01739999999999995, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0174>\n",
      "epoch0loss:6171136.0\n",
      "epoch1loss:5471940.0\n",
      "epoch2loss:4734086.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED3619FC40>\n",
      "{'name': 'Adam', 'learning_rate': 0.01749999999999995, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0175>\n",
      "epoch0loss:6166688.5\n",
      "epoch1loss:5461084.0\n",
      "epoch2loss:4717616.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F34400>\n",
      "{'name': 'Adam', 'learning_rate': 0.01759999999999995, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0176>\n",
      "epoch0loss:6162224.0\n",
      "epoch1loss:5450195.5\n",
      "epoch2loss:4701136.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED361934F0>\n",
      "{'name': 'Adam', 'learning_rate': 0.01769999999999995, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0177>\n",
      "epoch0loss:6157743.5\n",
      "epoch1loss:5439278.0\n",
      "epoch2loss:4684647.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F3D760>\n",
      "{'name': 'Adam', 'learning_rate': 0.017799999999999948, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0178>\n",
      "epoch0loss:6153245.0\n",
      "epoch1loss:5428330.0\n",
      "epoch2loss:4668151.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F4BCA0>\n",
      "{'name': 'Adam', 'learning_rate': 0.017899999999999947, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0179>\n",
      "epoch0loss:6148730.0\n",
      "epoch1loss:5417353.0\n",
      "epoch2loss:4651647.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F26130>\n",
      "{'name': 'Adam', 'learning_rate': 0.017999999999999947, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.018>\n",
      "epoch0loss:6144199.5\n",
      "epoch1loss:5406347.5\n",
      "epoch2loss:4635138.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F3D6A0>\n",
      "{'name': 'Adam', 'learning_rate': 0.018099999999999946, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0181>\n",
      "epoch0loss:6139651.0\n",
      "epoch1loss:5395312.0\n",
      "epoch2loss:4618624.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36193B80>\n",
      "{'name': 'Adam', 'learning_rate': 0.018199999999999945, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0182>\n",
      "epoch0loss:6135087.5\n",
      "epoch1loss:5384248.5\n",
      "epoch2loss:4602109.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED3619FD00>\n",
      "{'name': 'Adam', 'learning_rate': 0.018299999999999945, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0183>\n",
      "epoch0loss:6130506.0\n",
      "epoch1loss:5373158.5\n",
      "epoch2loss:4585590.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F26040>\n",
      "{'name': 'Adam', 'learning_rate': 0.018399999999999944, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0184>\n",
      "epoch0loss:6125908.0\n",
      "epoch1loss:5362039.5\n",
      "epoch2loss:4569070.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED309A6BB0>\n",
      "{'name': 'Adam', 'learning_rate': 0.018499999999999944, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0185>\n",
      "epoch0loss:6121294.0\n",
      "epoch1loss:5350893.5\n",
      "epoch2loss:4552552.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED309A6CD0>\n",
      "{'name': 'Adam', 'learning_rate': 0.018599999999999943, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0186>\n",
      "epoch0loss:6116664.5\n",
      "epoch1loss:5339719.0\n",
      "epoch2loss:4536035.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36193970>\n",
      "{'name': 'Adam', 'learning_rate': 0.018699999999999942, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0187>\n",
      "epoch0loss:6112017.5\n",
      "epoch1loss:5328520.0\n",
      "epoch2loss:4519520.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36193F40>\n",
      "{'name': 'Adam', 'learning_rate': 0.018799999999999942, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0188>\n",
      "epoch0loss:6107354.5\n",
      "epoch1loss:5317294.0\n",
      "epoch2loss:4503009.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED361ACF10>\n",
      "{'name': 'Adam', 'learning_rate': 0.01889999999999994, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0189>\n",
      "epoch0loss:6102676.0\n",
      "epoch1loss:5306042.0\n",
      "epoch2loss:4486502.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F4BC40>\n",
      "{'name': 'Adam', 'learning_rate': 0.01899999999999994, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.019>\n",
      "epoch0loss:6097982.0\n",
      "epoch1loss:5294763.0\n",
      "epoch2loss:4470004.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F4BB80>\n",
      "{'name': 'Adam', 'learning_rate': 0.01909999999999994, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0191>\n",
      "epoch0loss:6093269.0\n",
      "epoch1loss:5283461.0\n",
      "epoch2loss:4453512.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED309A6BB0>\n",
      "{'name': 'Adam', 'learning_rate': 0.01919999999999994, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0192>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0loss:6088541.5\n",
      "epoch1loss:5272132.0\n",
      "epoch2loss:4437028.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED361930D0>\n",
      "{'name': 'Adam', 'learning_rate': 0.01929999999999994, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0193>\n",
      "epoch0loss:6083797.5\n",
      "epoch1loss:5260781.0\n",
      "epoch2loss:4420555.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED30C533A0>\n",
      "{'name': 'Adam', 'learning_rate': 0.019399999999999938, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0194>\n",
      "epoch0loss:6079039.5\n",
      "epoch1loss:5249404.0\n",
      "epoch2loss:4404093.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F4BF10>\n",
      "{'name': 'Adam', 'learning_rate': 0.019499999999999938, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0195>\n",
      "epoch0loss:6074263.0\n",
      "epoch1loss:5238004.5\n",
      "epoch2loss:4387643.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED361AC130>\n",
      "{'name': 'Adam', 'learning_rate': 0.019599999999999937, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0196>\n",
      "epoch0loss:6069472.0\n",
      "epoch1loss:5226581.0\n",
      "epoch2loss:4371208.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED3619FD00>\n",
      "{'name': 'Adam', 'learning_rate': 0.019699999999999936, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0197>\n",
      "epoch0loss:6064664.5\n",
      "epoch1loss:5215134.0\n",
      "epoch2loss:4354787.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36193BB0>\n",
      "{'name': 'Adam', 'learning_rate': 0.019799999999999936, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0198>\n",
      "epoch0loss:6059842.0\n",
      "epoch1loss:5203666.0\n",
      "epoch2loss:4338382.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED30C53250>\n",
      "{'name': 'Adam', 'learning_rate': 0.019899999999999935, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0199>\n",
      "epoch0loss:6055002.0\n",
      "epoch1loss:5192173.5\n",
      "epoch2loss:4321994.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED3619FBE0>\n",
      "{'name': 'Adam', 'learning_rate': 0.019999999999999934, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.02>\n",
      "epoch0loss:6050146.5\n",
      "epoch1loss:5180661.5\n",
      "epoch2loss:4305627.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED30C53580>\n",
      "{'name': 'Adam', 'learning_rate': 0.020099999999999934, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0201>\n",
      "epoch0loss:6045277.0\n",
      "epoch1loss:5169126.0\n",
      "epoch2loss:4289279.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED361AC070>\n",
      "{'name': 'Adam', 'learning_rate': 0.020199999999999933, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0202>\n",
      "epoch0loss:6040390.0\n",
      "epoch1loss:5157569.5\n",
      "epoch2loss:4272951.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F3D6A0>\n",
      "{'name': 'Adam', 'learning_rate': 0.020299999999999933, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0203>\n",
      "epoch0loss:6035488.5\n",
      "epoch1loss:5145993.0\n",
      "epoch2loss:4256646.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED3619FE50>\n",
      "{'name': 'Adam', 'learning_rate': 0.020399999999999932, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0204>\n",
      "epoch0loss:6030571.0\n",
      "epoch1loss:5134397.0\n",
      "epoch2loss:4240365.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED30C53310>\n",
      "{'name': 'Adam', 'learning_rate': 0.02049999999999993, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0205>\n",
      "epoch0loss:6025638.0\n",
      "epoch1loss:5122779.5\n",
      "epoch2loss:4224110.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F3DD90>\n",
      "{'name': 'Adam', 'learning_rate': 0.02059999999999993, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0206>\n",
      "epoch0loss:6020690.0\n",
      "epoch1loss:5111144.0\n",
      "epoch2loss:4207880.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED361ACC70>\n",
      "{'name': 'Adam', 'learning_rate': 0.02069999999999993, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0207>\n",
      "epoch0loss:6015727.0\n",
      "epoch1loss:5099487.5\n",
      "epoch2loss:4191679.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36193D90>\n",
      "{'name': 'Adam', 'learning_rate': 0.02079999999999993, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0208>\n",
      "epoch0loss:6010746.5\n",
      "epoch1loss:5087813.0\n",
      "epoch2loss:4175507.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F34220>\n",
      "{'name': 'Adam', 'learning_rate': 0.02089999999999993, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0209>\n",
      "epoch0loss:6005752.0\n",
      "epoch1loss:5076119.5\n",
      "epoch2loss:4159364.8\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED30C53B50>\n",
      "{'name': 'Adam', 'learning_rate': 0.02099999999999993, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.021>\n",
      "epoch0loss:6000743.0\n",
      "epoch1loss:5064410.0\n",
      "epoch2loss:4143255.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F4B7C0>\n",
      "{'name': 'Adam', 'learning_rate': 0.021099999999999928, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0211>\n",
      "epoch0loss:5995717.5\n",
      "epoch1loss:5052681.0\n",
      "epoch2loss:4127177.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F34A60>\n",
      "{'name': 'Adam', 'learning_rate': 0.021199999999999927, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0212>\n",
      "epoch0loss:5990676.5\n",
      "epoch1loss:5040934.5\n",
      "epoch2loss:4111135.2\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F3D6A0>\n",
      "{'name': 'Adam', 'learning_rate': 0.021299999999999927, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0213>\n",
      "epoch0loss:5985622.0\n",
      "epoch1loss:5029173.0\n",
      "epoch2loss:4095128.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36193700>\n",
      "{'name': 'Adam', 'learning_rate': 0.021399999999999926, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0214>\n",
      "epoch0loss:5980550.5\n",
      "epoch1loss:5017393.0\n",
      "epoch2loss:4079157.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F26D60>\n",
      "{'name': 'Adam', 'learning_rate': 0.021499999999999925, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0215>\n",
      "epoch0loss:5975465.5\n",
      "epoch1loss:5005596.5\n",
      "epoch2loss:4063226.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F4BC10>\n",
      "{'name': 'Adam', 'learning_rate': 0.021599999999999925, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0216>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0loss:5970365.5\n",
      "epoch1loss:4993787.0\n",
      "epoch2loss:4047335.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED309A64C0>\n",
      "{'name': 'Adam', 'learning_rate': 0.021699999999999924, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0217>\n",
      "epoch0loss:5965248.5\n",
      "epoch1loss:4981961.5\n",
      "epoch2loss:4031484.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F26F70>\n",
      "{'name': 'Adam', 'learning_rate': 0.021799999999999924, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0218>\n",
      "epoch0loss:5960117.5\n",
      "epoch1loss:4970121.0\n",
      "epoch2loss:4015676.8\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36193C10>\n",
      "{'name': 'Adam', 'learning_rate': 0.021899999999999923, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0219>\n",
      "epoch0loss:5954973.0\n",
      "epoch1loss:4958265.5\n",
      "epoch2loss:3999912.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F26970>\n",
      "{'name': 'Adam', 'learning_rate': 0.021999999999999922, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.022>\n",
      "epoch0loss:5949813.0\n",
      "epoch1loss:4946396.0\n",
      "epoch2loss:3984193.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F1AC70>\n",
      "{'name': 'Adam', 'learning_rate': 0.022099999999999922, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0221>\n",
      "epoch0loss:5944638.0\n",
      "epoch1loss:4934514.0\n",
      "epoch2loss:3968521.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F1AC40>\n",
      "{'name': 'Adam', 'learning_rate': 0.02219999999999992, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0222>\n",
      "epoch0loss:5939447.0\n",
      "epoch1loss:4922618.0\n",
      "epoch2loss:3952897.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F3DC40>\n",
      "{'name': 'Adam', 'learning_rate': 0.02229999999999992, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0223>\n",
      "epoch0loss:5934243.5\n",
      "epoch1loss:4910709.0\n",
      "epoch2loss:3937322.8\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F3DBB0>\n",
      "{'name': 'Adam', 'learning_rate': 0.02239999999999992, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0224>\n",
      "epoch0loss:5929023.5\n",
      "epoch1loss:4898788.0\n",
      "epoch2loss:3921799.2\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F342B0>\n",
      "{'name': 'Adam', 'learning_rate': 0.02249999999999992, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0225>\n",
      "epoch0loss:5923790.0\n",
      "epoch1loss:4886855.0\n",
      "epoch2loss:3906327.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F26430>\n",
      "{'name': 'Adam', 'learning_rate': 0.02259999999999992, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0226>\n",
      "epoch0loss:5918541.0\n",
      "epoch1loss:4874911.0\n",
      "epoch2loss:3890909.2\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED3619F370>\n",
      "{'name': 'Adam', 'learning_rate': 0.022699999999999918, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0227>\n",
      "epoch0loss:5913279.0\n",
      "epoch1loss:4862955.0\n",
      "epoch2loss:3875548.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F1A580>\n",
      "{'name': 'Adam', 'learning_rate': 0.022799999999999918, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0228>\n",
      "epoch0loss:5908000.5\n",
      "epoch1loss:4850989.0\n",
      "epoch2loss:3860241.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F3DB80>\n",
      "{'name': 'Adam', 'learning_rate': 0.022899999999999917, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0229>\n",
      "epoch0loss:5902709.5\n",
      "epoch1loss:4839012.5\n",
      "epoch2loss:3844993.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED3619FBE0>\n",
      "{'name': 'Adam', 'learning_rate': 0.022999999999999916, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.023>\n",
      "epoch0loss:5897403.5\n",
      "epoch1loss:4827026.5\n",
      "epoch2loss:3829805.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F26970>\n",
      "{'name': 'Adam', 'learning_rate': 0.023099999999999916, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0231>\n",
      "epoch0loss:5892083.0\n",
      "epoch1loss:4815031.0\n",
      "epoch2loss:3814677.8\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED3619F5E0>\n",
      "{'name': 'Adam', 'learning_rate': 0.023199999999999915, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0232>\n",
      "epoch0loss:5886748.5\n",
      "epoch1loss:4803027.0\n",
      "epoch2loss:3799612.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED361AC2B0>\n",
      "{'name': 'Adam', 'learning_rate': 0.023299999999999915, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0233>\n",
      "epoch0loss:5881398.5\n",
      "epoch1loss:4791013.0\n",
      "epoch2loss:3784611.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F3DB20>\n",
      "{'name': 'Adam', 'learning_rate': 0.023399999999999914, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0234>\n",
      "epoch0loss:5876036.0\n",
      "epoch1loss:4778991.0\n",
      "epoch2loss:3769675.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F34370>\n",
      "{'name': 'Adam', 'learning_rate': 0.023499999999999913, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0235>\n",
      "epoch0loss:5870659.5\n",
      "epoch1loss:4766964.0\n",
      "epoch2loss:3754805.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED361AC8E0>\n",
      "{'name': 'Adam', 'learning_rate': 0.023599999999999913, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0236>\n",
      "epoch0loss:5865269.5\n",
      "epoch1loss:4754927.5\n",
      "epoch2loss:3740004.2\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F26A30>\n",
      "{'name': 'Adam', 'learning_rate': 0.023699999999999912, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0237>\n",
      "epoch0loss:5859863.5\n",
      "epoch1loss:4742884.0\n",
      "epoch2loss:3725273.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED3619F280>\n",
      "{'name': 'Adam', 'learning_rate': 0.02379999999999991, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0238>\n",
      "epoch0loss:5854445.0\n",
      "epoch1loss:4730834.5\n",
      "epoch2loss:3710612.8\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36193E20>\n",
      "{'name': 'Adam', 'learning_rate': 0.02389999999999991, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0239>\n",
      "epoch0loss:5849012.0\n",
      "epoch1loss:4718780.0\n",
      "epoch2loss:3696025.2\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F34A60>\n",
      "{'name': 'Adam', 'learning_rate': 0.02399999999999991, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.024>\n",
      "epoch0loss:5843565.5\n",
      "epoch1loss:4706719.0\n",
      "epoch2loss:3681512.2\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED361AC4F0>\n",
      "{'name': 'Adam', 'learning_rate': 0.02409999999999991, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0241>\n",
      "epoch0loss:5838105.0\n",
      "epoch1loss:4694654.0\n",
      "epoch2loss:3667074.2\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36193EB0>\n",
      "{'name': 'Adam', 'learning_rate': 0.02419999999999991, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0242>\n",
      "epoch0loss:5832630.5\n",
      "epoch1loss:4682584.0\n",
      "epoch2loss:3652713.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F1AF40>\n",
      "{'name': 'Adam', 'learning_rate': 0.02429999999999991, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0243>\n",
      "epoch0loss:5827143.0\n",
      "epoch1loss:4670509.5\n",
      "epoch2loss:3638432.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F34CD0>\n",
      "{'name': 'Adam', 'learning_rate': 0.024399999999999908, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0244>\n",
      "epoch0loss:5821642.0\n",
      "epoch1loss:4658431.0\n",
      "epoch2loss:3624230.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED30C536A0>\n",
      "{'name': 'Adam', 'learning_rate': 0.024499999999999907, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0245>\n",
      "epoch0loss:5816127.0\n",
      "epoch1loss:4646350.5\n",
      "epoch2loss:3610110.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36193970>\n",
      "{'name': 'Adam', 'learning_rate': 0.024599999999999907, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0246>\n",
      "epoch0loss:5810597.0\n",
      "epoch1loss:4634267.5\n",
      "epoch2loss:3596073.8\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED361AC820>\n",
      "{'name': 'Adam', 'learning_rate': 0.024699999999999906, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0247>\n",
      "epoch0loss:5805055.0\n",
      "epoch1loss:4622180.5\n",
      "epoch2loss:3582121.8\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F1AF40>\n",
      "{'name': 'Adam', 'learning_rate': 0.024799999999999905, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0248>\n",
      "epoch0loss:5799500.5\n",
      "epoch1loss:4610093.0\n",
      "epoch2loss:3568257.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED30C53970>\n",
      "{'name': 'Adam', 'learning_rate': 0.024899999999999905, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0249>\n",
      "epoch0loss:5793931.5\n",
      "epoch1loss:4598003.0\n",
      "epoch2loss:3554479.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F3D250>\n",
      "{'name': 'Adam', 'learning_rate': 0.024999999999999904, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.025>\n",
      "epoch0loss:5788350.0\n",
      "epoch1loss:4585913.0\n",
      "epoch2loss:3540790.8\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F4B610>\n",
      "{'name': 'Adam', 'learning_rate': 0.025099999999999904, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0251>\n",
      "epoch0loss:5782754.0\n",
      "epoch1loss:4573821.5\n",
      "epoch2loss:3527194.2\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F260A0>\n",
      "{'name': 'Adam', 'learning_rate': 0.025199999999999903, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0252>\n",
      "epoch0loss:5777145.5\n",
      "epoch1loss:4561732.0\n",
      "epoch2loss:3513690.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36193E20>\n",
      "{'name': 'Adam', 'learning_rate': 0.025299999999999902, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0253>\n",
      "epoch0loss:5771523.5\n",
      "epoch1loss:4549641.0\n",
      "epoch2loss:3500279.8\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F34100>\n",
      "{'name': 'Adam', 'learning_rate': 0.025399999999999902, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0254>\n",
      "epoch0loss:5765888.5\n",
      "epoch1loss:4537552.0\n",
      "epoch2loss:3486965.2\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED309A6250>\n",
      "{'name': 'Adam', 'learning_rate': 0.0254999999999999, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0255>\n",
      "epoch0loss:5760240.0\n",
      "epoch1loss:4525464.5\n",
      "epoch2loss:3473749.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F4BFD0>\n",
      "{'name': 'Adam', 'learning_rate': 0.0255999999999999, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0256>\n",
      "epoch0loss:5754579.5\n",
      "epoch1loss:4513378.0\n",
      "epoch2loss:3460630.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F4B0D0>\n",
      "{'name': 'Adam', 'learning_rate': 0.0256999999999999, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0257>\n",
      "epoch0loss:5748906.5\n",
      "epoch1loss:4501293.5\n",
      "epoch2loss:3447613.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED309A62B0>\n",
      "{'name': 'Adam', 'learning_rate': 0.0257999999999999, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0258>\n",
      "epoch0loss:5743220.5\n",
      "epoch1loss:4489212.0\n",
      "epoch2loss:3434697.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36193820>\n",
      "{'name': 'Adam', 'learning_rate': 0.0258999999999999, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0259>\n",
      "epoch0loss:5737520.0\n",
      "epoch1loss:4477133.5\n",
      "epoch2loss:3421886.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED361AC7C0>\n",
      "{'name': 'Adam', 'learning_rate': 0.025999999999999898, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.026>\n",
      "epoch0loss:5731807.5\n",
      "epoch1loss:4465060.5\n",
      "epoch2loss:3409180.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36193C40>\n",
      "{'name': 'Adam', 'learning_rate': 0.026099999999999898, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0261>\n",
      "epoch0loss:5726083.5\n",
      "epoch1loss:4452991.0\n",
      "epoch2loss:3396581.2\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED309A6D00>\n",
      "{'name': 'Adam', 'learning_rate': 0.026199999999999897, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0262>\n",
      "epoch0loss:5720345.5\n",
      "epoch1loss:4440925.0\n",
      "epoch2loss:3384089.8\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED361AC370>\n",
      "{'name': 'Adam', 'learning_rate': 0.026299999999999896, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0263>\n",
      "epoch0loss:5714595.5\n",
      "epoch1loss:4428866.0\n",
      "epoch2loss:3371709.2\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F4BBE0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Adam', 'learning_rate': 0.026399999999999896, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0264>\n",
      "epoch0loss:5708833.0\n",
      "epoch1loss:4416811.5\n",
      "epoch2loss:3359441.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36193520>\n",
      "{'name': 'Adam', 'learning_rate': 0.026499999999999895, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0265>\n",
      "epoch0loss:5703057.5\n",
      "epoch1loss:4404763.5\n",
      "epoch2loss:3347286.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F34280>\n",
      "{'name': 'Adam', 'learning_rate': 0.026599999999999895, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0266>\n",
      "epoch0loss:5697270.0\n",
      "epoch1loss:4392721.5\n",
      "epoch2loss:3335246.2\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED309A6190>\n",
      "{'name': 'Adam', 'learning_rate': 0.026699999999999894, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0267>\n",
      "epoch0loss:5691470.5\n",
      "epoch1loss:4380687.0\n",
      "epoch2loss:3323323.8\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED361ACF40>\n",
      "{'name': 'Adam', 'learning_rate': 0.026799999999999893, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0268>\n",
      "epoch0loss:5685657.5\n",
      "epoch1loss:4368661.0\n",
      "epoch2loss:3311519.8\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F34E50>\n",
      "{'name': 'Adam', 'learning_rate': 0.026899999999999893, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0269>\n",
      "epoch0loss:5679833.0\n",
      "epoch1loss:4356642.0\n",
      "epoch2loss:3299834.2\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED361931C0>\n",
      "{'name': 'Adam', 'learning_rate': 0.026999999999999892, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.027>\n",
      "epoch0loss:5673996.5\n",
      "epoch1loss:4344631.0\n",
      "epoch2loss:3288272.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F4BF70>\n",
      "{'name': 'Adam', 'learning_rate': 0.02709999999999989, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0271>\n",
      "epoch0loss:5668146.5\n",
      "epoch1loss:4332631.0\n",
      "epoch2loss:3276833.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F26A00>\n",
      "{'name': 'Adam', 'learning_rate': 0.02719999999999989, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0272>\n",
      "epoch0loss:5662286.0\n",
      "epoch1loss:4320639.5\n",
      "epoch2loss:3265519.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED30C53CA0>\n",
      "{'name': 'Adam', 'learning_rate': 0.02729999999999989, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0273>\n",
      "epoch0loss:5656413.5\n",
      "epoch1loss:4308658.5\n",
      "epoch2loss:3254332.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F4BBB0>\n",
      "{'name': 'Adam', 'learning_rate': 0.02739999999999989, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0274>\n",
      "epoch0loss:5650527.5\n",
      "epoch1loss:4296688.5\n",
      "epoch2loss:3243274.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36193580>\n",
      "{'name': 'Adam', 'learning_rate': 0.02749999999999989, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0275>\n",
      "epoch0loss:5644632.0\n",
      "epoch1loss:4284728.5\n",
      "epoch2loss:3232346.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED309A6F70>\n",
      "{'name': 'Adam', 'learning_rate': 0.02759999999999989, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0276>\n",
      "epoch0loss:5638722.0\n",
      "epoch1loss:4272780.0\n",
      "epoch2loss:3221550.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F26A00>\n",
      "{'name': 'Adam', 'learning_rate': 0.027699999999999888, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0277>\n",
      "epoch0loss:5632802.5\n",
      "epoch1loss:4260844.0\n",
      "epoch2loss:3210887.2\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F3D400>\n",
      "{'name': 'Adam', 'learning_rate': 0.027799999999999887, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0278>\n",
      "epoch0loss:5626870.0\n",
      "epoch1loss:4248921.5\n",
      "epoch2loss:3200361.2\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36193370>\n",
      "{'name': 'Adam', 'learning_rate': 0.027899999999999887, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0279>\n",
      "epoch0loss:5620926.5\n",
      "epoch1loss:4237011.5\n",
      "epoch2loss:3189971.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F34CA0>\n",
      "{'name': 'Adam', 'learning_rate': 0.027999999999999886, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.028>\n",
      "epoch0loss:5614970.5\n",
      "epoch1loss:4225115.0\n",
      "epoch2loss:3179720.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED309A69A0>\n",
      "{'name': 'Adam', 'learning_rate': 0.028099999999999885, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0281>\n",
      "epoch0loss:5609003.0\n",
      "epoch1loss:4213232.5\n",
      "epoch2loss:3169609.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F3DD30>\n",
      "{'name': 'Adam', 'learning_rate': 0.028199999999999885, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0282>\n",
      "epoch0loss:5603023.5\n",
      "epoch1loss:4201364.5\n",
      "epoch2loss:3159641.2\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED30C538E0>\n",
      "{'name': 'Adam', 'learning_rate': 0.028299999999999884, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0283>\n",
      "epoch0loss:5597034.5\n",
      "epoch1loss:4189512.0\n",
      "epoch2loss:3149817.2\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED3619FA60>\n",
      "{'name': 'Adam', 'learning_rate': 0.028399999999999884, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0284>\n",
      "epoch0loss:5591033.0\n",
      "epoch1loss:4177675.2\n",
      "epoch2loss:3140139.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED309A6550>\n",
      "{'name': 'Adam', 'learning_rate': 0.028499999999999883, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0285>\n",
      "epoch0loss:5585019.0\n",
      "epoch1loss:4165854.5\n",
      "epoch2loss:3130608.8\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED30C533D0>\n",
      "{'name': 'Adam', 'learning_rate': 0.028599999999999882, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0286>\n",
      "epoch0loss:5578996.0\n",
      "epoch1loss:4154050.2\n",
      "epoch2loss:3121227.8\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F3DEB0>\n",
      "{'name': 'Adam', 'learning_rate': 0.028699999999999882, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0287>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0loss:5572961.0\n",
      "epoch1loss:4142263.8\n",
      "epoch2loss:3111997.8\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F26340>\n",
      "{'name': 'Adam', 'learning_rate': 0.02879999999999988, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0288>\n",
      "epoch0loss:5566914.0\n",
      "epoch1loss:4130494.0\n",
      "epoch2loss:3102920.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F34340>\n",
      "{'name': 'Adam', 'learning_rate': 0.02889999999999988, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0289>\n",
      "epoch0loss:5560857.0\n",
      "epoch1loss:4118743.2\n",
      "epoch2loss:3093998.8\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F1A940>\n",
      "{'name': 'Adam', 'learning_rate': 0.02899999999999988, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.029>\n",
      "epoch0loss:5554788.5\n",
      "epoch1loss:4107012.2\n",
      "epoch2loss:3085232.8\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36193BE0>\n",
      "{'name': 'Adam', 'learning_rate': 0.02909999999999988, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0291>\n",
      "epoch0loss:5548708.5\n",
      "epoch1loss:4095299.8\n",
      "epoch2loss:3076624.8\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED3619FFA0>\n",
      "{'name': 'Adam', 'learning_rate': 0.02919999999999988, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0292>\n",
      "epoch0loss:5542619.0\n",
      "epoch1loss:4083606.2\n",
      "epoch2loss:3068165.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F11A60>\n",
      "{'name': 'Adam', 'learning_rate': 0.029299999999999878, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0293>\n",
      "epoch0loss:5536517.5\n",
      "epoch1loss:4071933.8\n",
      "epoch2loss:3059849.2\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F11FD0>\n",
      "{'name': 'Adam', 'learning_rate': 0.029399999999999878, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0294>\n",
      "epoch0loss:5530404.5\n",
      "epoch1loss:4060282.5\n",
      "epoch2loss:3051706.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F3D790>\n",
      "{'name': 'Adam', 'learning_rate': 0.029499999999999877, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0295>\n",
      "epoch0loss:5524284.0\n",
      "epoch1loss:4048652.5\n",
      "epoch2loss:3043726.2\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F267C0>\n",
      "{'name': 'Adam', 'learning_rate': 0.029599999999999876, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0296>\n",
      "epoch0loss:5518149.0\n",
      "epoch1loss:4037044.5\n",
      "epoch2loss:3035909.8\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ECA179D850>\n",
      "{'name': 'Adam', 'learning_rate': 0.029699999999999876, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0297>\n",
      "epoch0loss:5512005.0\n",
      "epoch1loss:4025458.5\n",
      "epoch2loss:3028260.8\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F26F10>\n",
      "{'name': 'Adam', 'learning_rate': 0.029799999999999875, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0298>\n",
      "epoch0loss:5505850.5\n",
      "epoch1loss:4013896.0\n",
      "epoch2loss:3020772.8\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F26D60>\n",
      "{'name': 'Adam', 'learning_rate': 0.029899999999999875, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0299>\n",
      "epoch0loss:5499686.0\n",
      "epoch1loss:4002358.0\n",
      "epoch2loss:3013420.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F1A970>\n",
      "{'name': 'Adam', 'learning_rate': 0.029999999999999874, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.03>\n",
      "epoch0loss:5493511.5\n",
      "epoch1loss:3990843.0\n",
      "epoch2loss:3006254.2\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F3D970>\n",
      "{'name': 'Adam', 'learning_rate': 0.030099999999999873, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0301>\n",
      "epoch0loss:5487324.5\n",
      "epoch1loss:3979353.5\n",
      "epoch2loss:2999288.8\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F34520>\n",
      "{'name': 'Adam', 'learning_rate': 0.030199999999999873, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0302>\n",
      "epoch0loss:5481129.0\n",
      "epoch1loss:3967888.2\n",
      "epoch2loss:2992499.8\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED3619F880>\n",
      "{'name': 'Adam', 'learning_rate': 0.030299999999999872, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0303>\n",
      "epoch0loss:5474922.0\n",
      "epoch1loss:3956449.5\n",
      "epoch2loss:2985894.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F11040>\n",
      "{'name': 'Adam', 'learning_rate': 0.03039999999999987, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0304>\n",
      "epoch0loss:5468706.0\n",
      "epoch1loss:3945036.5\n",
      "epoch2loss:2979472.8\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F1AB50>\n",
      "{'name': 'Adam', 'learning_rate': 0.03049999999999987, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0305>\n",
      "epoch0loss:5462480.5\n",
      "epoch1loss:3933651.0\n",
      "epoch2loss:2973220.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F3DE20>\n",
      "{'name': 'Adam', 'learning_rate': 0.03059999999999987, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0306>\n",
      "epoch0loss:5456244.0\n",
      "epoch1loss:3922292.8\n",
      "epoch2loss:2967143.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F26610>\n",
      "{'name': 'Adam', 'learning_rate': 0.03069999999999987, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0307>\n",
      "epoch0loss:5449997.0\n",
      "epoch1loss:3910963.2\n",
      "epoch2loss:2961227.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F4BDC0>\n",
      "{'name': 'Adam', 'learning_rate': 0.03079999999999987, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0308>\n",
      "epoch0loss:5443741.5\n",
      "epoch1loss:3899660.8\n",
      "epoch2loss:2955434.8\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F11970>\n",
      "{'name': 'Adam', 'learning_rate': 0.03089999999999987, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0309>\n",
      "epoch0loss:5437474.0\n",
      "epoch1loss:3888388.0\n",
      "epoch2loss:2949804.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F348B0>\n",
      "{'name': 'Adam', 'learning_rate': 0.030999999999999868, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.031>\n",
      "epoch0loss:5431199.0\n",
      "epoch1loss:3877145.5\n",
      "epoch2loss:2944373.2\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED30C53F70>\n",
      "{'name': 'Adam', 'learning_rate': 0.031099999999999867, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0311>\n",
      "epoch0loss:5424913.0\n",
      "epoch1loss:3865932.8\n",
      "epoch2loss:2939177.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F4B3D0>\n",
      "{'name': 'Adam', 'learning_rate': 0.031199999999999867, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0312>\n",
      "epoch0loss:5418618.0\n",
      "epoch1loss:3854750.8\n",
      "epoch2loss:2934096.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED3619F940>\n",
      "{'name': 'Adam', 'learning_rate': 0.03129999999999987, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0313>\n",
      "epoch0loss:5412313.5\n",
      "epoch1loss:3843600.5\n",
      "epoch2loss:2929100.8\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F11A60>\n",
      "{'name': 'Adam', 'learning_rate': 0.03139999999999987, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0314>\n",
      "epoch0loss:5405998.5\n",
      "epoch1loss:3832481.8\n",
      "epoch2loss:2924241.2\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F26100>\n",
      "{'name': 'Adam', 'learning_rate': 0.031499999999999875, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0315>\n",
      "epoch0loss:5399674.5\n",
      "epoch1loss:3821395.0\n",
      "epoch2loss:2919477.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED30C533A0>\n",
      "{'name': 'Adam', 'learning_rate': 0.03159999999999988, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0316>\n",
      "epoch0loss:5393342.0\n",
      "epoch1loss:3810342.5\n",
      "epoch2loss:2914932.8\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36193BB0>\n",
      "{'name': 'Adam', 'learning_rate': 0.03169999999999988, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0317>\n",
      "epoch0loss:5386999.0\n",
      "epoch1loss:3799323.0\n",
      "epoch2loss:2910537.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F34040>\n",
      "{'name': 'Adam', 'learning_rate': 0.031799999999999884, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0318>\n",
      "epoch0loss:5380647.0\n",
      "epoch1loss:3788337.5\n",
      "epoch2loss:2906351.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F26550>\n",
      "{'name': 'Adam', 'learning_rate': 0.03189999999999989, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0319>\n",
      "epoch0loss:5374287.0\n",
      "epoch1loss:3777386.5\n",
      "epoch2loss:2902403.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED3619FA60>\n",
      "{'name': 'Adam', 'learning_rate': 0.03199999999999989, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.032>\n",
      "epoch0loss:5367916.5\n",
      "epoch1loss:3766471.8\n",
      "epoch2loss:2898554.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F4B3D0>\n",
      "{'name': 'Adam', 'learning_rate': 0.03209999999999989, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0321>\n",
      "epoch0loss:5361537.5\n",
      "epoch1loss:3755593.2\n",
      "epoch2loss:2894501.8\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F34040>\n",
      "{'name': 'Adam', 'learning_rate': 0.032199999999999895, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0322>\n",
      "epoch0loss:5355149.5\n",
      "epoch1loss:3744749.5\n",
      "epoch2loss:2890673.8\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED361ACB20>\n",
      "{'name': 'Adam', 'learning_rate': 0.0322999999999999, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0323>\n",
      "epoch0loss:5348753.0\n",
      "epoch1loss:3733944.2\n",
      "epoch2loss:2886940.2\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F11490>\n",
      "{'name': 'Adam', 'learning_rate': 0.0323999999999999, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0324>\n",
      "epoch0loss:5342345.5\n",
      "epoch1loss:3723176.0\n",
      "epoch2loss:2883310.8\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED3619FE80>\n",
      "{'name': 'Adam', 'learning_rate': 0.032499999999999904, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0325>\n",
      "epoch0loss:5335932.0\n",
      "epoch1loss:3712446.8\n",
      "epoch2loss:2879741.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F3D460>\n",
      "{'name': 'Adam', 'learning_rate': 0.03259999999999991, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0326>\n",
      "epoch0loss:5329508.5\n",
      "epoch1loss:3701755.0\n",
      "epoch2loss:2876380.8\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F4B7C0>\n",
      "{'name': 'Adam', 'learning_rate': 0.03269999999999991, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0327>\n",
      "epoch0loss:5323075.5\n",
      "epoch1loss:3691104.0\n",
      "epoch2loss:2873234.8\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED361AC5B0>\n",
      "{'name': 'Adam', 'learning_rate': 0.03279999999999991, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0328>\n",
      "epoch0loss:5316635.5\n",
      "epoch1loss:3680492.0\n",
      "epoch2loss:2870092.8\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED361B4340>\n",
      "{'name': 'Adam', 'learning_rate': 0.032899999999999915, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0329>\n",
      "epoch0loss:5310186.0\n",
      "epoch1loss:3669921.2\n",
      "epoch2loss:2866940.2\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED309A6B20>\n",
      "{'name': 'Adam', 'learning_rate': 0.03299999999999992, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.033>\n",
      "epoch0loss:5303728.5\n",
      "epoch1loss:3659391.8\n",
      "epoch2loss:2863888.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED30C53F40>\n",
      "{'name': 'Adam', 'learning_rate': 0.03309999999999992, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0331>\n",
      "epoch0loss:5297263.0\n",
      "epoch1loss:3648903.2\n",
      "epoch2loss:2860736.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F4BCA0>\n",
      "{'name': 'Adam', 'learning_rate': 0.033199999999999924, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0332>\n",
      "epoch0loss:5290788.0\n",
      "epoch1loss:3638458.2\n",
      "epoch2loss:2857609.2\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F4BA00>\n",
      "{'name': 'Adam', 'learning_rate': 0.03329999999999993, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0333>\n",
      "epoch0loss:5284306.0\n",
      "epoch1loss:3628055.5\n",
      "epoch2loss:2854471.2\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED361ACB80>\n",
      "{'name': 'Adam', 'learning_rate': 0.03339999999999993, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0334>\n",
      "epoch0loss:5277816.0\n",
      "epoch1loss:3617696.5\n",
      "epoch2loss:2851628.8\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED309A6310>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Adam', 'learning_rate': 0.03349999999999993, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0335>\n",
      "epoch0loss:5271315.5\n",
      "epoch1loss:3607381.8\n",
      "epoch2loss:2848781.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED309A69D0>\n",
      "{'name': 'Adam', 'learning_rate': 0.033599999999999935, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0336>\n",
      "epoch0loss:5264811.0\n",
      "epoch1loss:3597111.5\n",
      "epoch2loss:2845857.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED30C539D0>\n",
      "{'name': 'Adam', 'learning_rate': 0.03369999999999994, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0337>\n",
      "epoch0loss:5258295.0\n",
      "epoch1loss:3586887.2\n",
      "epoch2loss:2843091.2\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F342B0>\n",
      "{'name': 'Adam', 'learning_rate': 0.03379999999999994, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0338>\n",
      "epoch0loss:5251772.5\n",
      "epoch1loss:3576708.5\n",
      "epoch2loss:2840162.2\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED309A62B0>\n",
      "{'name': 'Adam', 'learning_rate': 0.033899999999999944, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0339>\n",
      "epoch0loss:5245242.0\n",
      "epoch1loss:3566576.8\n",
      "epoch2loss:2836836.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED361ACA00>\n",
      "{'name': 'Adam', 'learning_rate': 0.03399999999999995, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.034>\n",
      "epoch0loss:5238703.5\n",
      "epoch1loss:3556491.0\n",
      "epoch2loss:2833842.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED3619F9D0>\n",
      "{'name': 'Adam', 'learning_rate': 0.03409999999999995, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0341>\n",
      "epoch0loss:5232158.0\n",
      "epoch1loss:3546454.5\n",
      "epoch2loss:2830745.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F34160>\n",
      "{'name': 'Adam', 'learning_rate': 0.03419999999999995, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0342>\n",
      "epoch0loss:5225604.0\n",
      "epoch1loss:3536465.8\n",
      "epoch2loss:2827119.2\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED3619FEB0>\n",
      "{'name': 'Adam', 'learning_rate': 0.034299999999999956, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0343>\n",
      "epoch0loss:5219043.0\n",
      "epoch1loss:3526526.8\n",
      "epoch2loss:2824078.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED3619FEE0>\n",
      "{'name': 'Adam', 'learning_rate': 0.03439999999999996, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0344>\n",
      "epoch0loss:5212475.5\n",
      "epoch1loss:3516636.2\n",
      "epoch2loss:2820259.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED309A6040>\n",
      "{'name': 'Adam', 'learning_rate': 0.03449999999999996, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0345>\n",
      "epoch0loss:5205900.0\n",
      "epoch1loss:3506797.2\n",
      "epoch2loss:2816086.2\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED30C53250>\n",
      "{'name': 'Adam', 'learning_rate': 0.034599999999999964, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0346>\n",
      "epoch0loss:5199314.5\n",
      "epoch1loss:3497008.5\n",
      "epoch2loss:2812613.0\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F3DF40>\n",
      "{'name': 'Adam', 'learning_rate': 0.03469999999999997, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0347>\n",
      "epoch0loss:5192725.0\n",
      "epoch1loss:3487270.8\n",
      "epoch2loss:2808955.2\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED3619F280>\n",
      "{'name': 'Adam', 'learning_rate': 0.03479999999999997, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0348>\n",
      "epoch0loss:5186126.0\n",
      "epoch1loss:3477586.2\n",
      "epoch2loss:2805138.2\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED30C530A0>\n",
      "{'name': 'Adam', 'learning_rate': 0.03489999999999997, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0349>\n",
      "epoch0loss:5179520.5\n",
      "epoch1loss:3467954.0\n",
      "epoch2loss:2800681.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F26730>\n",
      "{'name': 'Adam', 'learning_rate': 0.034999999999999976, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.035>\n",
      "epoch0loss:5172909.0\n",
      "epoch1loss:3458374.2\n",
      "epoch2loss:2796087.5\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED36F341C0>\n",
      "{'name': 'Adam', 'learning_rate': 0.03509999999999998, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0351>\n",
      "epoch0loss:5166289.5\n",
      "epoch1loss:3448849.5\n",
      "epoch2loss:2791930.2\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x000001ED3619F280>\n",
      "{'name': 'Adam', 'learning_rate': 0.03519999999999998, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0352>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-83d0e3e96861>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'lrFinderNeu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_splitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0mcsv_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsvfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlearning_rate_step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-e36c8541a87e>\u001b[0m in \u001b[0;36mtrain_splitted\u001b[1;34m(self, epochs, optimizer)\u001b[0m\n\u001b[0;32m     92\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzeilen\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mspalten\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m                     train = optimizer.minimize(self.loss, var_list=[self.tf_bias,self.tf_context_bias,\n\u001b[0m\u001b[0;32m     95\u001b[0m                                                               self.tf_weights,self.tf_context_weights])\n\u001b[0;32m     96\u001b[0m                     \u001b[0mcur_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(self, loss, var_list, grad_loss, name, tape)\u001b[0m\n\u001b[0;32m    526\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m     \"\"\"\n\u001b[1;32m--> 528\u001b[1;33m     grads_and_vars = self._compute_gradients(\n\u001b[0m\u001b[0;32m    529\u001b[0m         loss, var_list=var_list, grad_loss=grad_loss, tape=tape)\n\u001b[0;32m    530\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36m_compute_gradients\u001b[1;34m(self, loss, var_list, grad_loss, tape)\u001b[0m\n\u001b[0;32m    578\u001b[0m     \u001b[0mvar_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/gradients\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mgrads_and_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     self._assert_valid_dtypes([\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36m_get_gradients\u001b[1;34m(self, tape, loss, var_list, grad_loss)\u001b[0m\n\u001b[0;32m    471\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_get_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    472\u001b[0m     \u001b[1;34m\"\"\"Called in `minimize` to compute gradients from loss.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m     \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    474\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    475\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1072\u001b[0m                           for x in nest.flatten(output_gradients)]\n\u001b[0;32m   1073\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1074\u001b[1;33m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[0;32m   1075\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1076\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[0;32m     72\u001b[0m       \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[0mThe\u001b[0m \u001b[0mgradients\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mrespect\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minputs\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m   \"\"\"\n\u001b[1;32m--> 147\u001b[1;33m   \u001b[0mmock_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_MockOp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattr_tuple\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskip_input_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    148\u001b[0m   \u001b[0mgrad_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gradient_registry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlookup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_name\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mgrad_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vocab = Vocabulary()\n",
    "vocab.load('../vocabs/text8_filtered100')\n",
    "vocab_size = len(vocab.word2Id)\n",
    "csv_writer = CSV_writer('lrFinderNeu','a+')\n",
    "\n",
    "learning_rate_step = 0.0001\n",
    "lr =  0.0352#init\n",
    "#tf.keras.optimizers.Adam(),tf.keras.optimizers.Adamax(),tf.keras.optimizers.RMSprop(),tf.keras.optimizers.Adadelta(),tf.keras.optimizers.Adagrad(),tf.keras.optimizers.Ftrl(),tf.keras.optimizers.Nadam(),tf.keras.optimizers.SGD()]\n",
    "    \n",
    "\n",
    "while lr < 0.3:\n",
    "    tf.keras.backend.clear_session()\n",
    "    opt = tf.keras.optimizers.Adam()\n",
    "    print(opt)\n",
    "    trainer = ModelTrainer(vocab,1)\n",
    "    opt.learning_rate = lr\n",
    "    trainer.prepare('lrFinderNeu')\n",
    "    print(opt.get_config())\n",
    "    trainer.train_splitted(3,opt)\n",
    "    csv_writer.csvfile.flush()\n",
    "    lr = lr + learning_rate_step\n",
    "\n",
    "csv_writer.csvfile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d50852",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
