{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2873f882",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04c2c2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "path = r'C:\\\\Users\\\\weso\\\\Desktop\\\\glove.6B\\\\'\n",
    "id_dict = {}\n",
    "word_dict = {}\n",
    "\n",
    "matrix = []\n",
    "dimensions = 300\n",
    "with open(path + \"glove.6B.300d.txt\", 'r' , encoding=\"utf-8\")  as f:\n",
    "    lines = f.readlines()\n",
    "    vocab_size = len(lines)\n",
    "    \n",
    "    matrix = np.zeros((vocab_size,dimensions),dtype=float)\n",
    "    for line in lines:\n",
    "        values = line.split()\n",
    "        word = values[0].strip()\n",
    "        id = len(id_dict)\n",
    "        id_dict[word]=id\n",
    "        word_dict[id] = word\n",
    "        vector = np.asarray(values[1:], \"double\")\n",
    "        matrix[id_dict[word],:] = vector\n",
    "print(len(id_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a21edb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(word_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6e185c",
   "metadata": {},
   "source": [
    "## 3cosAdd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbceec31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d75b0f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_normalized = tf.nn.l2_normalize(matrix,axis = 1)\n",
    "def three_cos_predict_np(a,a_star,b,b_star):\n",
    "    if( a in id_dict and b in id_dict and a_star in id_dict and b_star in id_dict):\n",
    "        pass\n",
    "    else:\n",
    "        return None\n",
    "    id_a = id_dict[a]\n",
    "    id_b = id_dict[b]\n",
    "    id_a_star = id_dict[a_star]\n",
    "    id_b_star = id_dict[b_star]#remove this after testing\n",
    "    weight_a = matrix[id_a,:]\n",
    "    weight_b = matrix[id_b,:]\n",
    "    weight_a_star = matrix[id_a_star,:]\n",
    "    direction = weight_b + ( weight_a_star - weight_a)\n",
    "    direction /= np.linalg.norm(direction)\n",
    "    \n",
    "    sim = tf.tensordot(tf.convert_to_tensor(matrix_normalized),tf.convert_to_tensor(direction),axes = 1)\n",
    "    myList = [id_a, id_b, id_a_star];\n",
    "    myList.sort();\n",
    "    index1 = np.argmax(sim[:myList[0]])\n",
    "    sim2 = sim[myList[0]+1:myList[1]]\n",
    "    if len(sim2) > 0:\n",
    "        index2 = np.argmax(sim[myList[0]+1:myList[1]])\n",
    "        index2 +=  myList[0]+1\n",
    "    else:\n",
    "        index2 = None\n",
    "    sim3 = sim[myList[1]+1:myList[2]]\n",
    "    if len(sim3) > 0:\n",
    "        index3 = np.argmax(sim[myList[1]+1:myList[2]])\n",
    "        index3 +=  myList[1]+1\n",
    "    else:\n",
    "        index3 = None\n",
    "    index4 = np.argmax(sim[myList[2]+1:])\n",
    "    index4 +=  myList[2]+1\n",
    "    \n",
    "    myList = [index1, index2, index3,index4];\n",
    "    values = []\n",
    "    myList2 = []\n",
    "    for index in myList:\n",
    "        if index != None:\n",
    "            values.append(sim[index])\n",
    "            myList2.append(index)\n",
    "    index = myList2[np.argmax(values)]\n",
    "    \n",
    "    return word_dict[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e77754f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weaker\n",
      "larger\n",
      "paris\n",
      "four\n",
      "Execution time in seconds: 0.22805190086364746\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "startTime = time.time()\n",
    "\n",
    "print(three_cos_predict_np('small','smaller','weak','weaker'))\n",
    "print(three_cos_predict_np('big','bigger','small','smaller'))\n",
    "print(three_cos_predict_np('germany','berlin','france','paris'))\n",
    "print(three_cos_predict_np('one','two','three','four'))\n",
    "\n",
    "executionTime = (time.time() - startTime)\n",
    "print('Execution time in seconds: ' + str(executionTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7782cc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 13106\n",
      "1000 of 13106\n",
      "2000 of 13106\n",
      "3000 of 13106\n",
      "4000 of 13106\n",
      "5000 of 13106\n",
      "6000 of 13106\n",
      "7000 of 13106\n",
      "8000 of 13106\n",
      "9000 of 13106\n",
      "10000 of 13106\n",
      "11000 of 13106\n",
      "12000 of 13106\n",
      "13000 of 13106\n",
      "0.724858843277888\n"
     ]
    }
   ],
   "source": [
    "count_sucess = 0\n",
    "count_unsucessful = 0\n",
    "count_out_of_vocab = 0\n",
    "count_b = 0\n",
    "with open(r'..\\datasets\\miklov Analogies.txt') as file:\n",
    "    lines = file.readlines()\n",
    "    for index, line in enumerate(lines):\n",
    "        if(index % 1000 == 0):\n",
    "            print(str(index) + \" of \" + str(len(lines)))\n",
    "            \n",
    "        if line.startswith(\":\"):\n",
    "            pass\n",
    "        else:\n",
    "            a,a_star,b,b_star = line.split(\" \")\n",
    "            b_star = b_star.strip()#super important\n",
    "            \n",
    "            predicted = three_cos_predict_np(a,a_star,b,b_star)\n",
    "            if(predicted == None):\n",
    "                count_out_of_vocab += 1\n",
    "            elif(predicted == b_star):\n",
    "                count_sucess += 1\n",
    "            elif(predicted == b):\n",
    "                count_b += 1\n",
    "            else:\n",
    "                count_unsucessful += 1\n",
    "\n",
    "print(count_sucess/ len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6af3218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import winsound\n",
    "winsound.Beep(440, 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c305346a",
   "metadata": {},
   "source": [
    "normalised before exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "383f8d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_cos_predict_np_norm(a,a_star,b,b_star):\n",
    "    if( a in id_dict and b in id_dict and a_star in id_dict and b_star in id_dict):\n",
    "        pass\n",
    "    else:\n",
    "        return None\n",
    "    id_a = id_dict[a]\n",
    "    id_b = id_dict[b]\n",
    "    id_a_star = id_dict[a_star]\n",
    "    id_b_star = id_dict[b_star]#remove this after testing\n",
    "    weight_a = matrix_normalized[id_a,:]\n",
    "    weight_b = matrix_normalized[id_b,:]\n",
    "    weight_a_star = matrix_normalized[id_a_star,:]\n",
    "    direction = weight_b + ( weight_a_star - weight_a)\n",
    "    direction /= np.linalg.norm(direction)\n",
    "    \n",
    "    sim = tf.tensordot(tf.convert_to_tensor(matrix_normalized),tf.convert_to_tensor(direction),axes = 1)\n",
    "    myList = [id_a, id_b, id_a_star];\n",
    "    myList.sort();\n",
    "    index1 = np.argmax(sim[:myList[0]])\n",
    "    sim2 = sim[myList[0]+1:myList[1]]\n",
    "    if len(sim2) > 0:\n",
    "        index2 = np.argmax(sim[myList[0]+1:myList[1]])\n",
    "        index2 +=  myList[0]+1\n",
    "    else:\n",
    "        index2 = None\n",
    "    sim3 = sim[myList[1]+1:myList[2]]\n",
    "    if len(sim3) > 0:\n",
    "        index3 = np.argmax(sim[myList[1]+1:myList[2]])\n",
    "        index3 +=  myList[1]+1\n",
    "    else:\n",
    "        index3 = None\n",
    "    index4 = np.argmax(sim[myList[2]+1:])\n",
    "    index4 +=  myList[2]+1\n",
    "    \n",
    "    myList = [index1, index2, index3,index4];\n",
    "    values = []\n",
    "    myList2 = []\n",
    "    for index in myList:\n",
    "        if index != None:\n",
    "            values.append(sim[index])\n",
    "            myList2.append(index)\n",
    "    index = myList2[np.argmax(values)]\n",
    "    \n",
    "    return word_dict[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43ceb461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 13106\n",
      "1000 of 13106\n",
      "2000 of 13106\n",
      "3000 of 13106\n",
      "4000 of 13106\n",
      "5000 of 13106\n",
      "6000 of 13106\n",
      "7000 of 13106\n",
      "8000 of 13106\n",
      "9000 of 13106\n",
      "10000 of 13106\n",
      "11000 of 13106\n",
      "12000 of 13106\n",
      "13000 of 13106\n",
      "0.7239432321074317\n"
     ]
    }
   ],
   "source": [
    "count_sucess = 0\n",
    "count_unsucessful = 0\n",
    "count_out_of_vocab = 0\n",
    "count_b = 0\n",
    "with open(r'..\\datasets\\miklov Analogies.txt') as file:\n",
    "    lines = file.readlines()\n",
    "    for index, line in enumerate(lines):\n",
    "        if(index % 1000 == 0):\n",
    "            print(str(index) + \" of \" + str(len(lines)))\n",
    "            \n",
    "        if line.startswith(\":\"):\n",
    "            pass\n",
    "        else:\n",
    "            a,a_star,b,b_star = line.split(\" \")\n",
    "            b_star = b_star.strip()#super important\n",
    "            \n",
    "            predicted = three_cos_predict_np_norm(a,a_star,b,b_star)\n",
    "            if(predicted == None):\n",
    "                count_out_of_vocab += 1\n",
    "            elif(predicted == b_star):\n",
    "                count_sucess += 1\n",
    "            elif(predicted == b):\n",
    "                count_b += 1\n",
    "            else:\n",
    "                count_unsucessful += 1\n",
    "\n",
    "print(count_sucess/ len(lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4042c364",
   "metadata": {},
   "source": [
    "## 3cos Mult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ac07eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_01(matrix,weight):\n",
    "    tmp = tf.tensordot(matrix,weight,axes=1)\n",
    "    tmp = (tmp+1)/2.0\n",
    "    return tmp\n",
    "\n",
    "def predict_three_cos_mult(a,a_star,b,b_star):\n",
    "    if( a in id_dict and b in id_dict and a_star in id_dict and b_star in id_dict):\n",
    "        pass\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    id_a = id_dict[a]\n",
    "    id_b = id_dict[b]\n",
    "    id_a_star = id_dict[a_star]\n",
    "    \n",
    "    weight_a = matrix_normalized[id_a,:]\n",
    "    weight_b = matrix_normalized[id_b,:]\n",
    "    weight_a_star = matrix_normalized[id_a_star,:]\n",
    "    \n",
    "    nominator = sim_01(matrix_normalized,weight_a_star)\n",
    "    \n",
    "    nominator = nominator * sim_01(matrix_normalized,weight_b) \n",
    "    donominator = sim_01(matrix_normalized,weight_a) + 0.0001\n",
    "    sim = nominator / donominator\n",
    "    myList = [id_a, id_b, id_a_star];\n",
    "    myList.sort();\n",
    "    index1 = np.argmax(sim[:myList[0]])\n",
    "    sim2 = sim[myList[0]+1:myList[1]]\n",
    "    if len(sim2) > 0:\n",
    "        index2 = np.argmax(sim[myList[0]+1:myList[1]])\n",
    "        index2 +=  myList[0]+1\n",
    "    else:\n",
    "        index2 = None\n",
    "    sim3 = sim[myList[1]+1:myList[2]]\n",
    "    if len(sim3) > 0:\n",
    "        index3 = np.argmax(sim[myList[1]+1:myList[2]])\n",
    "        index3 +=  myList[1]+1\n",
    "    else:\n",
    "        index3 = None\n",
    "    index4 = np.argmax(sim[myList[2]+1:])\n",
    "    index4 +=  myList[2]+1\n",
    "    \n",
    "    myList = [index1, index2, index3,index4];\n",
    "    values = []\n",
    "    myList2 = []\n",
    "    for index in myList:\n",
    "        if index != None:\n",
    "            values.append(sim[index])\n",
    "            myList2.append(index)\n",
    "    index = myList2[np.argmax(values)]\n",
    "    \n",
    "    return word_dict[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5babfc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weaker\n",
      "larger\n",
      "paris\n",
      "four\n",
      "Execution time in seconds: 0.6551494598388672\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "startTime = time.time()\n",
    "\n",
    "print(predict_three_cos_mult('small','smaller','weak','weaker'))\n",
    "print(predict_three_cos_mult('big','bigger','small','smaller'))\n",
    "print(predict_three_cos_mult('germany','berlin','france','paris'))\n",
    "print(predict_three_cos_mult('one','two','three','four'))\n",
    "\n",
    "executionTime = (time.time() - startTime)\n",
    "print('Execution time in seconds: ' + str(executionTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eecd5ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 13106 => 0\n",
      "100 of 13106 => 98\n",
      "200 of 13106 => 193\n",
      "300 of 13106 => 287\n",
      "400 of 13106 => 385\n",
      "500 of 13106 => 477\n",
      "600 of 13106 => 575\n",
      "700 of 13106 => 669\n",
      "800 of 13106 => 762\n",
      "900 of 13106 => 854\n",
      "1000 of 13106 => 951\n",
      "1100 of 13106 => 1047\n",
      "1200 of 13106 => 1143\n",
      "1300 of 13106 => 1239\n",
      "1400 of 13106 => 1337\n",
      "1500 of 13106 => 1434\n",
      "1600 of 13106 => 1526\n",
      "1700 of 13106 => 1619\n",
      "1800 of 13106 => 1716\n",
      "1900 of 13106 => 1812\n",
      "2000 of 13106 => 1909\n",
      "2100 of 13106 => 2007\n",
      "2200 of 13106 => 2101\n",
      "2300 of 13106 => 2197\n",
      "2400 of 13106 => 2287\n",
      "2500 of 13106 => 2381\n",
      "2600 of 13106 => 2478\n",
      "2700 of 13106 => 2577\n",
      "2800 of 13106 => 2674\n",
      "2900 of 13106 => 2773\n",
      "3000 of 13106 => 2866\n",
      "3100 of 13106 => 2963\n",
      "3200 of 13106 => 3057\n",
      "3300 of 13106 => 3151\n",
      "3400 of 13106 => 3249\n",
      "3500 of 13106 => 3345\n",
      "3600 of 13106 => 3438\n",
      "3700 of 13106 => 3535\n",
      "3800 of 13106 => 3629\n",
      "3900 of 13106 => 3724\n",
      "4000 of 13106 => 3821\n",
      "4100 of 13106 => 3917\n",
      "4200 of 13106 => 4012\n",
      "4300 of 13106 => 4108\n",
      "4400 of 13106 => 4205\n",
      "4500 of 13106 => 4303\n",
      "4600 of 13106 => 4344\n",
      "4700 of 13106 => 4349\n",
      "4800 of 13106 => 4367\n",
      "4900 of 13106 => 4399\n",
      "5000 of 13106 => 4418\n",
      "5100 of 13106 => 4430\n",
      "5200 of 13106 => 4458\n",
      "5300 of 13106 => 4483\n",
      "5400 of 13106 => 4502\n",
      "5500 of 13106 => 4567\n",
      "5600 of 13106 => 4645\n",
      "5700 of 13106 => 4711\n",
      "5800 of 13106 => 4772\n",
      "5900 of 13106 => 4821\n",
      "6000 of 13106 => 4875\n",
      "6100 of 13106 => 4931\n",
      "6200 of 13106 => 4978\n",
      "6300 of 13106 => 5021\n",
      "6400 of 13106 => 5064\n",
      "6500 of 13106 => 5106\n",
      "6600 of 13106 => 5162\n",
      "6700 of 13106 => 5223\n",
      "6800 of 13106 => 5275\n",
      "6900 of 13106 => 5341\n",
      "7000 of 13106 => 5398\n",
      "7100 of 13106 => 5453\n",
      "7200 of 13106 => 5521\n",
      "7300 of 13106 => 5582\n",
      "7400 of 13106 => 5632\n",
      "7500 of 13106 => 5690\n",
      "7600 of 13106 => 5752\n",
      "7700 of 13106 => 5824\n",
      "7800 of 13106 => 5881\n",
      "7900 of 13106 => 5956\n",
      "8000 of 13106 => 6049\n",
      "8100 of 13106 => 6136\n",
      "8200 of 13106 => 6218\n",
      "8300 of 13106 => 6303\n",
      "8400 of 13106 => 6362\n",
      "8500 of 13106 => 6387\n",
      "8600 of 13106 => 6417\n",
      "8700 of 13106 => 6447\n",
      "8800 of 13106 => 6467\n",
      "8900 of 13106 => 6492\n",
      "9000 of 13106 => 6517\n",
      "9100 of 13106 => 6548\n",
      "9200 of 13106 => 6575\n",
      "9300 of 13106 => 6604\n",
      "9400 of 13106 => 6629\n",
      "9500 of 13106 => 6652\n",
      "9600 of 13106 => 6679\n",
      "9700 of 13106 => 6709\n",
      "9800 of 13106 => 6730\n",
      "9900 of 13106 => 6747\n",
      "10000 of 13106 => 6767\n",
      "10100 of 13106 => 6799\n",
      "10200 of 13106 => 6838\n",
      "10300 of 13106 => 6927\n",
      "10400 of 13106 => 7020\n",
      "10500 of 13106 => 7109\n",
      "10600 of 13106 => 7195\n",
      "10700 of 13106 => 7283\n",
      "10800 of 13106 => 7370\n",
      "10900 of 13106 => 7440\n",
      "11000 of 13106 => 7530\n",
      "11100 of 13106 => 7619\n",
      "11200 of 13106 => 7706\n",
      "11300 of 13106 => 7792\n",
      "11400 of 13106 => 7880\n",
      "11500 of 13106 => 7969\n",
      "11600 of 13106 => 8058\n",
      "11700 of 13106 => 8139\n",
      "11800 of 13106 => 8233\n",
      "11900 of 13106 => 8325\n",
      "12000 of 13106 => 8419\n",
      "12100 of 13106 => 8511\n",
      "12200 of 13106 => 8602\n",
      "12300 of 13106 => 8696\n",
      "12400 of 13106 => 8787\n",
      "12500 of 13106 => 8879\n",
      "12600 of 13106 => 8973\n",
      "12700 of 13106 => 9065\n",
      "12800 of 13106 => 9158\n",
      "12900 of 13106 => 9251\n",
      "13000 of 13106 => 9344\n",
      "13100 of 13106 => 9437\n",
      "9442 3656\n",
      "258.2603938730853\n"
     ]
    }
   ],
   "source": [
    "count_sucess = 0\n",
    "count_unsucessful = 0\n",
    "count_out_of_vocab = 0\n",
    "with open(r'..\\datasets\\miklov Analogies.txt') as file:\n",
    "    lines = file.readlines()\n",
    "    for index, line in enumerate(lines):\n",
    "        if(index % 100 == 0):\n",
    "            print(str(index) + \" of \" + str(len(lines)) +\" => \"+str( count_sucess))\n",
    "            \n",
    "        if line.startswith(\":\"):\n",
    "            pass\n",
    "        else:\n",
    "            a,a_star,b,b_star = line.split(\" \")\n",
    "            b_star = b_star.strip()#super important\n",
    "            \n",
    "            predicted = predict_three_cos_mult(a,a_star,b,b_star)\n",
    "            if(predicted == None):\n",
    "                count_out_of_vocab += 1\n",
    "            elif(predicted == b_star):\n",
    "                count_sucess += 1\n",
    "            else:\n",
    "                count_unsucessful += 1\n",
    "print(count_sucess,count_unsucessful)\n",
    "print(count_sucess/count_unsucessful * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "635a0c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7204333892873493"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9442 / 13106 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c15546d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import winsound\n",
    "winsound.Beep(440, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88565cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
