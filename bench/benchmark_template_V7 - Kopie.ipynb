{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2873f882",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "path = r'E://'\n",
    "id_dict = {}\n",
    "word_dict = {}\n",
    "\n",
    "emb_name = \"NonDynCleanDeleteBaseline_150w\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9554f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimensions 500\n"
     ]
    }
   ],
   "source": [
    "#AutoDetect dims\n",
    "#test with base2021_300\n",
    "with open(path + emb_name, 'r' , encoding=\"utf-8\")  as file:\n",
    "    line0 = file.readline()\n",
    "    dimensions = len(line0.split())-1\n",
    "print(\"dimensions \"+str(dimensions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04c2c2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260377\n"
     ]
    }
   ],
   "source": [
    "matrix = []\n",
    "with open(path + emb_name, 'r' , encoding=\"utf-8\")  as f:\n",
    "    lines = f.readlines()\n",
    "    vocab_size = len(lines)\n",
    "    \n",
    "    matrix = np.zeros((vocab_size,dimensions),dtype=float)\n",
    "    for line in lines:\n",
    "        entry = line.split()\n",
    "        word = entry[0].strip()\n",
    "        values = entry[1:]\n",
    "        id = len(id_dict)\n",
    "        id_dict[word]=id\n",
    "        word_dict[id] = word\n",
    "        vector = np.asarray(values, \"double\")\n",
    "        matrix[id_dict[word],:] = vector\n",
    "print(len(id_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37a44f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_candidate(sim,exclusion_list_ids,isMult):\n",
    "    for exclude_id in exclusion_list_ids:\n",
    "        if isMult:\n",
    "             sim[exclude_id] = 0#lowest possible value in 3CosMult\n",
    "        else:\n",
    "            sim[exclude_id] = -1#lowest possible value in 3CosAdd\n",
    "    return np.argmax(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd299ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_normalized = tf.nn.l2_normalize(matrix,axis = 1)# only use normalised version !!!\n",
    "matrix = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bc818b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_k(searched_word,k):\n",
    "    list = []\n",
    "    id = id_dict[searched_word]\n",
    "    searched_vector = matrix_normalized[id,:] \n",
    "    \n",
    "    for word in id_dict:\n",
    "        word_weights = matrix_normalized[id_dict[word]]\n",
    "        loss = tf.tensordot(word_weights,searched_vector,axes = 1).numpy()\n",
    "        list = insert(list,(word,loss))\n",
    "        if len(list) > k:\n",
    "            list = list[0:k+1]\n",
    "    return list[0:k]\n",
    "\n",
    "# Function to insert element\n",
    "def insert(list, tuple):\n",
    "    (word,n) = tuple\n",
    "    if(len(list) == 0):\n",
    "        list = [(word,n)]\n",
    "    # Searching for the position\n",
    "    for i in range(len(list)):\n",
    "        (word_i,n_i) = list[i]\n",
    "        if n_i < n:\n",
    "            index = i\n",
    "            break\n",
    "      \n",
    "    # Inserting n in the list\n",
    "    list = list[:i] + [(word,n)] + list[i:]\n",
    "    return list\n",
    "\n",
    "def unzip(some_list):\n",
    "    return [ i for i, j in some_list ]\n",
    "    \n",
    "# take nearest 6 and remove the searched word itself\n",
    "print(unzip(find_nearest_k('bank' ,7)[1:]))#the food or the place\n",
    "print(unzip(find_nearest_k('apple',7)[1:]))#location or to to speak to\n",
    "print(unzip(find_nearest_k('so'   ,7)[1:]))#noun (animal) or verb \n",
    "print(unzip(find_nearest_k('desert',   6)[1:]))#animal or verb\n",
    "print(unzip(find_nearest_k('left',   6)[1:]))#adverb (direction) and verb(the plane left)\n",
    "print(unzip(find_nearest_k('duck',   6)[1:]))# The president of the bank walked along the river bank.\n",
    "print(\"--------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a646d761",
   "metadata": {},
   "source": [
    "# 3cosAdd normalised befor arithmetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "383f8d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_cos_predict_np_norm(a,a_star,b,b_star):\n",
    "    if( a in id_dict and b in id_dict and a_star in id_dict and b_star in id_dict):\n",
    "        pass\n",
    "    else:\n",
    "        return None\n",
    "    id_a = id_dict[a]\n",
    "    id_b = id_dict[b]\n",
    "    id_a_star = id_dict[a_star]\n",
    "    id_b_star = id_dict[b_star]#remove this after testing\n",
    "    weight_a = matrix_normalized[id_a,:]\n",
    "    weight_b = matrix_normalized[id_b,:]\n",
    "    weight_a_star = matrix_normalized[id_a_star,:]\n",
    "    direction = weight_b + ( weight_a_star - weight_a)\n",
    "    direction /= np.linalg.norm(direction)\n",
    "    \n",
    "    sim = tf.tensordot(tf.convert_to_tensor(matrix_normalized),tf.convert_to_tensor(direction),axes = 1)\n",
    "    index = find_candidate(sim.numpy(),[id_a,id_a_star,id_b],False)\n",
    "    return word_dict[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4042c364",
   "metadata": {},
   "source": [
    "## 3cos Mult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ac07eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_01(matrix,weight):\n",
    "    tmp = tf.tensordot(matrix,weight,axes=1)\n",
    "    tmp = (tmp+1.0)/2.0\n",
    "    return tmp\n",
    "\n",
    "def predict_three_cos_mult(a,a_star,b,b_star):\n",
    "    if( a in id_dict and b in id_dict and a_star in id_dict and b_star in id_dict):\n",
    "        pass\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    id_a = id_dict[a]\n",
    "    id_b = id_dict[b]\n",
    "    id_a_star = id_dict[a_star]\n",
    "    \n",
    "    weight_a = matrix_normalized[id_a,:]\n",
    "    weight_b = matrix_normalized[id_b,:]\n",
    "    weight_a_star = matrix_normalized[id_a_star,:]\n",
    "    \n",
    "    nominator = sim_01(matrix_normalized,weight_a_star) * sim_01(matrix_normalized,weight_b) \n",
    "    denominator = sim_01(matrix_normalized,weight_a) + 0.0001\n",
    "    sim = nominator / denominator\n",
    "    index = find_candidate(sim.numpy(),[id_a,id_a_star,id_b],True)\n",
    "    return word_dict[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c53d10",
   "metadata": {},
   "source": [
    "# Test all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2911b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_results(add,mult):\n",
    "    add_string = str(add)\n",
    "    add_string = add_string.lstrip('0')\n",
    "    add_string = format(add_string, \".4\")\n",
    "    mult_string = str(mult)\n",
    "    mult_string = mult_string.lstrip('0')\n",
    "    mult_string = format(mult_string, \".4\")\n",
    "    return add_string +'/'+mult_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eecd5ce6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "capital-common-countries.txt\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      ".934/.934\n",
      "-------------------\n",
      "capital-world.txt\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n",
      "1000\n",
      "1010\n",
      "1020\n",
      "1030\n",
      "1040\n",
      "1050\n",
      "1060\n",
      "1070\n",
      "1080\n",
      "1090\n",
      "1100\n",
      "1110\n",
      "1120\n",
      "1130\n",
      "1140\n",
      "1150\n",
      "1160\n",
      "1170\n",
      "1180\n",
      "1190\n",
      "1200\n",
      "1210\n",
      "1220\n",
      "1230\n",
      "1240\n",
      "1250\n",
      "1260\n",
      "1270\n",
      "1280\n",
      "1290\n",
      "1300\n",
      "1310\n",
      "1320\n",
      "1330\n",
      "1340\n",
      "1350\n",
      "1360\n",
      "1370\n",
      "1380\n",
      "1390\n",
      "1400\n",
      "1410\n",
      "1420\n",
      "1430\n",
      "1440\n",
      "1450\n",
      "1460\n",
      "1470\n",
      "1480\n",
      "1490\n",
      "1500\n",
      "1510\n",
      "1520\n",
      "1530\n",
      "1540\n",
      "1550\n",
      "1560\n",
      "1570\n",
      "1580\n",
      "1590\n",
      "1600\n",
      "1610\n",
      "1620\n",
      "1630\n",
      "1640\n",
      "1650\n",
      "1660\n",
      "1670\n",
      "1680\n",
      "1690\n",
      "1700\n",
      "1710\n",
      "1720\n",
      "1730\n",
      "1740\n",
      "1750\n",
      "1760\n",
      "1770\n",
      "1780\n",
      "1790\n",
      "1800\n",
      "1810\n",
      "1820\n",
      "1830\n",
      "1840\n",
      "1850\n",
      "1860\n",
      "1870\n",
      "1880\n",
      "1890\n",
      "1900\n",
      "1910\n",
      "1920\n",
      "1930\n",
      "1940\n",
      "1950\n",
      "1960\n",
      "1970\n",
      "1980\n",
      "1990\n",
      "2000\n",
      "2010\n",
      "2020\n",
      "2030\n",
      "2040\n",
      "2050\n",
      "2060\n",
      "2070\n",
      "2080\n",
      "2090\n",
      "2100\n",
      "2110\n",
      "2120\n",
      "2130\n",
      "2140\n",
      "2150\n",
      "2160\n",
      "2170\n",
      "2180\n",
      "2190\n",
      "2200\n",
      "2210\n",
      "2220\n",
      "2230\n",
      "2240\n",
      "2250\n",
      "2260\n",
      "2270\n",
      "2280\n",
      "2290\n",
      "2300\n",
      "2310\n",
      "2320\n",
      "2330\n",
      "2340\n",
      "2350\n",
      "2360\n",
      "2370\n",
      "2380\n",
      "2390\n",
      "2400\n",
      "2410\n",
      "2420\n",
      "2430\n",
      "2440\n",
      "2450\n",
      "2460\n",
      "2470\n",
      "2480\n",
      "2490\n",
      "2500\n",
      "2510\n",
      "2520\n",
      "2530\n",
      "2540\n",
      "2550\n",
      "2560\n",
      "2570\n",
      "2580\n",
      "2590\n",
      "2600\n",
      "2610\n",
      "2620\n",
      "2630\n",
      "2640\n",
      "2650\n",
      "2660\n",
      "2670\n",
      "2680\n",
      "2690\n",
      "2700\n",
      "2710\n",
      "2720\n",
      "2730\n",
      "2740\n",
      "2750\n",
      "2760\n",
      "2770\n",
      "2780\n",
      "2790\n",
      "2800\n",
      "2810\n",
      "2820\n",
      "2830\n",
      "2840\n",
      "2850\n",
      "2860\n",
      "2870\n",
      "2880\n",
      "2890\n",
      "2900\n",
      "2910\n",
      "2920\n",
      "2930\n",
      "2940\n",
      "2950\n",
      "2960\n",
      "2970\n",
      "2980\n",
      "2990\n",
      "3000\n",
      "3010\n",
      "3020\n",
      "3030\n",
      "3040\n",
      "3050\n",
      "3060\n",
      "3070\n",
      "3080\n",
      "3090\n",
      "3100\n",
      "3110\n",
      "3120\n",
      "3130\n",
      "3140\n",
      "3150\n",
      "3160\n",
      "3170\n",
      "3180\n",
      "3190\n",
      "3200\n",
      "3210\n",
      "3220\n",
      "3230\n",
      "3240\n",
      "3250\n",
      "3260\n",
      "3270\n",
      "3280\n",
      "3290\n",
      "3300\n",
      "3310\n",
      "3320\n",
      "3330\n",
      "3340\n",
      "3350\n",
      "3360\n",
      "3370\n",
      "3380\n",
      "3390\n",
      "3400\n",
      "3410\n",
      "3420\n",
      "3430\n",
      "3440\n",
      "3450\n",
      "3460\n",
      "3470\n",
      "3480\n",
      "3490\n",
      "3500\n",
      "3510\n",
      "3520\n",
      "3530\n",
      "3540\n",
      "3550\n",
      "3560\n",
      "3570\n",
      "3580\n",
      "3590\n",
      "3600\n",
      "3610\n",
      "3620\n",
      "3630\n",
      "3640\n",
      "3650\n",
      "3660\n",
      "3670\n",
      "3680\n",
      "3690\n",
      "3700\n",
      "3710\n",
      "3720\n",
      "3730\n",
      "3740\n",
      "3750\n",
      "3760\n",
      "3770\n",
      "3780\n",
      "3790\n",
      "3800\n",
      "3810\n",
      "3820\n",
      "3830\n",
      "3840\n",
      "3850\n",
      "3860\n",
      "3870\n",
      "3880\n",
      "3890\n",
      "3900\n",
      "3910\n",
      "3920\n",
      "3930\n",
      "3940\n",
      "3950\n",
      "3960\n",
      "3970\n",
      "3980\n",
      "3990\n",
      "4000\n",
      "4010\n",
      "4020\n",
      "4030\n",
      "4040\n",
      "4050\n",
      "4060\n",
      "4070\n",
      "4080\n",
      "4090\n",
      "4100\n",
      "4110\n",
      "4120\n",
      "4130\n",
      "4140\n",
      "4150\n",
      "4160\n",
      "4170\n",
      "4180\n",
      "4190\n",
      "4200\n",
      "4210\n",
      "4220\n",
      "4230\n",
      "4240\n",
      "4250\n",
      "4260\n",
      "4270\n",
      "4280\n",
      "4290\n",
      "4300\n",
      "4310\n",
      "4320\n",
      "4330\n",
      "4340\n",
      "4350\n",
      "4360\n",
      "4370\n",
      "4380\n",
      "4390\n",
      "4400\n",
      "4410\n",
      "4420\n",
      "4430\n",
      "4440\n",
      "4450\n",
      "4460\n",
      "4470\n",
      "4480\n",
      "4490\n",
      "4500\n",
      "4510\n",
      "4520\n",
      ".935/.934\n",
      "-------------------\n",
      "city-in-state.txt\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n",
      "1000\n",
      "1010\n",
      "1020\n",
      "1030\n",
      "1040\n",
      "1050\n",
      "1060\n",
      "1070\n",
      "1080\n",
      "1090\n",
      "1100\n",
      "1110\n",
      "1120\n",
      "1130\n",
      "1140\n",
      "1150\n",
      "1160\n",
      "1170\n",
      "1180\n",
      "1190\n",
      "1200\n",
      "1210\n",
      "1220\n",
      "1230\n",
      "1240\n",
      "1250\n",
      "1260\n",
      "1270\n",
      "1280\n",
      "1290\n",
      "1300\n",
      "1310\n",
      "1320\n",
      "1330\n",
      "1340\n",
      "1350\n",
      "1360\n",
      "1370\n",
      "1380\n",
      "1390\n",
      "1400\n",
      "1410\n",
      "1420\n",
      "1430\n",
      "1440\n",
      "1450\n",
      "1460\n",
      "1470\n",
      "1480\n",
      "1490\n",
      "1500\n",
      "1510\n",
      "1520\n",
      "1530\n",
      "1540\n",
      "1550\n",
      "1560\n",
      "1570\n",
      "1580\n",
      "1590\n",
      "1600\n",
      "1610\n",
      "1620\n",
      "1630\n",
      "1640\n",
      "1650\n",
      "1660\n",
      "1670\n",
      "1680\n",
      "1690\n",
      "1700\n",
      "1710\n",
      "1720\n",
      "1730\n",
      "1740\n",
      "1750\n",
      "1760\n",
      "1770\n",
      "1780\n",
      "1790\n",
      "1800\n",
      "1810\n",
      "1820\n",
      "1830\n",
      "1840\n",
      "1850\n",
      "1860\n",
      "1870\n",
      "1880\n",
      "1890\n",
      "1900\n",
      "1910\n",
      "1920\n",
      "1930\n",
      "1940\n",
      "1950\n",
      "1960\n",
      "1970\n",
      "1980\n",
      "1990\n",
      "2000\n",
      "2010\n",
      "2020\n",
      "2030\n",
      "2040\n",
      "2050\n",
      "2060\n",
      "2070\n",
      "2080\n",
      "2090\n",
      "2100\n",
      "2110\n",
      "2120\n",
      "2130\n",
      "2140\n",
      "2150\n",
      "2160\n",
      "2170\n",
      "2180\n",
      "2190\n",
      "2200\n",
      "2210\n",
      "2220\n",
      "2230\n",
      "2240\n",
      "2250\n",
      "2260\n",
      "2270\n",
      "2280\n",
      "2290\n",
      "2300\n",
      "2310\n",
      "2320\n",
      "2330\n",
      "2340\n",
      "2350\n",
      "2360\n",
      "2370\n",
      "2380\n",
      "2390\n",
      "2400\n",
      "2410\n",
      "2420\n",
      "2430\n",
      "2440\n",
      "2450\n",
      "2460\n",
      ".732/.732\n",
      "-------------------\n",
      "currency.txt\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      ".026/.025\n",
      "-------------------\n",
      "family.txt\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      ".669/.669\n",
      "-------------------\n",
      "gram1-adjective-to-adverb.txt\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n",
      ".259/.258\n",
      "-------------------\n",
      "gram2-opposite.txt\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      ".151/.151\n",
      "-------------------\n",
      "gram3-comparative.txt\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n",
      "1000\n",
      "1010\n",
      "1020\n",
      "1030\n",
      "1040\n",
      "1050\n",
      "1060\n",
      "1070\n",
      "1080\n",
      "1090\n",
      "1100\n",
      "1110\n",
      "1120\n",
      "1130\n",
      "1140\n",
      "1150\n",
      "1160\n",
      "1170\n",
      "1180\n",
      "1190\n",
      "1200\n",
      "1210\n",
      "1220\n",
      "1230\n",
      "1240\n",
      "1250\n",
      "1260\n",
      "1270\n",
      "1280\n",
      "1290\n",
      "1300\n",
      "1310\n",
      "1320\n",
      "1330\n",
      ".319/.317\n",
      "-------------------\n",
      "gram4-superlative.txt\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n",
      "1000\n",
      "1010\n",
      "1020\n",
      "1030\n",
      "1040\n",
      "1050\n",
      "1060\n",
      "1070\n",
      "1080\n",
      "1090\n",
      "1100\n",
      "1110\n",
      "1120\n",
      ".080/.078\n",
      "-------------------\n",
      "gram5-present-participle.txt\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n",
      "1000\n",
      "1010\n",
      "1020\n",
      "1030\n",
      "1040\n",
      "1050\n",
      ".563/.561\n",
      "-------------------\n",
      "gram6-nationality-adjective.txt\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n",
      "1000\n",
      "1010\n",
      "1020\n",
      "1030\n",
      "1040\n",
      "1050\n",
      "1060\n",
      "1070\n",
      "1080\n",
      "1090\n",
      "1100\n",
      "1110\n",
      "1120\n",
      "1130\n",
      "1140\n",
      "1150\n",
      "1160\n",
      "1170\n",
      "1180\n",
      "1190\n",
      "1200\n",
      "1210\n",
      "1220\n",
      "1230\n",
      "1240\n",
      "1250\n",
      "1260\n",
      "1270\n",
      "1280\n",
      "1290\n",
      "1300\n",
      "1310\n",
      "1320\n",
      "1330\n",
      "1340\n",
      "1350\n",
      "1360\n",
      "1370\n",
      "1380\n",
      "1390\n",
      "1400\n",
      "1410\n",
      "1420\n",
      "1430\n",
      "1440\n",
      "1450\n",
      "1460\n",
      "1470\n",
      "1480\n",
      "1490\n",
      "1500\n",
      "1510\n",
      "1520\n",
      "1530\n",
      "1540\n",
      "1550\n",
      "1560\n",
      "1570\n",
      "1580\n",
      "1590\n",
      ".884/.884\n",
      "-------------------\n",
      "gram7-past-tense.txt\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n",
      "1000\n",
      "1010\n",
      "1020\n",
      "1030\n",
      "1040\n",
      "1050\n",
      "1060\n",
      "1070\n",
      "1080\n",
      "1090\n",
      "1100\n",
      "1110\n",
      "1120\n",
      "1130\n",
      "1140\n",
      "1150\n",
      "1160\n",
      "1170\n",
      "1180\n",
      "1190\n",
      "1200\n",
      "1210\n",
      "1220\n",
      "1230\n",
      "1240\n",
      "1250\n",
      "1260\n",
      "1270\n",
      "1280\n",
      "1290\n",
      "1300\n",
      "1310\n",
      "1320\n",
      "1330\n",
      "1340\n",
      "1350\n",
      "1360\n",
      "1370\n",
      "1380\n",
      "1390\n",
      "1400\n",
      "1410\n",
      "1420\n",
      "1430\n",
      "1440\n",
      "1450\n",
      "1460\n",
      "1470\n",
      "1480\n",
      "1490\n",
      "1500\n",
      "1510\n",
      "1520\n",
      "1530\n",
      "1540\n",
      "1550\n",
      ".462/.462\n",
      "-------------------\n",
      "gram8-plural.txt\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n",
      "1000\n",
      "1010\n",
      "1020\n",
      "1030\n",
      "1040\n",
      "1050\n",
      "1060\n",
      "1070\n",
      "1080\n",
      "1090\n",
      "1100\n",
      "1110\n",
      "1120\n",
      "1130\n",
      "1140\n",
      "1150\n",
      "1160\n",
      "1170\n",
      "1180\n",
      "1190\n",
      "1200\n",
      "1210\n",
      "1220\n",
      "1230\n",
      "1240\n",
      "1250\n",
      "1260\n",
      "1270\n",
      "1280\n",
      "1290\n",
      "1300\n",
      "1310\n",
      "1320\n",
      "1330\n",
      ".592/.587\n",
      "-------------------\n",
      "gram9-plural-verbs.txt\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      ".262/.257\n",
      "-------------------\n",
      "ner.classes\n",
      "treebank_pos.classes\n",
      "universal_pos.classes\n",
      "semantical\n",
      ".775/.774\n",
      "syntactical\n",
      ".523/.521\n",
      "overall\n",
      ".649/.647\n"
     ]
    }
   ],
   "source": [
    "count_sem_questions =  0\n",
    "count_syn_questions =  0\n",
    "\n",
    "count_sem_sucess      = [0,0]\n",
    "count_syn_sucess      = [0,0]\n",
    "\n",
    "errors = []\n",
    "\n",
    "\n",
    "files = os.listdir('.\\\\datasets\\\\question-data')\n",
    "for idx,file_name in enumerate(files):\n",
    "    print(file_name)\n",
    "    if file_name.endswith('.classes'):\n",
    "        continue\n",
    "    \n",
    "    with open('.\\\\datasets\\\\question-data\\\\'+file_name,'r') as file:    \n",
    "        lines = file.readlines()\n",
    "        local_sucesses    = [0,0,0]\n",
    "        local_tasks_count = 0\n",
    "         \n",
    "        for line_id,line in enumerate(lines):\n",
    "            if (line_id % 10 == 0):\n",
    "                print(line_id)\n",
    "            a,a_star,b,b_star = line.split(\" \")\n",
    "            b_star = b_star.strip()\n",
    "            predicted_3cos_add_norm = three_cos_predict_np_norm(a,a_star,b,b_star)\n",
    "            predicted_3cos_mult     = predict_three_cos_mult(a,a_star,b,b_star)\n",
    "            if(idx < 5):#first 5 are sem\n",
    "                count_sem_questions += 1\n",
    "                local_tasks_count   += 1\n",
    "                \n",
    "                if predicted_3cos_add_norm == b_star:\n",
    "                    local_sucesses[0] += 1\n",
    "                    count_sem_sucess[0] += 1\n",
    "                    \n",
    "                if  predicted_3cos_mult    == b_star:\n",
    "                    local_sucesses[1] += 1\n",
    "                    count_sem_sucess[1] += 1\n",
    "            else:\n",
    "                count_syn_questions += 1\n",
    "                local_tasks_count   += 1\n",
    "                \n",
    "                if predicted_3cos_add_norm == b_star:\n",
    "                    local_sucesses[0] += 1\n",
    "                    count_syn_sucess[0] += 1\n",
    "                    \n",
    "                if  predicted_3cos_mult    == b_star:\n",
    "                    local_sucesses[1] += 1\n",
    "                    count_syn_sucess[1] += 1\n",
    "                    \n",
    "        print(format_results(local_sucesses[0]/float(local_tasks_count),local_sucesses[1]/float(local_tasks_count)))\n",
    "        print('-------------------')\n",
    "\n",
    "print('semantical')\n",
    "print(format_results(count_sem_sucess[0]/float(count_sem_questions),count_sem_sucess[1]/float(count_sem_questions)))\n",
    "\n",
    "print('syntactical')\n",
    "print(format_results(count_syn_sucess[0]/float(count_sem_questions),count_syn_sucess[1]/float(count_sem_questions)))\n",
    "\n",
    "print('overall')\n",
    "print(format_results((count_syn_sucess[0]+count_sem_sucess[0])/float(count_sem_questions+count_sem_questions), \\\n",
    "                     (count_syn_sucess[1]+count_sem_sucess[1])/float(count_sem_questions+count_sem_questions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c15546d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import winsound\n",
    "winsound.Beep(440, 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb4fdf0",
   "metadata": {},
   "source": [
    "Spearman Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa2916f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linetiger\tcat\t7.35\n",
      "\n",
      "tiger cat\n",
      "58274\n",
      "34268\n",
      "tf.Tensor(0.9948665165286512, shape=(), dtype=float64) 0.735\n",
      "linetiger\ttiger\t10.00\n",
      "\n",
      "tiger tiger\n",
      "58274\n",
      "58274\n",
      "tf.Tensor(1.0, shape=(), dtype=float64) 1.0\n",
      "lineplane\tcar\t5.77\n",
      "\n",
      "plane car\n",
      "202953\n",
      "35611\n",
      "tf.Tensor(0.9945349118206713, shape=(), dtype=float64) 0.577\n",
      "linetrain\tcar\t6.31\n",
      "\n",
      "train car\n",
      "156986\n",
      "35611\n",
      "tf.Tensor(0.996950317225267, shape=(), dtype=float64) 0.631\n",
      "linetelevision\tradio\t6.77\n",
      "\n",
      "television radio\n",
      "139248\n",
      "176699\n",
      "tf.Tensor(0.9975300707292811, shape=(), dtype=float64) 0.6769999999999999\n",
      "linemedia\tradio\t7.42\n",
      "\n",
      "media radio\n",
      "118685\n",
      "176699\n",
      "tf.Tensor(0.9972227315311613, shape=(), dtype=float64) 0.742\n",
      "linebread\tbutter\t6.19\n",
      "\n",
      "bread butter\n",
      "219262\n",
      "74084\n",
      "tf.Tensor(0.9919743087415465, shape=(), dtype=float64) 0.619\n",
      "linecucumber\tpotato\t5.92\n",
      "\n",
      "cucumber potato\n",
      "64788\n",
      "185448\n",
      "tf.Tensor(0.9737629400256691, shape=(), dtype=float64) 0.592\n",
      "linedoctor\tnurse\t7.00\n",
      "\n",
      "doctor nurse\n",
      "234074\n",
      "107922\n",
      "tf.Tensor(0.9953666977395734, shape=(), dtype=float64) 0.7\n",
      "lineprofessor\tdoctor\t6.62\n",
      "\n",
      "professor doctor\n",
      "208085\n",
      "234074\n",
      "tf.Tensor(0.9962420962330087, shape=(), dtype=float64) 0.662\n",
      "linestudent\tprofessor\t6.81\n",
      "\n",
      "student professor\n",
      "64856\n",
      "208085\n",
      "tf.Tensor(0.996614652235325, shape=(), dtype=float64) 0.6809999999999999\n",
      "linesmart\tstupid\t5.81\n",
      "\n",
      "smart stupid\n",
      "254362\n",
      "47784\n",
      "tf.Tensor(0.9925528148541942, shape=(), dtype=float64) 0.581\n",
      "linewood\tforest\t7.73\n",
      "\n",
      "wood forest\n",
      "35306\n",
      "80216\n",
      "tf.Tensor(0.996378743504895, shape=(), dtype=float64) 0.773\n",
      "linemoney\tcash\t9.15\n",
      "\n",
      "money cash\n",
      "53013\n",
      "217351\n",
      "tf.Tensor(0.9974123192285214, shape=(), dtype=float64) 0.915\n",
      "lineking\tqueen\t8.58\n",
      "\n",
      "king queen\n",
      "251718\n",
      "225561\n",
      "tf.Tensor(0.997971225457525, shape=(), dtype=float64) 0.858\n",
      "lineking\trook\t5.92\n",
      "\n",
      "king rook\n",
      "251718\n",
      "6556\n",
      "tf.Tensor(0.9669805449401668, shape=(), dtype=float64) 0.592\n",
      "linebishop\trabbi\t6.69\n",
      "\n",
      "bishop rabbi\n",
      "98103\n",
      "41790\n",
      "tf.Tensor(0.9901524080775572, shape=(), dtype=float64) 0.669\n",
      "linefuck\tsex\t9.44\n",
      "\n",
      "fuck sex\n",
      "123896\n",
      "235857\n",
      "tf.Tensor(0.988238505813944, shape=(), dtype=float64) 0.944\n",
      "linefootball\tsoccer\t9.03\n",
      "\n",
      "football soccer\n",
      "86349\n",
      "257413\n",
      "tf.Tensor(0.9963057591984381, shape=(), dtype=float64) 0.9029999999999999\n",
      "linefootball\tbasketball\t6.81\n",
      "\n",
      "football basketball\n",
      "86349\n",
      "245478\n",
      "tf.Tensor(0.9964160669797151, shape=(), dtype=float64) 0.6809999999999999\n",
      "linefootball\ttennis\t6.63\n",
      "\n",
      "football tennis\n",
      "86349\n",
      "117339\n",
      "tf.Tensor(0.9931122377523631, shape=(), dtype=float64) 0.663\n",
      "lineArafat\tJackson\t2.50\n",
      "\n",
      "Arafat Jackson\n",
      "0 0.25\n",
      "linephysics\tchemistry\t7.35\n",
      "\n",
      "physics chemistry\n",
      "199727\n",
      "203425\n",
      "tf.Tensor(0.9964680685389529, shape=(), dtype=float64) 0.735\n",
      "linevodka\tgin\t8.46\n",
      "\n",
      "vodka gin\n",
      "174262\n",
      "36196\n",
      "tf.Tensor(0.9882519826045931, shape=(), dtype=float64) 0.8460000000000001\n",
      "linevodka\tbrandy\t8.13\n",
      "\n",
      "vodka brandy\n",
      "174262\n",
      "225479\n",
      "tf.Tensor(0.9869478650917491, shape=(), dtype=float64) 0.8130000000000001\n",
      "linedrink\teat\t6.87\n",
      "\n",
      "drink eat\n",
      "245847\n",
      "62625\n",
      "tf.Tensor(0.9952278301315924, shape=(), dtype=float64) 0.687\n",
      "linecar\tautomobile\t8.94\n",
      "\n",
      "car automobile\n",
      "35611\n",
      "77800\n",
      "tf.Tensor(0.9956268660333881, shape=(), dtype=float64) 0.8939999999999999\n",
      "linegem\tjewel\t8.96\n",
      "\n",
      "gem jewel\n",
      "171360\n",
      "58475\n",
      "tf.Tensor(0.9944550560144297, shape=(), dtype=float64) 0.8960000000000001\n",
      "linejourney\tvoyage\t9.29\n",
      "\n",
      "journey voyage\n",
      "216910\n",
      "162519\n",
      "tf.Tensor(0.9954309502651786, shape=(), dtype=float64) 0.9289999999999999\n",
      "lineboy\tlad\t8.83\n",
      "\n",
      "boy lad\n",
      "339\n",
      "137152\n",
      "tf.Tensor(0.9880367880663321, shape=(), dtype=float64) 0.883\n",
      "linecoast\tshore\t9.10\n",
      "\n",
      "coast shore\n",
      "163111\n",
      "95473\n",
      "tf.Tensor(0.9971410796554245, shape=(), dtype=float64) 0.9099999999999999\n",
      "lineasylum\tmadhouse\t8.87\n",
      "\n",
      "asylum madhouse\n",
      "228824\n",
      "31851\n",
      "tf.Tensor(0.980310078837511, shape=(), dtype=float64) 0.8869999999999999\n",
      "linemagician\twizard\t9.02\n",
      "\n",
      "magician wizard\n",
      "253573\n",
      "238384\n",
      "tf.Tensor(0.9931050361013486, shape=(), dtype=float64) 0.9019999999999999\n",
      "linemidday\tnoon\t9.29\n",
      "\n",
      "midday noon\n",
      "187884\n",
      "70066\n",
      "tf.Tensor(0.992434896739268, shape=(), dtype=float64) 0.9289999999999999\n",
      "linefurnace\tstove\t8.79\n",
      "\n",
      "furnace stove\n",
      "18433\n",
      "182430\n",
      "tf.Tensor(0.985636197575784, shape=(), dtype=float64) 0.8789999999999999\n",
      "linefood\tfruit\t7.52\n",
      "\n",
      "food fruit\n",
      "242035\n",
      "26778\n",
      "tf.Tensor(0.994898387788722, shape=(), dtype=float64) 0.752\n",
      "linebird\tcock\t7.10\n",
      "\n",
      "bird cock\n",
      "197103\n",
      "240795\n",
      "tf.Tensor(0.9899791886269546, shape=(), dtype=float64) 0.71\n",
      "linebird\tcrane\t7.38\n",
      "\n",
      "bird crane\n",
      "197103\n",
      "88074\n",
      "tf.Tensor(0.994185481407323, shape=(), dtype=float64) 0.738\n",
      "linefood\trooster\t4.42\n",
      "\n",
      "food rooster\n",
      "242035\n",
      "176417\n",
      "tf.Tensor(0.9874442857462, shape=(), dtype=float64) 0.442\n",
      "linemoney\tdollar\t8.42\n",
      "\n",
      "money dollar\n",
      "53013\n",
      "141746\n",
      "tf.Tensor(0.9954639268713806, shape=(), dtype=float64) 0.842\n",
      "linemoney\tcurrency\t9.04\n",
      "\n",
      "money currency\n",
      "53013\n",
      "139508\n",
      "tf.Tensor(0.993531593930822, shape=(), dtype=float64) 0.9039999999999999\n",
      "linetiger\tjaguar\t8.00\n",
      "\n",
      "tiger jaguar\n",
      "58274\n",
      "45474\n",
      "tf.Tensor(0.9903764182583434, shape=(), dtype=float64) 0.8\n",
      "linetiger\tfeline\t8.00\n",
      "\n",
      "tiger feline\n",
      "58274\n",
      "33782\n",
      "tf.Tensor(0.9840122093622556, shape=(), dtype=float64) 0.8\n",
      "linetiger\tcarnivore\t7.08\n",
      "\n",
      "tiger carnivore\n",
      "58274\n",
      "130262\n",
      "tf.Tensor(0.977219461612373, shape=(), dtype=float64) 0.708\n",
      "linetiger\tmammal\t6.85\n",
      "\n",
      "tiger mammal\n",
      "58274\n",
      "148729\n",
      "tf.Tensor(0.9863242500051708, shape=(), dtype=float64) 0.6849999999999999\n",
      "linetiger\tanimal\t7.00\n",
      "\n",
      "tiger animal\n",
      "58274\n",
      "110076\n",
      "tf.Tensor(0.9942278111744989, shape=(), dtype=float64) 0.7\n",
      "linetiger\torganism\t4.77\n",
      "\n",
      "tiger organism\n",
      "58274\n",
      "36934\n",
      "tf.Tensor(0.9866445213190967, shape=(), dtype=float64) 0.477\n",
      "linetiger\tfauna\t5.62\n",
      "\n",
      "tiger fauna\n",
      "58274\n",
      "248547\n",
      "tf.Tensor(0.9868426401506742, shape=(), dtype=float64) 0.562\n",
      "linepsychology\tpsychiatry\t8.08\n",
      "\n",
      "psychology psychiatry\n",
      "159905\n",
      "165916\n",
      "tf.Tensor(0.9920255494126409, shape=(), dtype=float64) 0.808\n",
      "linepsychology\tscience\t6.71\n",
      "\n",
      "psychology science\n",
      "159905\n",
      "221434\n",
      "tf.Tensor(0.9957030454292279, shape=(), dtype=float64) 0.671\n",
      "linepsychology\tdiscipline\t5.58\n",
      "\n",
      "psychology discipline\n",
      "159905\n",
      "7842\n",
      "tf.Tensor(0.9928816234779663, shape=(), dtype=float64) 0.558\n",
      "lineplanet\tstar\t8.45\n",
      "\n",
      "planet star\n",
      "136564\n",
      "230371\n",
      "tf.Tensor(0.9960625646257133, shape=(), dtype=float64) 0.845\n",
      "lineplanet\tmoon\t8.08\n",
      "\n",
      "planet moon\n",
      "136564\n",
      "91729\n",
      "tf.Tensor(0.9961304350248545, shape=(), dtype=float64) 0.808\n",
      "lineplanet\tsun\t8.02\n",
      "\n",
      "planet sun\n",
      "136564\n",
      "158525\n",
      "tf.Tensor(0.9955407319590498, shape=(), dtype=float64) 0.8019999999999999\n",
      "lineprecedent\texample\t5.85\n",
      "\n",
      "precedent example\n",
      "164348\n",
      "15153\n",
      "tf.Tensor(0.9927339134436601, shape=(), dtype=float64) 0.585\n",
      "lineprecedent\tantecedent\t6.04\n",
      "\n",
      "precedent antecedent\n",
      "164348\n",
      "253576\n",
      "tf.Tensor(0.9815901108322856, shape=(), dtype=float64) 0.604\n",
      "linecup\ttableware\t6.85\n",
      "\n",
      "cup tableware\n",
      "76390\n",
      "65497\n",
      "tf.Tensor(0.976672645032552, shape=(), dtype=float64) 0.6849999999999999\n",
      "linecup\tartifact\t2.92\n",
      "\n",
      "cup artifact\n",
      "76390\n",
      "90874\n",
      "tf.Tensor(0.9889084663854084, shape=(), dtype=float64) 0.292\n",
      "linecup\tobject\t3.69\n",
      "\n",
      "cup object\n",
      "76390\n",
      "116366\n",
      "tf.Tensor(0.9918011161045429, shape=(), dtype=float64) 0.369\n",
      "linecup\tentity\t2.15\n",
      "\n",
      "cup entity\n",
      "76390\n",
      "182816\n",
      "tf.Tensor(0.9917423935086938, shape=(), dtype=float64) 0.215\n",
      "linejaguar\tcat\t7.42\n",
      "\n",
      "jaguar cat\n",
      "45474\n",
      "34268\n",
      "tf.Tensor(0.9900297245469372, shape=(), dtype=float64) 0.742\n",
      "linejaguar\tcar\t7.27\n",
      "\n",
      "jaguar car\n",
      "45474\n",
      "35611\n",
      "tf.Tensor(0.991257810064167, shape=(), dtype=float64) 0.727\n",
      "linemile\tkilometer\t8.66\n",
      "\n",
      "mile kilometer\n",
      "24793\n",
      "14332\n",
      "tf.Tensor(0.991188048810985, shape=(), dtype=float64) 0.866\n",
      "lineskin\teye\t6.22\n",
      "\n",
      "skin eye\n",
      "37863\n",
      "214327\n",
      "tf.Tensor(0.9948910499894684, shape=(), dtype=float64) 0.622\n",
      "lineJapanese\tAmerican\t6.50\n",
      "\n",
      "Japanese American\n",
      "0 0.65\n",
      "linecentury\tyear\t7.59\n",
      "\n",
      "century year\n",
      "191459\n",
      "176855\n",
      "tf.Tensor(0.9976288969999038, shape=(), dtype=float64) 0.759\n",
      "lineannouncement\tnews\t7.56\n",
      "\n",
      "announcement news\n",
      "155882\n",
      "145274\n",
      "tf.Tensor(0.9966458874131308, shape=(), dtype=float64) 0.756\n",
      "linedoctor\tpersonnel\t5.00\n",
      "\n",
      "doctor personnel\n",
      "234074\n",
      "248906\n",
      "tf.Tensor(0.9947127430988834, shape=(), dtype=float64) 0.5\n",
      "lineHarvard\tYale\t8.13\n",
      "\n",
      "Harvard Yale\n",
      "0 0.8130000000000001\n",
      "linehospital\tinfrastructure\t4.63\n",
      "\n",
      "hospital infrastructure\n",
      "123020\n",
      "53410\n",
      "tf.Tensor(0.9937260893224469, shape=(), dtype=float64) 0.46299999999999997\n",
      "linelife\tdeath\t7.88\n",
      "\n",
      "life death\n",
      "218279\n",
      "222781\n",
      "tf.Tensor(0.998617883941087, shape=(), dtype=float64) 0.788\n",
      "linetravel\tactivity\t5.00\n",
      "\n",
      "travel activity\n",
      "229871\n",
      "100553\n",
      "tf.Tensor(0.9962380110858007, shape=(), dtype=float64) 0.5\n",
      "linetype\tkind\t8.97\n",
      "\n",
      "type kind\n",
      "242046\n",
      "113499\n",
      "tf.Tensor(0.9975357629811459, shape=(), dtype=float64) 0.897\n",
      "linestreet\tplace\t6.44\n",
      "\n",
      "street place\n",
      "38212\n",
      "8513\n",
      "tf.Tensor(0.9974622273864501, shape=(), dtype=float64) 0.644\n",
      "linestreet\tavenue\t8.88\n",
      "\n",
      "street avenue\n",
      "38212\n",
      "185042\n",
      "tf.Tensor(0.9978039494092532, shape=(), dtype=float64) 0.8880000000000001\n",
      "linestreet\tblock\t6.88\n",
      "\n",
      "street block\n",
      "38212\n",
      "163182\n",
      "tf.Tensor(0.9961775891921949, shape=(), dtype=float64) 0.688\n",
      "linecell\tphone\t7.81\n",
      "\n",
      "cell phone\n",
      "172545\n",
      "148911\n",
      "tf.Tensor(0.9943726049816815, shape=(), dtype=float64) 0.7809999999999999\n",
      "linedividend\tpayment\t7.63\n",
      "\n",
      "dividend payment\n",
      "196637\n",
      "157948\n",
      "tf.Tensor(0.9816791418928261, shape=(), dtype=float64) 0.763\n",
      "linecalculation\tcomputation\t8.44\n",
      "\n",
      "calculation computation\n",
      "244356\n",
      "207244\n",
      "tf.Tensor(0.9895403688906947, shape=(), dtype=float64) 0.844\n",
      "lineprofit\tloss\t7.63\n",
      "\n",
      "profit loss\n",
      "29238\n",
      "157507\n",
      "tf.Tensor(0.9945256026470397, shape=(), dtype=float64) 0.763\n",
      "linedollar\tyen\t7.78\n",
      "\n",
      "dollar yen\n",
      "141746\n",
      "118273\n",
      "tf.Tensor(0.9901723795746968, shape=(), dtype=float64) 0.778\n",
      "linedollar\tbuck\t9.22\n",
      "\n",
      "dollar buck\n",
      "141746\n",
      "196454\n",
      "tf.Tensor(0.9930705485961382, shape=(), dtype=float64) 0.922\n",
      "linephone\tequipment\t7.13\n",
      "\n",
      "phone equipment\n",
      "148911\n",
      "17830\n",
      "tf.Tensor(0.99491288878023, shape=(), dtype=float64) 0.713\n",
      "lineliquid\twater\t7.89\n",
      "\n",
      "liquid water\n",
      "137611\n",
      "38284\n",
      "tf.Tensor(0.9942946734983646, shape=(), dtype=float64) 0.7889999999999999\n",
      "linemarathon\tsprint\t7.47\n",
      "\n",
      "marathon sprint\n",
      "196042\n",
      "226418\n",
      "tf.Tensor(0.9886250251052396, shape=(), dtype=float64) 0.747\n",
      "lineseafood\tfood\t8.34\n",
      "\n",
      "seafood food\n",
      "8472\n",
      "242035\n",
      "tf.Tensor(0.9856217828802154, shape=(), dtype=float64) 0.834\n",
      "lineseafood\tlobster\t8.70\n",
      "\n",
      "seafood lobster\n",
      "8472\n",
      "42032\n",
      "tf.Tensor(0.9875780819762274, shape=(), dtype=float64) 0.8699999999999999\n",
      "linelobster\tfood\t7.81\n",
      "\n",
      "lobster food\n",
      "42032\n",
      "242035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.9901948890446421, shape=(), dtype=float64) 0.7809999999999999\n",
      "linelobster\twine\t5.70\n",
      "\n",
      "lobster wine\n",
      "42032\n",
      "5668\n",
      "tf.Tensor(0.9888609749434425, shape=(), dtype=float64) 0.5700000000000001\n",
      "linechampionship\ttournament\t8.36\n",
      "\n",
      "championship tournament\n",
      "97374\n",
      "161120\n",
      "tf.Tensor(0.9969243464765138, shape=(), dtype=float64) 0.836\n",
      "lineman\twoman\t8.30\n",
      "\n",
      "man woman\n",
      "108231\n",
      "82521\n",
      "tf.Tensor(0.9985360444484157, shape=(), dtype=float64) 0.8300000000000001\n",
      "lineman\tgovernor\t5.25\n",
      "\n",
      "man governor\n",
      "108231\n",
      "34291\n",
      "tf.Tensor(0.9950961102202455, shape=(), dtype=float64) 0.525\n",
      "linemurder\tmanslaughter\t8.53\n",
      "\n",
      "murder manslaughter\n",
      "41798\n",
      "16982\n",
      "tf.Tensor(0.9828662558136521, shape=(), dtype=float64) 0.853\n",
      "lineopera\tperformance\t6.88\n",
      "\n",
      "opera performance\n",
      "190922\n",
      "126124\n",
      "tf.Tensor(0.9956332016512035, shape=(), dtype=float64) 0.688\n",
      "lineMexico\tBrazil\t7.44\n",
      "\n",
      "Mexico Brazil\n",
      "0 0.744\n",
      "lineglass\tmetal\t5.56\n",
      "\n",
      "glass metal\n",
      "217762\n",
      "38702\n",
      "tf.Tensor(0.9960296331239658, shape=(), dtype=float64) 0.5559999999999999\n",
      "linealuminum\tmetal\t7.83\n",
      "\n",
      "aluminum metal\n",
      "224132\n",
      "38702\n",
      "tf.Tensor(0.991354369868982, shape=(), dtype=float64) 0.783\n",
      "linerock\tjazz\t7.59\n",
      "\n",
      "rock jazz\n",
      "64217\n",
      "101161\n",
      "tf.Tensor(0.9954958609347211, shape=(), dtype=float64) 0.759\n",
      "linemuseum\ttheater\t7.19\n",
      "\n",
      "museum theater\n",
      "69364\n",
      "80135\n",
      "tf.Tensor(0.9953437348943109, shape=(), dtype=float64) 0.7190000000000001\n",
      "lineshower\tthunderstorm\t6.31\n",
      "\n",
      "shower thunderstorm\n",
      "8562\n",
      "103126\n",
      "tf.Tensor(0.979960556561385, shape=(), dtype=float64) 0.631\n",
      "linemonk\toracle\t5.00\n",
      "\n",
      "monk oracle\n",
      "15676\n",
      "85228\n",
      "tf.Tensor(0.9870290261856445, shape=(), dtype=float64) 0.5\n",
      "linecup\tfood\t5.00\n",
      "\n",
      "cup food\n",
      "76390\n",
      "242035\n",
      "tf.Tensor(0.9938310253465306, shape=(), dtype=float64) 0.5\n",
      "linejournal\tassociation\t4.97\n",
      "\n",
      "journal association\n",
      "76996\n",
      "181634\n",
      "tf.Tensor(0.9964533590845837, shape=(), dtype=float64) 0.497\n",
      "linestreet\tchildren\t4.94\n",
      "\n",
      "street children\n",
      "38212\n",
      "88993\n",
      "tf.Tensor(0.9968967804741444, shape=(), dtype=float64) 0.49400000000000005\n",
      "linecar\tflight\t4.94\n",
      "\n",
      "car flight\n",
      "35611\n",
      "124617\n",
      "tf.Tensor(0.9954979880017323, shape=(), dtype=float64) 0.49400000000000005\n",
      "linespace\tchemistry\t4.88\n",
      "\n",
      "space chemistry\n",
      "259973\n",
      "203425\n",
      "tf.Tensor(0.9928240794829684, shape=(), dtype=float64) 0.488\n",
      "linesituation\tconclusion\t4.81\n",
      "\n",
      "situation conclusion\n",
      "97928\n",
      "39427\n",
      "tf.Tensor(0.9968066206922042, shape=(), dtype=float64) 0.481\n",
      "lineword\tsimilarity\t4.75\n",
      "\n",
      "word similarity\n",
      "104067\n",
      "250379\n",
      "tf.Tensor(0.9938431298766841, shape=(), dtype=float64) 0.475\n",
      "linepeace\tplan\t4.75\n",
      "\n",
      "peace plan\n",
      "223787\n",
      "56679\n",
      "tf.Tensor(0.995954097573311, shape=(), dtype=float64) 0.475\n",
      "lineconsumer\tenergy\t4.75\n",
      "\n",
      "consumer energy\n",
      "11489\n",
      "87034\n",
      "tf.Tensor(0.9944315719550988, shape=(), dtype=float64) 0.475\n",
      "lineministry\tculture\t4.69\n",
      "\n",
      "ministry culture\n",
      "229556\n",
      "5225\n",
      "tf.Tensor(0.995977853395946, shape=(), dtype=float64) 0.46900000000000003\n",
      "linesmart\tstudent\t4.62\n",
      "\n",
      "smart student\n",
      "254362\n",
      "64856\n",
      "tf.Tensor(0.9949578092436899, shape=(), dtype=float64) 0.462\n",
      "lineinvestigation\teffort\t4.59\n",
      "\n",
      "investigation effort\n",
      "179917\n",
      "74221\n",
      "tf.Tensor(0.9964234778952856, shape=(), dtype=float64) 0.45899999999999996\n",
      "lineimage\tsurface\t4.56\n",
      "\n",
      "image surface\n",
      "105904\n",
      "109299\n",
      "tf.Tensor(0.9945476892376117, shape=(), dtype=float64) 0.45599999999999996\n",
      "linelife\tterm\t4.50\n",
      "\n",
      "life term\n",
      "218279\n",
      "152372\n",
      "tf.Tensor(0.9978932667834907, shape=(), dtype=float64) 0.45\n",
      "linestart\tmatch\t4.47\n",
      "\n",
      "start match\n",
      "177622\n",
      "151040\n",
      "tf.Tensor(0.9967508753832113, shape=(), dtype=float64) 0.44699999999999995\n",
      "linecomputer\tnews\t4.47\n",
      "\n",
      "computer news\n",
      "235216\n",
      "145274\n",
      "tf.Tensor(0.9953679955297878, shape=(), dtype=float64) 0.44699999999999995\n",
      "lineboard\trecommendation\t4.47\n",
      "\n",
      "board recommendation\n",
      "210344\n",
      "243659\n",
      "tf.Tensor(0.9956120823407171, shape=(), dtype=float64) 0.44699999999999995\n",
      "linelad\tbrother\t4.46\n",
      "\n",
      "lad brother\n",
      "137152\n",
      "245552\n",
      "tf.Tensor(0.9867384336771793, shape=(), dtype=float64) 0.446\n",
      "lineobservation\tarchitecture\t4.38\n",
      "\n",
      "observation architecture\n",
      "187649\n",
      "76267\n",
      "tf.Tensor(0.9920833967926062, shape=(), dtype=float64) 0.438\n",
      "linecoast\thill\t4.38\n",
      "\n",
      "coast hill\n",
      "163111\n",
      "249706\n",
      "tf.Tensor(0.9963150067453181, shape=(), dtype=float64) 0.438\n",
      "linedeployment\tdeparture\t4.25\n",
      "\n",
      "deployment departure\n",
      "115680\n",
      "158725\n",
      "tf.Tensor(0.9925193490132319, shape=(), dtype=float64) 0.425\n",
      "linebenchmark\tindex\t4.25\n",
      "\n",
      "benchmark index\n",
      "137262\n",
      "248135\n",
      "tf.Tensor(0.9889502741784328, shape=(), dtype=float64) 0.425\n",
      "lineattempt\tpeace\t4.25\n",
      "\n",
      "attempt peace\n",
      "4838\n",
      "223787\n",
      "tf.Tensor(0.9961050615539876, shape=(), dtype=float64) 0.425\n",
      "lineconsumer\tconfidence\t4.13\n",
      "\n",
      "consumer confidence\n",
      "11489\n",
      "137831\n",
      "tf.Tensor(0.9933294250998956, shape=(), dtype=float64) 0.413\n",
      "linestart\tyear\t4.06\n",
      "\n",
      "start year\n",
      "177622\n",
      "176855\n",
      "tf.Tensor(0.998689386593002, shape=(), dtype=float64) 0.40599999999999997\n",
      "linefocus\tlife\t4.06\n",
      "\n",
      "focus life\n",
      "63470\n",
      "218279\n",
      "tf.Tensor(0.9980216133907072, shape=(), dtype=float64) 0.40599999999999997\n",
      "linedevelopment\tissue\t3.97\n",
      "\n",
      "development issue\n",
      "160671\n",
      "94743\n",
      "tf.Tensor(0.9968738021196029, shape=(), dtype=float64) 0.397\n",
      "linetheater\thistory\t3.91\n",
      "\n",
      "theater history\n",
      "80135\n",
      "79762\n",
      "tf.Tensor(0.9959093784954527, shape=(), dtype=float64) 0.391\n",
      "linesituation\tisolation\t3.88\n",
      "\n",
      "situation isolation\n",
      "97928\n",
      "245101\n",
      "tf.Tensor(0.9948560122140524, shape=(), dtype=float64) 0.388\n",
      "lineprofit\twarning\t3.88\n",
      "\n",
      "profit warning\n",
      "29238\n",
      "46425\n",
      "tf.Tensor(0.9927242753562423, shape=(), dtype=float64) 0.388\n",
      "linemedia\ttrading\t3.88\n",
      "\n",
      "media trading\n",
      "118685\n",
      "74082\n",
      "tf.Tensor(0.9952046194606172, shape=(), dtype=float64) 0.388\n",
      "linechance\tcredibility\t3.88\n",
      "\n",
      "chance credibility\n",
      "224374\n",
      "26962\n",
      "tf.Tensor(0.9914832860890654, shape=(), dtype=float64) 0.388\n",
      "lineprecedent\tinformation\t3.85\n",
      "\n",
      "precedent information\n",
      "164348\n",
      "200451\n",
      "tf.Tensor(0.9915190901681223, shape=(), dtype=float64) 0.385\n",
      "linearchitecture\tcentury\t3.78\n",
      "\n",
      "architecture century\n",
      "76267\n",
      "191459\n",
      "tf.Tensor(0.9954366975244118, shape=(), dtype=float64) 0.378\n",
      "linepopulation\tdevelopment\t3.75\n",
      "\n",
      "population development\n",
      "91483\n",
      "160671\n",
      "tf.Tensor(0.9957106598040443, shape=(), dtype=float64) 0.375\n",
      "linestock\tlive\t3.73\n",
      "\n",
      "stock live\n",
      "206356\n",
      "246039\n",
      "tf.Tensor(0.9955333459412646, shape=(), dtype=float64) 0.373\n",
      "linepeace\tatmosphere\t3.69\n",
      "\n",
      "peace atmosphere\n",
      "223787\n",
      "76544\n",
      "tf.Tensor(0.9930284166060718, shape=(), dtype=float64) 0.369\n",
      "linemorality\tmarriage\t3.69\n",
      "\n",
      "morality marriage\n",
      "46366\n",
      "85268\n",
      "tf.Tensor(0.9899996501281275, shape=(), dtype=float64) 0.369\n",
      "lineminority\tpeace\t3.69\n",
      "\n",
      "minority peace\n",
      "117779\n",
      "223787\n",
      "tf.Tensor(0.9936824908406653, shape=(), dtype=float64) 0.369\n",
      "lineatmosphere\tlandscape\t3.69\n",
      "\n",
      "atmosphere landscape\n",
      "76544\n",
      "161602\n",
      "tf.Tensor(0.9935884039421623, shape=(), dtype=float64) 0.369\n",
      "linereport\tgain\t3.63\n",
      "\n",
      "report gain\n",
      "135543\n",
      "179236\n",
      "tf.Tensor(0.996369754112606, shape=(), dtype=float64) 0.363\n",
      "linemusic\tproject\t3.63\n",
      "\n",
      "music project\n",
      "250143\n",
      "258528\n",
      "tf.Tensor(0.9973003445792572, shape=(), dtype=float64) 0.363\n",
      "lineseven\tseries\t3.56\n",
      "\n",
      "seven series\n",
      "97484\n",
      "74035\n",
      "tf.Tensor(0.99797162531313, shape=(), dtype=float64) 0.356\n",
      "lineexperience\tmusic\t3.47\n",
      "\n",
      "experience music\n",
      "91296\n",
      "250143\n",
      "tf.Tensor(0.9972874604115204, shape=(), dtype=float64) 0.34700000000000003\n",
      "lineschool\tcenter\t3.44\n",
      "\n",
      "school center\n",
      "94200\n",
      "6797\n",
      "tf.Tensor(0.9973442168626665, shape=(), dtype=float64) 0.344\n",
      "linefive\tmonth\t3.38\n",
      "\n",
      "five month\n",
      "253263\n",
      "50770\n",
      "tf.Tensor(0.9982961904126993, shape=(), dtype=float64) 0.33799999999999997\n",
      "lineannouncement\tproduction\t3.38\n",
      "\n",
      "announcement production\n",
      "155882\n",
      "97829\n",
      "tf.Tensor(0.995671129812767, shape=(), dtype=float64) 0.33799999999999997\n",
      "linemorality\timportance\t3.31\n",
      "\n",
      "morality importance\n",
      "46366\n",
      "59961\n",
      "tf.Tensor(0.9915536107936335, shape=(), dtype=float64) 0.331\n",
      "linemoney\toperation\t3.31\n",
      "\n",
      "money operation\n",
      "53013\n",
      "252931\n",
      "tf.Tensor(0.9962155360238123, shape=(), dtype=float64) 0.331\n",
      "linedelay\tnews\t3.31\n",
      "\n",
      "delay news\n",
      "145061\n",
      "145274\n",
      "tf.Tensor(0.9947357772437939, shape=(), dtype=float64) 0.331\n",
      "linegovernor\tinterview\t3.25\n",
      "\n",
      "governor interview\n",
      "34291\n",
      "208478\n",
      "tf.Tensor(0.9940588104779235, shape=(), dtype=float64) 0.325\n",
      "linepractice\tinstitution\t3.19\n",
      "\n",
      "practice institution\n",
      "43450\n",
      "246063\n",
      "tf.Tensor(0.9962832583462, shape=(), dtype=float64) 0.319\n",
      "linecentury\tnation\t3.16\n",
      "\n",
      "century nation\n",
      "191459\n",
      "159078\n",
      "tf.Tensor(0.996411346673989, shape=(), dtype=float64) 0.316\n",
      "linecoast\tforest\t3.15\n",
      "\n",
      "coast forest\n",
      "163111\n",
      "80216\n",
      "tf.Tensor(0.995802137798295, shape=(), dtype=float64) 0.315\n",
      "lineshore\twoodland\t3.08\n",
      "\n",
      "shore woodland\n",
      "95473\n",
      "188036\n",
      "tf.Tensor(0.99168340986968, shape=(), dtype=float64) 0.308\n",
      "linedrink\tcar\t3.04\n",
      "\n",
      "drink car\n",
      "245847\n",
      "35611\n",
      "tf.Tensor(0.9943630944395258, shape=(), dtype=float64) 0.304\n",
      "linepresident\tmedal\t3.00\n",
      "\n",
      "president medal\n",
      "139950\n",
      "193411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.9940840903724233, shape=(), dtype=float64) 0.3\n",
      "lineprejudice\trecognition\t3.00\n",
      "\n",
      "prejudice recognition\n",
      "230329\n",
      "192098\n",
      "tf.Tensor(0.9916047857454425, shape=(), dtype=float64) 0.3\n",
      "lineviewer\tserial\t2.97\n",
      "\n",
      "viewer serial\n",
      "244326\n",
      "180445\n",
      "tf.Tensor(0.9883580681688489, shape=(), dtype=float64) 0.29700000000000004\n",
      "linepeace\tinsurance\t2.94\n",
      "\n",
      "peace insurance\n",
      "223787\n",
      "52509\n",
      "tf.Tensor(0.99350487727538, shape=(), dtype=float64) 0.294\n",
      "lineMars\twater\t2.94\n",
      "\n",
      "Mars water\n",
      "0 0.294\n",
      "linemedia\tgain\t2.88\n",
      "\n",
      "media gain\n",
      "118685\n",
      "179236\n",
      "tf.Tensor(0.9967117219660806, shape=(), dtype=float64) 0.288\n",
      "lineprecedent\tcognition\t2.81\n",
      "\n",
      "precedent cognition\n",
      "164348\n",
      "75022\n",
      "tf.Tensor(0.9797843158485243, shape=(), dtype=float64) 0.281\n",
      "lineannouncement\teffort\t2.75\n",
      "\n",
      "announcement effort\n",
      "155882\n",
      "74221\n",
      "tf.Tensor(0.9965777544810096, shape=(), dtype=float64) 0.275\n",
      "lineline\tinsurance\t2.69\n",
      "\n",
      "line insurance\n",
      "199887\n",
      "52509\n",
      "tf.Tensor(0.9941771550492342, shape=(), dtype=float64) 0.269\n",
      "linecrane\timplement\t2.69\n",
      "\n",
      "crane implement\n",
      "88074\n",
      "121933\n",
      "tf.Tensor(0.9918753851332822, shape=(), dtype=float64) 0.269\n",
      "linedrink\tmother\t2.65\n",
      "\n",
      "drink mother\n",
      "245847\n",
      "186584\n",
      "tf.Tensor(0.9946192295952186, shape=(), dtype=float64) 0.265\n",
      "lineopera\tindustry\t2.63\n",
      "\n",
      "opera industry\n",
      "190922\n",
      "68448\n",
      "tf.Tensor(0.9940053816018604, shape=(), dtype=float64) 0.263\n",
      "linevolunteer\tmotto\t2.56\n",
      "\n",
      "volunteer motto\n",
      "92379\n",
      "149429\n",
      "tf.Tensor(0.9894795881843717, shape=(), dtype=float64) 0.256\n",
      "linelisting\tproximity\t2.56\n",
      "\n",
      "listing proximity\n",
      "183721\n",
      "33129\n",
      "tf.Tensor(0.99159235102617, shape=(), dtype=float64) 0.256\n",
      "lineprecedent\tcollection\t2.50\n",
      "\n",
      "precedent collection\n",
      "164348\n",
      "35511\n",
      "tf.Tensor(0.991362137869522, shape=(), dtype=float64) 0.25\n",
      "linecup\tarticle\t2.40\n",
      "\n",
      "cup article\n",
      "76390\n",
      "85502\n",
      "tf.Tensor(0.9942429601351732, shape=(), dtype=float64) 0.24\n",
      "linesign\trecess\t2.38\n",
      "\n",
      "sign recess\n",
      "107344\n",
      "213572\n",
      "tf.Tensor(0.9853234357486008, shape=(), dtype=float64) 0.238\n",
      "lineproblem\tairport\t2.38\n",
      "\n",
      "problem airport\n",
      "126306\n",
      "164985\n",
      "tf.Tensor(0.992898798478043, shape=(), dtype=float64) 0.238\n",
      "linereason\thypertension\t2.31\n",
      "\n",
      "reason hypertension\n",
      "109729\n",
      "124509\n",
      "tf.Tensor(0.9751040759510025, shape=(), dtype=float64) 0.231\n",
      "linedirection\tcombination\t2.25\n",
      "\n",
      "direction combination\n",
      "21956\n",
      "15235\n",
      "tf.Tensor(0.9965583754834599, shape=(), dtype=float64) 0.225\n",
      "lineWednesday\tnews\t2.22\n",
      "\n",
      "Wednesday news\n",
      "0 0.22200000000000003\n",
      "lineglass\tmagician\t2.08\n",
      "\n",
      "glass magician\n",
      "217762\n",
      "253573\n",
      "tf.Tensor(0.9910757562700354, shape=(), dtype=float64) 0.20800000000000002\n",
      "linecemetery\twoodland\t2.08\n",
      "\n",
      "cemetery woodland\n",
      "185734\n",
      "188036\n",
      "tf.Tensor(0.9903170912610777, shape=(), dtype=float64) 0.20800000000000002\n",
      "linepossibility\tgirl\t1.94\n",
      "\n",
      "possibility girl\n",
      "88682\n",
      "149247\n",
      "tf.Tensor(0.9953371764505301, shape=(), dtype=float64) 0.194\n",
      "linecup\tsubstance\t1.92\n",
      "\n",
      "cup substance\n",
      "76390\n",
      "213052\n",
      "tf.Tensor(0.9901290088297021, shape=(), dtype=float64) 0.192\n",
      "lineforest\tgraveyard\t1.85\n",
      "\n",
      "forest graveyard\n",
      "80216\n",
      "238161\n",
      "tf.Tensor(0.9910997723805335, shape=(), dtype=float64) 0.185\n",
      "linestock\tegg\t1.81\n",
      "\n",
      "stock egg\n",
      "206356\n",
      "143717\n",
      "tf.Tensor(0.9893856733214842, shape=(), dtype=float64) 0.181\n",
      "linemonth\thotel\t1.81\n",
      "\n",
      "month hotel\n",
      "50770\n",
      "110494\n",
      "tf.Tensor(0.996034892997914, shape=(), dtype=float64) 0.181\n",
      "lineenergy\tsecretary\t1.81\n",
      "\n",
      "energy secretary\n",
      "87034\n",
      "90565\n",
      "tf.Tensor(0.9940260497949225, shape=(), dtype=float64) 0.181\n",
      "lineprecedent\tgroup\t1.77\n",
      "\n",
      "precedent group\n",
      "164348\n",
      "109721\n",
      "tf.Tensor(0.9916052590897368, shape=(), dtype=float64) 0.177\n",
      "lineproduction\thike\t1.75\n",
      "\n",
      "production hike\n",
      "97829\n",
      "7821\n",
      "tf.Tensor(0.9802644304883428, shape=(), dtype=float64) 0.175\n",
      "linestock\tphone\t1.62\n",
      "\n",
      "stock phone\n",
      "206356\n",
      "148911\n",
      "tf.Tensor(0.9937746011306494, shape=(), dtype=float64) 0.162\n",
      "lineholy\tsex\t1.62\n",
      "\n",
      "holy sex\n",
      "161121\n",
      "235857\n",
      "tf.Tensor(0.9927374129240417, shape=(), dtype=float64) 0.162\n",
      "linestock\tCD\t1.31\n",
      "\n",
      "stock CD\n",
      "0 0.131\n",
      "linedrink\tear\t1.31\n",
      "\n",
      "drink ear\n",
      "245847\n",
      "98329\n",
      "tf.Tensor(0.9902410409441906, shape=(), dtype=float64) 0.131\n",
      "linedelay\tracism\t1.19\n",
      "\n",
      "delay racism\n",
      "145061\n",
      "68076\n",
      "tf.Tensor(0.9911526253633478, shape=(), dtype=float64) 0.119\n",
      "linestock\tlife\t0.92\n",
      "\n",
      "stock life\n",
      "206356\n",
      "218279\n",
      "tf.Tensor(0.9956750195918873, shape=(), dtype=float64) 0.092\n",
      "linestock\tjaguar\t0.92\n",
      "\n",
      "stock jaguar\n",
      "206356\n",
      "45474\n",
      "tf.Tensor(0.9883986173103221, shape=(), dtype=float64) 0.092\n",
      "linemonk\tslave\t0.92\n",
      "\n",
      "monk slave\n",
      "15676\n",
      "133437\n",
      "tf.Tensor(0.990699752590601, shape=(), dtype=float64) 0.092\n",
      "linelad\twizard\t0.92\n",
      "\n",
      "lad wizard\n",
      "137152\n",
      "238384\n",
      "tf.Tensor(0.9846331034332483, shape=(), dtype=float64) 0.092\n",
      "linesugar\tapproach\t0.88\n",
      "\n",
      "sugar approach\n",
      "158076\n",
      "205683\n",
      "tf.Tensor(0.9935244063890541, shape=(), dtype=float64) 0.088\n",
      "linerooster\tvoyage\t0.62\n",
      "\n",
      "rooster voyage\n",
      "176417\n",
      "162519\n",
      "tf.Tensor(0.9837745453934825, shape=(), dtype=float64) 0.062\n",
      "linenoon\tstring\t0.54\n",
      "\n",
      "noon string\n",
      "70066\n",
      "31507\n",
      "tf.Tensor(0.9908309871499483, shape=(), dtype=float64) 0.054000000000000006\n",
      "linechord\tsmile\t0.54\n",
      "\n",
      "chord smile\n",
      "87096\n",
      "133910\n",
      "tf.Tensor(0.9817449003587477, shape=(), dtype=float64) 0.054000000000000006\n",
      "lineprofessor\tcucumber\t0.31\n",
      "\n",
      "professor cucumber\n",
      "208085\n",
      "64788\n",
      "tf.Tensor(0.9657075499157283, shape=(), dtype=float64) 0.031\n",
      "lineking\tcabbage\t0.23\n",
      "\n",
      "king cabbage\n",
      "251718\n",
      "105708\n",
      "tf.Tensor(0.9705577638683198, shape=(), dtype=float64) 0.023\n",
      "Average Distance between prediction and hand assigned is tf.Tensor(0.47536722423428557, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "with open(r'.\\datasets\\wordsim353_sim_rel\\wordsim_similarity_goldstandard.txt') as file:\n",
    "\n",
    "    losses = []\n",
    "    scores = []\n",
    "\n",
    "    lines = file.readlines()\n",
    "    sum_diff = 0\n",
    "    for line in lines:\n",
    "        if(len(line) <= 1):\n",
    "            pass\n",
    "\n",
    "        print(\"line\" + line)\n",
    "        word1, word2, score10 = line.split()\n",
    "        score10 = float(score10)\n",
    "        try:\n",
    "            print(word1,word2)\n",
    "            id1 = id_dict[word1]\n",
    "            id2 = id_dict[word2]\n",
    "            print(id1)\n",
    "            print(id2)\n",
    "            vector1 = matrix_normalized[id1,:]\n",
    "            vector2 = matrix_normalized[id2,:]\n",
    "            #print(vector1)\n",
    "            #print(vector2)\n",
    "            loss = sim_01(vector1,vector2)\n",
    "        except: \n",
    "            loss = 0\n",
    "        print(str(loss),str(score10/10.0))\n",
    "        sum_diff += abs((score10/10.0) - loss)\n",
    "        losses.append(loss)\n",
    "        scores.append(score10/10.0)\n",
    "    print('Average Distance between prediction and hand assigned is ' + str(sum_diff / len(lines)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32b173bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.15898419513558842, pvalue=0.02347480205593653)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "stats.spearmanr(losses, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1ba75b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
