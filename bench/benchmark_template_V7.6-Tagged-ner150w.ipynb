{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2873f882",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from DoubleLinkedDict import bijection2int\n",
    "magicDict = bijection2int()\n",
    "\n",
    "from bench_util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f194aaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the path and the class file\n",
    "embedding_path = \".//nerTaggedwTags_150w\"\n",
    "class_file = \"ner.classes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04c2c2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimensions 500\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#AutoDetect dims\n",
    "with open(embedding_path, 'r' , encoding=\"utf-8\")  as file:\n",
    "    line0 = file.readline()\n",
    "    dimensions = len(line0.split())-1\n",
    "print(\"dimensions \"+str(dimensions))\n",
    "\n",
    "matrix = []\n",
    "with open(embedding_path, 'r' , encoding=\"utf-8\")  as f:\n",
    "    lines = f.readlines()\n",
    "    vocab_size = len(lines)\n",
    "    \n",
    "    matrix = np.zeros((vocab_size,dimensions),dtype=float)\n",
    "    for line in lines:\n",
    "        entry = line.split()\n",
    "        word, values = entry[0].strip(), entry[1:]\n",
    "        \n",
    "        magicDict.add(word)\n",
    "        vector = np.asarray(values, \"double\")\n",
    "        matrix[magicDict.getId(word),:] = vector\n",
    "\n",
    "#clean up\n",
    "matrix_normalized = tf.nn.l2_normalize(matrix,axis = 1)# only use normalised version !!!\n",
    "matrix = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91cafaf",
   "metadata": {},
   "source": [
    "# Qualitative Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81bc818b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_k(searched_word,k):\n",
    "    list = []\n",
    "    id = id_dict[searched_word]\n",
    "    searched_vector = matrix_normalized[id,:] \n",
    "    \n",
    "    for word in id_dict:\n",
    "        word_weights = matrix_normalized[id_dict[word]]\n",
    "        loss = tf.tensordot(word_weights,searched_vector,axes = 1).numpy()\n",
    "        list = insert(list,(word,loss))\n",
    "        if len(list) > k:\n",
    "            list = list[0:k+1]\n",
    "    return list[0:k]\n",
    "\n",
    "# Function to insert element\n",
    "def insert(list, tuple):\n",
    "    (word,n) = tuple\n",
    "    if(len(list) == 0):\n",
    "        list = [(word,n)]\n",
    "    # Searching for the position\n",
    "    for i in range(len(list)):\n",
    "        (word_i,n_i) = list[i]\n",
    "        if n_i < n:\n",
    "            index = i\n",
    "            break\n",
    "      \n",
    "    # Inserting n in the list\n",
    "    list = list[:i] + [(word,n)] + list[i:]\n",
    "    return list\n",
    "\n",
    "def unzip(some_list):\n",
    "    return [ i for i, j in some_list ]\n",
    "    \n",
    "# take nearest 6 and remove the searched word itself\n",
    "# print(unzip(find_nearest_k('bank' ,7)[1:]))#the food or the place\n",
    "# print(unzip(find_nearest_k('apple',7)[1:]))#location or to to speak to\n",
    "# print(unzip(find_nearest_k('so'   ,7)[1:]))#noun (animal) or verb \n",
    "# print(unzip(find_nearest_k('desert',   6)[1:]))#animal or verb\n",
    "# print(unzip(find_nearest_k('left',   6)[1:]))#adverb (direction) and verb(the plane left)\n",
    "# print(unzip(find_nearest_k('duck',   6)[1:]))# The president of the bank walked along the river bank.\n",
    "# print(\"--------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ecb557",
   "metadata": {},
   "source": [
    "# Prepare Analogies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37a44f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_candidate(sim,exclusion_list_ids,isMult):\n",
    "    for exclude_id in exclusion_list_ids:\n",
    "        if isMult:\n",
    "             sim[exclude_id] = 0#lowest possible value in 3CosMult\n",
    "        else:\n",
    "            sim[exclude_id] = -1#lowest possible value in 3CosAdd\n",
    "    return np.argmax(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c0a557b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GPE', 'GPE', 'GPE', '', '', '', '', '', '', '', 'GPE', '', '', '']\n",
      "['GPE', 'GPE', 'GPE', '', '', '', '', '', '', '', 'NORP', '', '', '']\n"
     ]
    }
   ],
   "source": [
    "#prepare classes of anaglogies.\n",
    "#ner.classes or treebank_pos.classes or universal_pos.classes\n",
    "inTags = []\n",
    "outTags = []\n",
    "with open(\".\\\\datasets\\\\question-data\\\\\"+class_file) as classes:\n",
    "    lines = [line.split(\"#\")[0] for line in classes.readlines()]\n",
    "    for class_line in lines:\n",
    "        if \"=>\" in class_line:\n",
    "            parts = class_line.split(\"=>\")\n",
    "            inTags.append(parts[0].strip())\n",
    "            outTags.append(parts[1].strip())\n",
    "        else:\n",
    "            inTags.append(class_line)\n",
    "            outTags.append(class_line)\n",
    "print(inTags)\n",
    "print(outTags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "984d2699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loc': True, 'person': True, 'work_of_art': True, 'gpe': True, '': True, 'quantity': True, 'org': True, 'law': True, 'event': True, 'cardinal': True, 'date': True, 'norp': True, 'fac': True, 'product': True, 'ordinal': True, 'percent': True, 'time': True, 'money': True, 'language': True}\n"
     ]
    }
   ],
   "source": [
    "#step one, find all the tags.\n",
    "used_tags = {}\n",
    "for word in magicDict.getThings():#a little hacky, but small application\n",
    "    if chr(4) in word:\n",
    "        tag = word.split(chr(4))[1]\n",
    "        if tag not in used_tags:\n",
    "            used_tags[tag] = True\n",
    "print(used_tags)\n",
    "\n",
    "#step two, split word_dict into these tags.\n",
    "dict_of_tagdicts      = {}\n",
    "dict_of_Norm_matrices = {}\n",
    "\n",
    "for tag in used_tags:\n",
    "    dict_of_tagdicts[tag] = bijection2int()\n",
    "    dict_of_Norm_matrices[tag] = []\n",
    "    \n",
    "#benchmark specific\n",
    "for tagOrTags in list(set(inTags) | set(outTags)):\n",
    "    tagOrTags = tagOrTags.lower()\n",
    "    if \",\" in tagOrTags:#if multi tag\n",
    "        dict_of_tagdicts[tagOrTags] = bijection2int()\n",
    "        dict_of_Norm_matrices[tagOrTags] = []\n",
    "\n",
    "for tagged_token in magicDict.getThings():\n",
    "    if chr(4) in tagged_token:\n",
    "        split = tagged_token.split(chr(4))\n",
    "        word,tag  = split[0],split[1]\n",
    "        \n",
    "        id_base = magicDict.getId(tagged_token)\n",
    "        dict_of_Norm_matrices[tag].append(matrix_normalized[id_base])\n",
    "        \n",
    "        dict_of_tagdicts[tag].add(word)\n",
    "        for  key in dict_of_tagdicts:\n",
    "            if \",\" in key and tag in key:\n",
    "                key = key.lower()\n",
    "                dict_of_tagdicts[key].add(word)\n",
    "                dict_of_Norm_matrices[key].append(matrix_normalized[id_base])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a646d761",
   "metadata": {},
   "source": [
    "# 3cosAdd normalised befor arithmetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "383f8d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_cos_predict_np_norm(a,a_star,b,b_star,dict1,dict2,m1,m2):\n",
    "    if not (dict1.containsAll([a,b]) and dict2.containsAll([a_star,b_star])):\n",
    "        return None\n",
    "    \n",
    "    id_a = dict1.getId(a)\n",
    "    id_b = dict1.getId(b)\n",
    "    id_a_star = dict2.getId(a_star)\n",
    "    \n",
    "    weight_a = m1[id_a]\n",
    "    weight_b = m1[id_b]\n",
    "    weight_a_star = m2[id_a_star]\n",
    "    direction = weight_b + ( weight_a_star - weight_a)\n",
    "    direction /= np.linalg.norm(direction)\n",
    "    \n",
    "    if dict1 == dict2:\n",
    "        exclusion = [id_a,id_b,id_a_star]\n",
    "    else:\n",
    "        exclusion = [id_a_star]#the other are not part of the dict\n",
    "    sim = tf.tensordot(tf.convert_to_tensor(m2),tf.convert_to_tensor(direction),axes = 1)\n",
    "    index = find_candidate(sim.numpy(),exclusion,False)\n",
    "    return dict2.getThingById(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4042c364",
   "metadata": {},
   "source": [
    "## 3cos Mult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ac07eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_01(matrix,weight):\n",
    "    tmp = tf.tensordot(matrix,weight,axes=1)\n",
    "    tmp = (tmp+1.0)/2.0\n",
    "    return tmp\n",
    "\n",
    "def predict_three_cos_mult(a,a_star,b,b_star,dict1,dict2,m1,m2):\n",
    "    if not (dict1.containsAll([a,b]) and dict2.containsAll([a_star,b_star])):\n",
    "        return None\n",
    "    \n",
    "    id_a = dict1.getId(a)\n",
    "    id_b = dict1.getId(b)\n",
    "    id_a_star = dict2.getId(a_star)\n",
    "    \n",
    "    if dict1 == dict2:\n",
    "        exclusion = [id_a,id_b,id_a_star]\n",
    "    else:\n",
    "        exclusion = [id_a_star]\n",
    "    \n",
    "    weight_a = m1[id_a]\n",
    "    weight_b = m1[id_b]\n",
    "    weight_a_star = m2[id_a_star]\n",
    "    \n",
    "    nominator = sim_01(m2,weight_a_star) * sim_01(m2,weight_b) \n",
    "    denominator = sim_01(m2,weight_a) + 0.0001\n",
    "    sim = nominator / denominator\n",
    "    index = find_candidate(sim.numpy(),exclusion,True)\n",
    "    return dict2.getThingById(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c53d10",
   "metadata": {},
   "source": [
    "# Test all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2911b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_results(add,mult):\n",
    "    add_string = str(add)\n",
    "    add_string = add_string.lstrip('0')\n",
    "    add_string = format(add_string, \".4\")\n",
    "    mult_string = str(mult)\n",
    "    mult_string = mult_string.lstrip('0')\n",
    "    mult_string = format(mult_string, \".4\")\n",
    "    return add_string +'/'+mult_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91e1a1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[76157, 163261, 164074]\n",
      "nod\u0004org\n",
      "bachata\u0004\n"
     ]
    }
   ],
   "source": [
    "def find_variants(word,magicGlobal):\n",
    "    ids= []\n",
    "    for w in magicGlobal.getThings():\n",
    "        if w.startswith(word+chr(4)):\n",
    "            ids.append(magicGlobal.getId(w))\n",
    "    return ids\n",
    "\n",
    "print(find_variants(\"kuna\",magicDict))\n",
    "print(magicDict.getThingById(106965))\n",
    "print(magicDict.getThingById(147466))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eecd5ce6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "capital-common-countries.txt\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      ".685/.618\n",
      "out of Vocab:0\n",
      "-------------------\n",
      "capital-world.txt\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      ".450/.379\n",
      "out of Vocab:308\n",
      "-------------------\n",
      "city-in-state.txt\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      ".512/.400\n",
      "out of Vocab:73\n",
      "-------------------\n",
      "currency.txt\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      ".017/.020\n",
      "out of Vocab:168\n",
      "-------------------\n",
      "family.txt\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      ".658/.602\n",
      "out of Vocab:0\n",
      "-------------------\n",
      "gram1-adjective-to-adverb.txt\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      ".141/.164\n",
      "out of Vocab:0\n",
      "-------------------\n",
      "gram2-opposite.txt\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      ".259/.251\n",
      "out of Vocab:0\n",
      "-------------------\n",
      "gram3-comparative.txt\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      ".778/.746\n",
      "out of Vocab:0\n",
      "-------------------\n",
      "gram4-superlative.txt\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      ".357/.377\n",
      "out of Vocab:66\n",
      "-------------------\n",
      "gram5-present-participle.txt\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      ".560/.569\n",
      "out of Vocab:0\n",
      "-------------------\n",
      "gram6-nationality-adjective.txt\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      ".839/.813\n",
      "out of Vocab:0\n",
      "-------------------\n",
      "gram7-past-tense.txt\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      ".489/.479\n",
      "out of Vocab:0\n",
      "-------------------\n",
      "gram8-plural.txt\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      ".697/.644\n",
      "out of Vocab:0\n",
      "-------------------\n",
      "gram9-plural-verbs.txt\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      ".522/.556\n",
      "out of Vocab:0\n",
      "-------------------\n",
      "ner.classes\n",
      "treebank_pos.classes\n",
      "universal_pos.classes\n",
      "semantical\n",
      ".450/.376\n",
      "syntactical\n",
      ".661/.651\n",
      "overall\n",
      ".504/.466\n"
     ]
    }
   ],
   "source": [
    "count_sem_questions =  0\n",
    "count_syn_questions =  0\n",
    "\n",
    "count_sem_sucess      = [0,0,0]\n",
    "count_syn_sucess      = [0,0,0]\n",
    "\n",
    "errors = []\n",
    "\n",
    "files = os.listdir('.\\\\datasets\\\\question-data')\n",
    "for idx,file_name in enumerate(sorted(files)):\n",
    "    print(file_name)\n",
    "    with open('.\\\\datasets\\\\question-data\\\\'+file_name,'r') as file:\n",
    "        if file_name.endswith('.classes'):\n",
    "            continue\n",
    "\n",
    "        outOfVocab = 0\n",
    "        \n",
    "        inTag = inTags[idx].lower()\n",
    "        outTag = outTags[idx].lower()\n",
    "        lines = file.readlines()\n",
    "        local_sucesses    = [0,0,0]\n",
    "        local_tasks_count = 0\n",
    "        \n",
    "        dual_class_in  = False\n",
    "        dual_class_out = False\n",
    "        \n",
    "        \n",
    "        dict1 = dict_of_tagdicts[inTag]\n",
    "        m1    = dict_of_Norm_matrices[inTag]\n",
    "        \n",
    "        dict2 = dict_of_tagdicts[outTag]\n",
    "        m2    = dict_of_Norm_matrices[outTag]\n",
    "        \n",
    "        \n",
    "        for line_id,line in enumerate(lines):\n",
    "            if (line_id % 100 == 0):\n",
    "                print(line_id)\n",
    "            a,a_star,b,b_star = line.split(\" \")\n",
    "            b_star = b_star.strip()\n",
    "            \n",
    "            \n",
    "            \n",
    "            predicted_3cos_add_norm = three_cos_predict_np_norm(a,a_star,b,b_star,dict1,dict2,m1,m2)\n",
    "            predicted_3cos_mult     = predict_three_cos_mult(a,a_star,b,b_star,dict1,dict2,m1,m2)\n",
    "            #clean up, of tagged predictions\n",
    "\n",
    "            if predicted_3cos_add_norm == None:\n",
    "                outOfVocab+= 1\n",
    "\n",
    "\n",
    "            if predicted_3cos_add_norm != None and chr(4) in predicted_3cos_add_norm:\n",
    "                predicted_3cos_add_norm = predicted_3cos_add_norm.split(chr(4))[0]\n",
    "            if predicted_3cos_mult != None and chr(4) in predicted_3cos_mult:\n",
    "                predicted_3cos_mult = predicted_3cos_mult.split(chr(4))[0]\n",
    "            \n",
    "            if(idx < 5):#first 5 are sem\n",
    "                count_sem_questions += 1\n",
    "                local_tasks_count   += 1\n",
    "                \n",
    "                if predicted_3cos_add_norm == b_star:\n",
    "                    local_sucesses[1] += 1\n",
    "                    count_sem_sucess[1] += 1\n",
    "                    \n",
    "                if  predicted_3cos_mult    == b_star:\n",
    "                    local_sucesses[2] += 1\n",
    "                    count_sem_sucess[2] += 1\n",
    "            else:\n",
    "                count_syn_questions += 1\n",
    "                local_tasks_count   += 1\n",
    "                \n",
    "                if predicted_3cos_add_norm == b_star:\n",
    "                    local_sucesses[1] += 1\n",
    "                    count_syn_sucess[1] += 1\n",
    "                    \n",
    "                if  predicted_3cos_mult    == b_star:\n",
    "                    local_sucesses[2] += 1\n",
    "                    count_syn_sucess[2] += 1\n",
    "                    \n",
    "        print(format_results(local_sucesses[1]/float(local_tasks_count),local_sucesses[2]/float(local_tasks_count)))\n",
    "        print(\"out of Vocab:\"+str(outOfVocab))\n",
    "        print('-------------------')\n",
    "\n",
    "print('semantical')\n",
    "print(format_results(count_sem_sucess[1]/float(count_sem_questions),count_sem_sucess[2]/float(count_sem_questions)))\n",
    "\n",
    "print('syntactical')\n",
    "print(format_results(count_syn_sucess[1]/float(count_syn_questions),count_syn_sucess[2]/float(count_syn_questions)))\n",
    "\n",
    "print('overall')\n",
    "print(format_results((count_syn_sucess[1]+count_sem_sucess[1])/float(count_sem_questions+count_syn_questions), \\\n",
    "                     (count_syn_sucess[2]+count_sem_sucess[2])/float(count_sem_questions+count_syn_questions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c15546d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import winsound\n",
    "winsound.Beep(440, 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb4fdf0",
   "metadata": {},
   "source": [
    "# Spearman Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa2916f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linetiger\tcat\t7.35\n",
      "\n",
      "tiger cat\n",
      "0 0.735\n",
      "linetiger\ttiger\t10.00\n",
      "\n",
      "tiger tiger\n",
      "0 1.0\n",
      "lineplane\tcar\t5.77\n",
      "\n",
      "plane car\n",
      "0 0.577\n",
      "linetrain\tcar\t6.31\n",
      "\n",
      "train car\n",
      "0 0.631\n",
      "linetelevision\tradio\t6.77\n",
      "\n",
      "television radio\n",
      "0 0.6769999999999999\n",
      "linemedia\tradio\t7.42\n",
      "\n",
      "media radio\n",
      "0 0.742\n",
      "linebread\tbutter\t6.19\n",
      "\n",
      "bread butter\n",
      "0 0.619\n",
      "linecucumber\tpotato\t5.92\n",
      "\n",
      "cucumber potato\n",
      "0 0.592\n",
      "linedoctor\tnurse\t7.00\n",
      "\n",
      "doctor nurse\n",
      "0 0.7\n",
      "lineprofessor\tdoctor\t6.62\n",
      "\n",
      "professor doctor\n",
      "0 0.662\n",
      "linestudent\tprofessor\t6.81\n",
      "\n",
      "student professor\n",
      "0 0.6809999999999999\n",
      "linesmart\tstupid\t5.81\n",
      "\n",
      "smart stupid\n",
      "0 0.581\n",
      "linewood\tforest\t7.73\n",
      "\n",
      "wood forest\n",
      "0 0.773\n",
      "linemoney\tcash\t9.15\n",
      "\n",
      "money cash\n",
      "0 0.915\n",
      "lineking\tqueen\t8.58\n",
      "\n",
      "king queen\n",
      "0 0.858\n",
      "lineking\trook\t5.92\n",
      "\n",
      "king rook\n",
      "0 0.592\n",
      "linebishop\trabbi\t6.69\n",
      "\n",
      "bishop rabbi\n",
      "0 0.669\n",
      "linefuck\tsex\t9.44\n",
      "\n",
      "fuck sex\n",
      "0 0.944\n",
      "linefootball\tsoccer\t9.03\n",
      "\n",
      "football soccer\n",
      "0 0.9029999999999999\n",
      "linefootball\tbasketball\t6.81\n",
      "\n",
      "football basketball\n",
      "0 0.6809999999999999\n",
      "linefootball\ttennis\t6.63\n",
      "\n",
      "football tennis\n",
      "0 0.663\n",
      "lineArafat\tJackson\t2.50\n",
      "\n",
      "Arafat Jackson\n",
      "0 0.25\n",
      "linephysics\tchemistry\t7.35\n",
      "\n",
      "physics chemistry\n",
      "0 0.735\n",
      "linevodka\tgin\t8.46\n",
      "\n",
      "vodka gin\n",
      "0 0.8460000000000001\n",
      "linevodka\tbrandy\t8.13\n",
      "\n",
      "vodka brandy\n",
      "0 0.8130000000000001\n",
      "linedrink\teat\t6.87\n",
      "\n",
      "drink eat\n",
      "0 0.687\n",
      "linecar\tautomobile\t8.94\n",
      "\n",
      "car automobile\n",
      "0 0.8939999999999999\n",
      "linegem\tjewel\t8.96\n",
      "\n",
      "gem jewel\n",
      "0 0.8960000000000001\n",
      "linejourney\tvoyage\t9.29\n",
      "\n",
      "journey voyage\n",
      "0 0.9289999999999999\n",
      "lineboy\tlad\t8.83\n",
      "\n",
      "boy lad\n",
      "0 0.883\n",
      "linecoast\tshore\t9.10\n",
      "\n",
      "coast shore\n",
      "0 0.9099999999999999\n",
      "lineasylum\tmadhouse\t8.87\n",
      "\n",
      "asylum madhouse\n",
      "0 0.8869999999999999\n",
      "linemagician\twizard\t9.02\n",
      "\n",
      "magician wizard\n",
      "0 0.9019999999999999\n",
      "linemidday\tnoon\t9.29\n",
      "\n",
      "midday noon\n",
      "0 0.9289999999999999\n",
      "linefurnace\tstove\t8.79\n",
      "\n",
      "furnace stove\n",
      "0 0.8789999999999999\n",
      "linefood\tfruit\t7.52\n",
      "\n",
      "food fruit\n",
      "0 0.752\n",
      "linebird\tcock\t7.10\n",
      "\n",
      "bird cock\n",
      "0 0.71\n",
      "linebird\tcrane\t7.38\n",
      "\n",
      "bird crane\n",
      "0 0.738\n",
      "linefood\trooster\t4.42\n",
      "\n",
      "food rooster\n",
      "0 0.442\n",
      "linemoney\tdollar\t8.42\n",
      "\n",
      "money dollar\n",
      "0 0.842\n",
      "linemoney\tcurrency\t9.04\n",
      "\n",
      "money currency\n",
      "0 0.9039999999999999\n",
      "linetiger\tjaguar\t8.00\n",
      "\n",
      "tiger jaguar\n",
      "0 0.8\n",
      "linetiger\tfeline\t8.00\n",
      "\n",
      "tiger feline\n",
      "0 0.8\n",
      "linetiger\tcarnivore\t7.08\n",
      "\n",
      "tiger carnivore\n",
      "0 0.708\n",
      "linetiger\tmammal\t6.85\n",
      "\n",
      "tiger mammal\n",
      "0 0.6849999999999999\n",
      "linetiger\tanimal\t7.00\n",
      "\n",
      "tiger animal\n",
      "0 0.7\n",
      "linetiger\torganism\t4.77\n",
      "\n",
      "tiger organism\n",
      "0 0.477\n",
      "linetiger\tfauna\t5.62\n",
      "\n",
      "tiger fauna\n",
      "0 0.562\n",
      "linepsychology\tpsychiatry\t8.08\n",
      "\n",
      "psychology psychiatry\n",
      "0 0.808\n",
      "linepsychology\tscience\t6.71\n",
      "\n",
      "psychology science\n",
      "0 0.671\n",
      "linepsychology\tdiscipline\t5.58\n",
      "\n",
      "psychology discipline\n",
      "0 0.558\n",
      "lineplanet\tstar\t8.45\n",
      "\n",
      "planet star\n",
      "0 0.845\n",
      "lineplanet\tmoon\t8.08\n",
      "\n",
      "planet moon\n",
      "0 0.808\n",
      "lineplanet\tsun\t8.02\n",
      "\n",
      "planet sun\n",
      "0 0.8019999999999999\n",
      "lineprecedent\texample\t5.85\n",
      "\n",
      "precedent example\n",
      "0 0.585\n",
      "lineprecedent\tantecedent\t6.04\n",
      "\n",
      "precedent antecedent\n",
      "0 0.604\n",
      "linecup\ttableware\t6.85\n",
      "\n",
      "cup tableware\n",
      "0 0.6849999999999999\n",
      "linecup\tartifact\t2.92\n",
      "\n",
      "cup artifact\n",
      "0 0.292\n",
      "linecup\tobject\t3.69\n",
      "\n",
      "cup object\n",
      "0 0.369\n",
      "linecup\tentity\t2.15\n",
      "\n",
      "cup entity\n",
      "0 0.215\n",
      "linejaguar\tcat\t7.42\n",
      "\n",
      "jaguar cat\n",
      "0 0.742\n",
      "linejaguar\tcar\t7.27\n",
      "\n",
      "jaguar car\n",
      "0 0.727\n",
      "linemile\tkilometer\t8.66\n",
      "\n",
      "mile kilometer\n",
      "0 0.866\n",
      "lineskin\teye\t6.22\n",
      "\n",
      "skin eye\n",
      "0 0.622\n",
      "lineJapanese\tAmerican\t6.50\n",
      "\n",
      "Japanese American\n",
      "0 0.65\n",
      "linecentury\tyear\t7.59\n",
      "\n",
      "century year\n",
      "0 0.759\n",
      "lineannouncement\tnews\t7.56\n",
      "\n",
      "announcement news\n",
      "0 0.756\n",
      "linedoctor\tpersonnel\t5.00\n",
      "\n",
      "doctor personnel\n",
      "0 0.5\n",
      "lineHarvard\tYale\t8.13\n",
      "\n",
      "Harvard Yale\n",
      "0 0.8130000000000001\n",
      "linehospital\tinfrastructure\t4.63\n",
      "\n",
      "hospital infrastructure\n",
      "0 0.46299999999999997\n",
      "linelife\tdeath\t7.88\n",
      "\n",
      "life death\n",
      "0 0.788\n",
      "linetravel\tactivity\t5.00\n",
      "\n",
      "travel activity\n",
      "0 0.5\n",
      "linetype\tkind\t8.97\n",
      "\n",
      "type kind\n",
      "0 0.897\n",
      "linestreet\tplace\t6.44\n",
      "\n",
      "street place\n",
      "0 0.644\n",
      "linestreet\tavenue\t8.88\n",
      "\n",
      "street avenue\n",
      "0 0.8880000000000001\n",
      "linestreet\tblock\t6.88\n",
      "\n",
      "street block\n",
      "0 0.688\n",
      "linecell\tphone\t7.81\n",
      "\n",
      "cell phone\n",
      "0 0.7809999999999999\n",
      "linedividend\tpayment\t7.63\n",
      "\n",
      "dividend payment\n",
      "0 0.763\n",
      "linecalculation\tcomputation\t8.44\n",
      "\n",
      "calculation computation\n",
      "0 0.844\n",
      "lineprofit\tloss\t7.63\n",
      "\n",
      "profit loss\n",
      "0 0.763\n",
      "linedollar\tyen\t7.78\n",
      "\n",
      "dollar yen\n",
      "0 0.778\n",
      "linedollar\tbuck\t9.22\n",
      "\n",
      "dollar buck\n",
      "0 0.922\n",
      "linephone\tequipment\t7.13\n",
      "\n",
      "phone equipment\n",
      "0 0.713\n",
      "lineliquid\twater\t7.89\n",
      "\n",
      "liquid water\n",
      "0 0.7889999999999999\n",
      "linemarathon\tsprint\t7.47\n",
      "\n",
      "marathon sprint\n",
      "0 0.747\n",
      "lineseafood\tfood\t8.34\n",
      "\n",
      "seafood food\n",
      "0 0.834\n",
      "lineseafood\tlobster\t8.70\n",
      "\n",
      "seafood lobster\n",
      "0 0.8699999999999999\n",
      "linelobster\tfood\t7.81\n",
      "\n",
      "lobster food\n",
      "0 0.7809999999999999\n",
      "linelobster\twine\t5.70\n",
      "\n",
      "lobster wine\n",
      "0 0.5700000000000001\n",
      "linechampionship\ttournament\t8.36\n",
      "\n",
      "championship tournament\n",
      "0 0.836\n",
      "lineman\twoman\t8.30\n",
      "\n",
      "man woman\n",
      "0 0.8300000000000001\n",
      "lineman\tgovernor\t5.25\n",
      "\n",
      "man governor\n",
      "0 0.525\n",
      "linemurder\tmanslaughter\t8.53\n",
      "\n",
      "murder manslaughter\n",
      "0 0.853\n",
      "lineopera\tperformance\t6.88\n",
      "\n",
      "opera performance\n",
      "0 0.688\n",
      "lineMexico\tBrazil\t7.44\n",
      "\n",
      "Mexico Brazil\n",
      "0 0.744\n",
      "lineglass\tmetal\t5.56\n",
      "\n",
      "glass metal\n",
      "0 0.5559999999999999\n",
      "linealuminum\tmetal\t7.83\n",
      "\n",
      "aluminum metal\n",
      "0 0.783\n",
      "linerock\tjazz\t7.59\n",
      "\n",
      "rock jazz\n",
      "0 0.759\n",
      "linemuseum\ttheater\t7.19\n",
      "\n",
      "museum theater\n",
      "0 0.7190000000000001\n",
      "lineshower\tthunderstorm\t6.31\n",
      "\n",
      "shower thunderstorm\n",
      "0 0.631\n",
      "linemonk\toracle\t5.00\n",
      "\n",
      "monk oracle\n",
      "0 0.5\n",
      "linecup\tfood\t5.00\n",
      "\n",
      "cup food\n",
      "0 0.5\n",
      "linejournal\tassociation\t4.97\n",
      "\n",
      "journal association\n",
      "0 0.497\n",
      "linestreet\tchildren\t4.94\n",
      "\n",
      "street children\n",
      "0 0.49400000000000005\n",
      "linecar\tflight\t4.94\n",
      "\n",
      "car flight\n",
      "0 0.49400000000000005\n",
      "linespace\tchemistry\t4.88\n",
      "\n",
      "space chemistry\n",
      "0 0.488\n",
      "linesituation\tconclusion\t4.81\n",
      "\n",
      "situation conclusion\n",
      "0 0.481\n",
      "lineword\tsimilarity\t4.75\n",
      "\n",
      "word similarity\n",
      "0 0.475\n",
      "linepeace\tplan\t4.75\n",
      "\n",
      "peace plan\n",
      "0 0.475\n",
      "lineconsumer\tenergy\t4.75\n",
      "\n",
      "consumer energy\n",
      "0 0.475\n",
      "lineministry\tculture\t4.69\n",
      "\n",
      "ministry culture\n",
      "0 0.46900000000000003\n",
      "linesmart\tstudent\t4.62\n",
      "\n",
      "smart student\n",
      "0 0.462\n",
      "lineinvestigation\teffort\t4.59\n",
      "\n",
      "investigation effort\n",
      "0 0.45899999999999996\n",
      "lineimage\tsurface\t4.56\n",
      "\n",
      "image surface\n",
      "0 0.45599999999999996\n",
      "linelife\tterm\t4.50\n",
      "\n",
      "life term\n",
      "0 0.45\n",
      "linestart\tmatch\t4.47\n",
      "\n",
      "start match\n",
      "0 0.44699999999999995\n",
      "linecomputer\tnews\t4.47\n",
      "\n",
      "computer news\n",
      "0 0.44699999999999995\n",
      "lineboard\trecommendation\t4.47\n",
      "\n",
      "board recommendation\n",
      "0 0.44699999999999995\n",
      "linelad\tbrother\t4.46\n",
      "\n",
      "lad brother\n",
      "0 0.446\n",
      "lineobservation\tarchitecture\t4.38\n",
      "\n",
      "observation architecture\n",
      "0 0.438\n",
      "linecoast\thill\t4.38\n",
      "\n",
      "coast hill\n",
      "0 0.438\n",
      "linedeployment\tdeparture\t4.25\n",
      "\n",
      "deployment departure\n",
      "0 0.425\n",
      "linebenchmark\tindex\t4.25\n",
      "\n",
      "benchmark index\n",
      "0 0.425\n",
      "lineattempt\tpeace\t4.25\n",
      "\n",
      "attempt peace\n",
      "0 0.425\n",
      "lineconsumer\tconfidence\t4.13\n",
      "\n",
      "consumer confidence\n",
      "0 0.413\n",
      "linestart\tyear\t4.06\n",
      "\n",
      "start year\n",
      "0 0.40599999999999997\n",
      "linefocus\tlife\t4.06\n",
      "\n",
      "focus life\n",
      "0 0.40599999999999997\n",
      "linedevelopment\tissue\t3.97\n",
      "\n",
      "development issue\n",
      "0 0.397\n",
      "linetheater\thistory\t3.91\n",
      "\n",
      "theater history\n",
      "0 0.391\n",
      "linesituation\tisolation\t3.88\n",
      "\n",
      "situation isolation\n",
      "0 0.388\n",
      "lineprofit\twarning\t3.88\n",
      "\n",
      "profit warning\n",
      "0 0.388\n",
      "linemedia\ttrading\t3.88\n",
      "\n",
      "media trading\n",
      "0 0.388\n",
      "linechance\tcredibility\t3.88\n",
      "\n",
      "chance credibility\n",
      "0 0.388\n",
      "lineprecedent\tinformation\t3.85\n",
      "\n",
      "precedent information\n",
      "0 0.385\n",
      "linearchitecture\tcentury\t3.78\n",
      "\n",
      "architecture century\n",
      "0 0.378\n",
      "linepopulation\tdevelopment\t3.75\n",
      "\n",
      "population development\n",
      "0 0.375\n",
      "linestock\tlive\t3.73\n",
      "\n",
      "stock live\n",
      "0 0.373\n",
      "linepeace\tatmosphere\t3.69\n",
      "\n",
      "peace atmosphere\n",
      "0 0.369\n",
      "linemorality\tmarriage\t3.69\n",
      "\n",
      "morality marriage\n",
      "0 0.369\n",
      "lineminority\tpeace\t3.69\n",
      "\n",
      "minority peace\n",
      "0 0.369\n",
      "lineatmosphere\tlandscape\t3.69\n",
      "\n",
      "atmosphere landscape\n",
      "0 0.369\n",
      "linereport\tgain\t3.63\n",
      "\n",
      "report gain\n",
      "0 0.363\n",
      "linemusic\tproject\t3.63\n",
      "\n",
      "music project\n",
      "0 0.363\n",
      "lineseven\tseries\t3.56\n",
      "\n",
      "seven series\n",
      "0 0.356\n",
      "lineexperience\tmusic\t3.47\n",
      "\n",
      "experience music\n",
      "0 0.34700000000000003\n",
      "lineschool\tcenter\t3.44\n",
      "\n",
      "school center\n",
      "0 0.344\n",
      "linefive\tmonth\t3.38\n",
      "\n",
      "five month\n",
      "0 0.33799999999999997\n",
      "lineannouncement\tproduction\t3.38\n",
      "\n",
      "announcement production\n",
      "0 0.33799999999999997\n",
      "linemorality\timportance\t3.31\n",
      "\n",
      "morality importance\n",
      "0 0.331\n",
      "linemoney\toperation\t3.31\n",
      "\n",
      "money operation\n",
      "0 0.331\n",
      "linedelay\tnews\t3.31\n",
      "\n",
      "delay news\n",
      "0 0.331\n",
      "linegovernor\tinterview\t3.25\n",
      "\n",
      "governor interview\n",
      "0 0.325\n",
      "linepractice\tinstitution\t3.19\n",
      "\n",
      "practice institution\n",
      "0 0.319\n",
      "linecentury\tnation\t3.16\n",
      "\n",
      "century nation\n",
      "0 0.316\n",
      "linecoast\tforest\t3.15\n",
      "\n",
      "coast forest\n",
      "0 0.315\n",
      "lineshore\twoodland\t3.08\n",
      "\n",
      "shore woodland\n",
      "0 0.308\n",
      "linedrink\tcar\t3.04\n",
      "\n",
      "drink car\n",
      "0 0.304\n",
      "linepresident\tmedal\t3.00\n",
      "\n",
      "president medal\n",
      "0 0.3\n",
      "lineprejudice\trecognition\t3.00\n",
      "\n",
      "prejudice recognition\n",
      "0 0.3\n",
      "lineviewer\tserial\t2.97\n",
      "\n",
      "viewer serial\n",
      "0 0.29700000000000004\n",
      "linepeace\tinsurance\t2.94\n",
      "\n",
      "peace insurance\n",
      "0 0.294\n",
      "lineMars\twater\t2.94\n",
      "\n",
      "Mars water\n",
      "0 0.294\n",
      "linemedia\tgain\t2.88\n",
      "\n",
      "media gain\n",
      "0 0.288\n",
      "lineprecedent\tcognition\t2.81\n",
      "\n",
      "precedent cognition\n",
      "0 0.281\n",
      "lineannouncement\teffort\t2.75\n",
      "\n",
      "announcement effort\n",
      "0 0.275\n",
      "lineline\tinsurance\t2.69\n",
      "\n",
      "line insurance\n",
      "0 0.269\n",
      "linecrane\timplement\t2.69\n",
      "\n",
      "crane implement\n",
      "0 0.269\n",
      "linedrink\tmother\t2.65\n",
      "\n",
      "drink mother\n",
      "0 0.265\n",
      "lineopera\tindustry\t2.63\n",
      "\n",
      "opera industry\n",
      "0 0.263\n",
      "linevolunteer\tmotto\t2.56\n",
      "\n",
      "volunteer motto\n",
      "0 0.256\n",
      "linelisting\tproximity\t2.56\n",
      "\n",
      "listing proximity\n",
      "0 0.256\n",
      "lineprecedent\tcollection\t2.50\n",
      "\n",
      "precedent collection\n",
      "0 0.25\n",
      "linecup\tarticle\t2.40\n",
      "\n",
      "cup article\n",
      "0 0.24\n",
      "linesign\trecess\t2.38\n",
      "\n",
      "sign recess\n",
      "0 0.238\n",
      "lineproblem\tairport\t2.38\n",
      "\n",
      "problem airport\n",
      "0 0.238\n",
      "linereason\thypertension\t2.31\n",
      "\n",
      "reason hypertension\n",
      "0 0.231\n",
      "linedirection\tcombination\t2.25\n",
      "\n",
      "direction combination\n",
      "0 0.225\n",
      "lineWednesday\tnews\t2.22\n",
      "\n",
      "Wednesday news\n",
      "0 0.22200000000000003\n",
      "lineglass\tmagician\t2.08\n",
      "\n",
      "glass magician\n",
      "0 0.20800000000000002\n",
      "linecemetery\twoodland\t2.08\n",
      "\n",
      "cemetery woodland\n",
      "0 0.20800000000000002\n",
      "linepossibility\tgirl\t1.94\n",
      "\n",
      "possibility girl\n",
      "0 0.194\n",
      "linecup\tsubstance\t1.92\n",
      "\n",
      "cup substance\n",
      "0 0.192\n",
      "lineforest\tgraveyard\t1.85\n",
      "\n",
      "forest graveyard\n",
      "0 0.185\n",
      "linestock\tegg\t1.81\n",
      "\n",
      "stock egg\n",
      "0 0.181\n",
      "linemonth\thotel\t1.81\n",
      "\n",
      "month hotel\n",
      "0 0.181\n",
      "lineenergy\tsecretary\t1.81\n",
      "\n",
      "energy secretary\n",
      "0 0.181\n",
      "lineprecedent\tgroup\t1.77\n",
      "\n",
      "precedent group\n",
      "0 0.177\n",
      "lineproduction\thike\t1.75\n",
      "\n",
      "production hike\n",
      "0 0.175\n",
      "linestock\tphone\t1.62\n",
      "\n",
      "stock phone\n",
      "0 0.162\n",
      "lineholy\tsex\t1.62\n",
      "\n",
      "holy sex\n",
      "0 0.162\n",
      "linestock\tCD\t1.31\n",
      "\n",
      "stock CD\n",
      "0 0.131\n",
      "linedrink\tear\t1.31\n",
      "\n",
      "drink ear\n",
      "0 0.131\n",
      "linedelay\tracism\t1.19\n",
      "\n",
      "delay racism\n",
      "0 0.119\n",
      "linestock\tlife\t0.92\n",
      "\n",
      "stock life\n",
      "0 0.092\n",
      "linestock\tjaguar\t0.92\n",
      "\n",
      "stock jaguar\n",
      "0 0.092\n",
      "linemonk\tslave\t0.92\n",
      "\n",
      "monk slave\n",
      "0 0.092\n",
      "linelad\twizard\t0.92\n",
      "\n",
      "lad wizard\n",
      "0 0.092\n",
      "linesugar\tapproach\t0.88\n",
      "\n",
      "sugar approach\n",
      "0 0.088\n",
      "linerooster\tvoyage\t0.62\n",
      "\n",
      "rooster voyage\n",
      "0 0.062\n",
      "linenoon\tstring\t0.54\n",
      "\n",
      "noon string\n",
      "0 0.054000000000000006\n",
      "linechord\tsmile\t0.54\n",
      "\n",
      "chord smile\n",
      "0 0.054000000000000006\n",
      "lineprofessor\tcucumber\t0.31\n",
      "\n",
      "professor cucumber\n",
      "0 0.031\n",
      "lineking\tcabbage\t0.23\n",
      "\n",
      "king cabbage\n",
      "0 0.023\n",
      "Average Distance between prediction and hand assigned is 0.513256157635468\n"
     ]
    }
   ],
   "source": [
    "with open(r'.\\datasets\\wordsim353_sim_rel\\wordsim_similarity_goldstandard.txt') as file:\n",
    "\n",
    "    losses = []\n",
    "    scores = []\n",
    "\n",
    "    lines = file.readlines()\n",
    "    sum_diff = 0\n",
    "    for line in lines:\n",
    "        if(len(line) <= 1):\n",
    "            pass\n",
    "\n",
    "        print(\"line\" + line)\n",
    "        word1, word2, score10 = line.split()\n",
    "        score10 = float(score10)\n",
    "        try:\n",
    "            print(word1,word2)\n",
    "            id1 = id_dict[word1]\n",
    "            id2 = id_dict[word2]\n",
    "            print(id1)\n",
    "            print(id2)\n",
    "            vector1 = matrix_normalized[id1,:]\n",
    "            vector2 = matrix_normalized[id2,:]\n",
    "            #print(vector1)\n",
    "            #print(vector2)\n",
    "            loss = sim_01(vector1,vector2)\n",
    "        except: \n",
    "            loss = 0\n",
    "        print(str(loss),str(score10/10.0))\n",
    "        sum_diff += abs((score10/10.0) - loss)\n",
    "        losses.append(loss)\n",
    "        scores.append(score10/10.0)\n",
    "    print('Average Distance between prediction and hand assigned is ' + str(sum_diff / len(lines)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32b173bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\weso\\anaconda3\\envs\\gaundlet-TF\\lib\\site-packages\\scipy\\stats\\stats.py:4484: SpearmanRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(SpearmanRConstantInputWarning())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=nan, pvalue=nan)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "stats.spearmanr(losses, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80610682",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
