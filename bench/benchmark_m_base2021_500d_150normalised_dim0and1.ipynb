{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2873f882",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04c2c2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257757\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "path = r'..\\\\embeddings\\\\'\n",
    "id_dict = {}\n",
    "word_dict = {}\n",
    "\n",
    "matrix = []\n",
    "dimensions = 500\n",
    "with open(path + \"m_base2021_500d_150normalised_dim0and1\", 'r' , encoding=\"utf-8\")  as f:\n",
    "    lines = f.readlines()\n",
    "    vocab_size = len(lines)\n",
    "    \n",
    "    matrix = np.zeros((vocab_size,dimensions),dtype=float)\n",
    "    for line in lines:\n",
    "        values = line.split()\n",
    "        word = values[0].strip()\n",
    "        id = len(id_dict)\n",
    "        id_dict[word]=id\n",
    "        word_dict[id] = word\n",
    "        vector = np.asarray(values[1:], \"double\")\n",
    "        matrix[id_dict[word],:] = vector\n",
    "print(len(id_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37a44f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_candidate(sim,id_a,id_a_star,id_b):\n",
    "    myList = [id_a, id_b, id_a_star];\n",
    "    myList.sort();\n",
    "    \n",
    "    if(myList[0] != 0):\n",
    "        index1 = np.argmax(sim[:myList[0]])\n",
    "    else:\n",
    "        index1 = None\n",
    "    sim2 = sim[myList[0]+1:myList[1]]\n",
    "    if len(sim2) > 0:\n",
    "        index2 = np.argmax(sim2)\n",
    "        index2 +=  myList[0]+1\n",
    "    else:\n",
    "        index2 = None\n",
    "    sim3 = sim[myList[1]+1:myList[2]]\n",
    "    if len(sim3) > 0:\n",
    "        index3 = np.argmax(sim3)\n",
    "        index3 +=  myList[1]+1\n",
    "    else:\n",
    "        index3 = None\n",
    "    if(myList[2]+1 < len(sim)):\n",
    "        index4 = np.argmax(sim[myList[2]+1:])\n",
    "        index4 +=  myList[2]+1\n",
    "    else:\n",
    "        index4 = None\n",
    "    myList = [index1, index2, index3,index4];\n",
    "    values = []\n",
    "    myList2 = []\n",
    "    for index in myList:\n",
    "        if index != None:\n",
    "            values.append(sim[index])\n",
    "            myList2.append(index)\n",
    "    index = myList2[np.argmax(values)]\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c61e83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_normalized = tf.nn.l2_normalize(matrix,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81bc818b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('batman', 0.9999999999999992), ('riebeek', 0.572553252670668), ('vaishya', 0.4832892409915889), ('poage', 0.45809583678607574), ('chose', 0.4319010093370728), ('unabashedly', 0.4272291960304391)]\n",
      "[('hogwarts', 1.0000000000000016), ('saddam', 0.5315649008532886), ('eumenes', 0.5233324094209025), ('turney', 0.46177356325664454), ('deshi', 0.4611766211860368), ('zadie', 0.45359465062233917)]\n",
      "[('turing', 0.9999999999999996), ('approx', 0.5447156205054396), ('ashk', 0.51306896218268), ('intraocular', 0.4981955329169188), ('civils', 0.49794804631231754), ('nemrut', 0.4956310810140886)]\n",
      "[('florida', 1.0000000000000002), ('kolettis', 0.4589154564454295), ('birdsall', 0.4352360094923376), ('7:00', 0.42701782407634714), ('genom', 0.42168592003442695), ('bullett', 0.4109727736628013)]\n",
      "[('dancing', 1.0), ('mhlhausen', 0.5924953144295558), ('borisovich', 0.5897134080267081), ('wilhelmy', 0.5888777665139019), ('bermel', 0.5834665106245758), ('schlink', 0.5672964018153535)]\n"
     ]
    }
   ],
   "source": [
    "def find_nearest_k(searched_word,k):\n",
    "    list = []\n",
    "    id = id_dict[searched_word]\n",
    "    searched_vector = matrix_normalized[id,:] \n",
    "    \n",
    "    for word in id_dict:\n",
    "        word_weights = matrix_normalized[id_dict[word]]\n",
    "        loss = tf.tensordot(word_weights,searched_vector,axes = 1).numpy()\n",
    "        list = insert(list,(word,loss))\n",
    "        if len(list) > k:\n",
    "            list = list[0:k+1]\n",
    "    return list[0:k]\n",
    "\n",
    "# Function to insert element\n",
    "def insert(list, tuple):\n",
    "    (word,n) = tuple\n",
    "    if(len(list) == 0):\n",
    "        list = [(word,n)]\n",
    "    # Searching for the position\n",
    "    for i in range(len(list)):\n",
    "        (word_i,n_i) = list[i]\n",
    "        if n_i < n:\n",
    "            index = i\n",
    "            break\n",
    "      \n",
    "    # Inserting n in the list\n",
    "    list = list[:i] + [(word,n)] + list[i:]\n",
    "    return list\n",
    "\n",
    "\n",
    "print(find_nearest_k('batman',6))#this should produce one, for the same vectors\n",
    "print(find_nearest_k('hogwarts',6))\n",
    "print(find_nearest_k('turing',6))\n",
    "print(find_nearest_k('florida',6))\n",
    "#print(find_nearest_k('object-oriented',6))\n",
    "print(find_nearest_k('dancing',6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6e185c",
   "metadata": {},
   "source": [
    "## 3cosAdd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d75b0f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def three_cos_predict_np(a,a_star,b,b_star):\n",
    "    if( a in id_dict and b in id_dict and a_star in id_dict and b_star in id_dict):\n",
    "        pass\n",
    "    else:\n",
    "        return None\n",
    "    id_a = id_dict[a]\n",
    "    id_b = id_dict[b]\n",
    "    id_a_star = id_dict[a_star]\n",
    "    id_b_star = id_dict[b_star]#remove this after testing\n",
    "    weight_a = matrix[id_a,:]\n",
    "    weight_b = matrix[id_b,:]\n",
    "    weight_a_star = matrix[id_a_star,:]\n",
    "    direction = weight_b + ( weight_a_star - weight_a)\n",
    "    direction /= np.linalg.norm(direction)\n",
    "    \n",
    "    sim = tf.tensordot(tf.convert_to_tensor(matrix_normalized),tf.convert_to_tensor(direction),axes = 1)\n",
    "    index = find_candidate(sim,id_a,id_a_star,id_b)\n",
    "    return word_dict[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a646d761",
   "metadata": {},
   "source": [
    "# 3cosAdd normalised befor arithmetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "383f8d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_cos_predict_np_norm(a,a_star,b,b_star):\n",
    "    if( a in id_dict and b in id_dict and a_star in id_dict and b_star in id_dict):\n",
    "        pass\n",
    "    else:\n",
    "        return None\n",
    "    id_a = id_dict[a]\n",
    "    id_b = id_dict[b]\n",
    "    id_a_star = id_dict[a_star]\n",
    "    id_b_star = id_dict[b_star]#remove this after testing\n",
    "    weight_a = matrix_normalized[id_a,:]\n",
    "    weight_b = matrix_normalized[id_b,:]\n",
    "    weight_a_star = matrix_normalized[id_a_star,:]\n",
    "    direction = weight_b + ( weight_a_star - weight_a)\n",
    "    direction /= np.linalg.norm(direction)\n",
    "    \n",
    "    sim = tf.tensordot(tf.convert_to_tensor(matrix_normalized),tf.convert_to_tensor(direction),axes = 1)\n",
    "    index = find_candidate(sim,id_a,id_a_star,id_b)\n",
    "    return word_dict[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4042c364",
   "metadata": {},
   "source": [
    "## 3cos Mult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ac07eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_01(matrix,weight):\n",
    "    tmp = tf.tensordot(matrix,weight,axes=1)\n",
    "    tmp = (tmp+1.0)/2.0\n",
    "    return tmp\n",
    "\n",
    "def predict_three_cos_mult(a,a_star,b,b_star):\n",
    "    if( a in id_dict and b in id_dict and a_star in id_dict and b_star in id_dict):\n",
    "        pass\n",
    "    else:\n",
    "        print(a in id_dict)\n",
    "        print(a_star in id_dict)\n",
    "        print(b in id_dict)\n",
    "        print(b_star in id_dict)\n",
    "        return None\n",
    "    \n",
    "    id_a = id_dict[a]\n",
    "    id_b = id_dict[b]\n",
    "    id_a_star = id_dict[a_star]\n",
    "    \n",
    "    weight_a = matrix_normalized[id_a,:]\n",
    "    weight_b = matrix_normalized[id_b,:]\n",
    "    weight_a_star = matrix_normalized[id_a_star,:]\n",
    "    \n",
    "    nominator = sim_01(matrix_normalized,weight_a_star) * sim_01(matrix_normalized,weight_b) \n",
    "    denominator = sim_01(matrix_normalized,weight_a) + 0.0001\n",
    "    sim = nominator / denominator\n",
    "    index = find_candidate(sim,id_a,id_a_star,id_b)\n",
    "    return word_dict[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c53d10",
   "metadata": {},
   "source": [
    "# Test all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eecd5ce6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "capital-common-countries.txt\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "-------------------\n",
      "capital-world.txt\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "-------------------\n",
      "city-in-state.txt\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "-------------------\n",
      "currency.txt\n",
      "0\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "100\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "200\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "300\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "400\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "500\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "600\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "700\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "800\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "-------------------\n",
      "family.txt\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "-------------------\n",
      "gram1-adjective-to-adverb.txt\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "-------------------\n",
      "gram2-opposite.txt\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "-------------------\n",
      "gram3-comparative.txt\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "-------------------\n",
      "gram4-superlative.txt\n",
      "0\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "100\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "200\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "300\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "400\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "500\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "600\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "700\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "800\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "900\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "1000\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "1100\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "-------------------\n",
      "gram5-present-participle.txt\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "-------------------\n",
      "gram6-nationality-adjective.txt\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "-------------------\n",
      "gram7-past-tense.txt\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "-------------------\n",
      "gram8-plural.txt\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "-------------------\n",
      "gram9-plural-verbs.txt\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "-------------------\n",
      "semantical\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "syntactical\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "overall\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "count_sem_questions =  0\n",
    "count_syn_questions =  0\n",
    "\n",
    "count_sem_sucess      = [0,0,0]\n",
    "count_syn_sucess      = [0,0,0]\n",
    "\n",
    "errors = []\n",
    "\n",
    "\n",
    "files = os.listdir('.\\\\datasets\\\\question-data')\n",
    "for idx,file_name in enumerate(files):\n",
    "    print(file_name)\n",
    "    with open('.\\\\datasets\\\\question-data\\\\'+file_name,'r') as file:\n",
    "        lines = file.readlines()\n",
    "        local_sucesses    = [0,0,0]\n",
    "        local_tasks_count = 0\n",
    "        \n",
    "        for line_id,line in enumerate(lines):\n",
    "            if (line_id % 100 == 0):\n",
    "                print(line_id)\n",
    "            a,a_star,b,b_star = line.split(\" \")\n",
    "            b_star = b_star.strip()\n",
    "            #predicted_3cos_add      = three_cos_predict_np(a,a_star,b,b_star)\n",
    "            predicted_3cos_add_norm = three_cos_predict_np_norm(a,a_star,b,b_star)\n",
    "            predicted_3cos_mult     = predict_three_cos_mult(a,a_star,b,b_star)\n",
    "            #print(a,a_star,b,b_star)\n",
    "            #print(predicted_3cos_add,predicted_3cos_add_norm,predicted_3cos_mult)\n",
    "            if(idx < 5):#first 5 are sem\n",
    "                count_sem_questions += 1\n",
    "                local_tasks_count   += 1\n",
    "                \n",
    "                #if predicted_3cos_add      == b_star:\n",
    "                #    count_sem_sucess[0] += 1\n",
    "                if predicted_3cos_add_norm == b_star:\n",
    "                    local_sucesses[1] += 1\n",
    "                    count_sem_sucess[1] += 1\n",
    "                    \n",
    "                if  predicted_3cos_mult    == b_star:\n",
    "                    local_sucesses[2] += 1\n",
    "                    count_sem_sucess[2] += 1\n",
    "            else:\n",
    "                count_syn_questions += 1\n",
    "                local_tasks_count   += 1\n",
    "                \n",
    "                #if predicted_3cos_add      == b_star:\n",
    "                #    count_syn_sucess[0] += 1\n",
    "                if predicted_3cos_add_norm == b_star:\n",
    "                    local_sucesses[1] += 1\n",
    "                    count_syn_sucess[1] += 1\n",
    "                    \n",
    "                if  predicted_3cos_mult    == b_star:\n",
    "                    local_sucesses[2] += 1\n",
    "                    count_syn_sucess[2] += 1\n",
    "        print(local_sucesses[0]/float(local_tasks_count))\n",
    "        print(local_sucesses[1]/float(local_tasks_count))\n",
    "        print(local_sucesses[2]/float(local_tasks_count))\n",
    "        print('-------------------')\n",
    "\n",
    "print('semantical')\n",
    "\n",
    "print(count_sem_sucess[0]/float(count_sem_questions))\n",
    "print(count_sem_sucess[1]/float(count_sem_questions))\n",
    "print(count_sem_sucess[2]/float(count_sem_questions))\n",
    "        \n",
    "print('syntactical')\n",
    "print(count_syn_sucess[0]/float(count_sem_questions))\n",
    "print(count_syn_sucess[1]/float(count_sem_questions))\n",
    "print(count_syn_sucess[2]/float(count_sem_questions))\n",
    "\n",
    "print('overall')\n",
    "print((count_syn_sucess[0]+count_sem_sucess[0])/float(count_sem_questions+count_sem_questions))\n",
    "print((count_syn_sucess[1]+count_sem_sucess[1])/float(count_sem_questions+count_sem_questions))\n",
    "print((count_syn_sucess[2]+count_sem_sucess[2])/float(count_sem_questions+count_sem_questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c15546d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import winsound\n",
    "winsound.Beep(440, 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374dbbf3",
   "metadata": {},
   "source": [
    "Spearman Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa2916f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linetiger\tcat\t7.35\n",
      "\n",
      "tiger cat\n",
      "tf.Tensor(0.5247013331516679, shape=(), dtype=float64) 0.735\n",
      "linetiger\ttiger\t10.00\n",
      "\n",
      "tiger tiger\n",
      "tf.Tensor(1.0000000000000004, shape=(), dtype=float64) 1.0\n",
      "lineplane\tcar\t5.77\n",
      "\n",
      "plane car\n",
      "tf.Tensor(0.5469997907157521, shape=(), dtype=float64) 0.577\n",
      "linetrain\tcar\t6.31\n",
      "\n",
      "train car\n",
      "tf.Tensor(0.5532244850503454, shape=(), dtype=float64) 0.631\n",
      "linetelevision\tradio\t6.77\n",
      "\n",
      "television radio\n",
      "tf.Tensor(0.5420201548230794, shape=(), dtype=float64) 0.6769999999999999\n",
      "linemedia\tradio\t7.42\n",
      "\n",
      "media radio\n",
      "tf.Tensor(0.529624359928285, shape=(), dtype=float64) 0.742\n",
      "linebread\tbutter\t6.19\n",
      "\n",
      "bread butter\n",
      "tf.Tensor(0.49517725526936507, shape=(), dtype=float64) 0.619\n",
      "linecucumber\tpotato\t5.92\n",
      "\n",
      "cucumber potato\n",
      "tf.Tensor(0.33727169371692145, shape=(), dtype=float64) 0.592\n",
      "linedoctor\tnurse\t7.00\n",
      "\n",
      "doctor nurse\n",
      "tf.Tensor(0.5517928597956369, shape=(), dtype=float64) 0.7\n",
      "lineprofessor\tdoctor\t6.62\n",
      "\n",
      "professor doctor\n",
      "tf.Tensor(0.5644268613027906, shape=(), dtype=float64) 0.662\n",
      "linestudent\tprofessor\t6.81\n",
      "\n",
      "student professor\n",
      "tf.Tensor(0.5073164437457582, shape=(), dtype=float64) 0.6809999999999999\n",
      "linesmart\tstupid\t5.81\n",
      "\n",
      "smart stupid\n",
      "tf.Tensor(0.5653872789974097, shape=(), dtype=float64) 0.581\n",
      "linewood\tforest\t7.73\n",
      "\n",
      "wood forest\n",
      "tf.Tensor(0.5233325566138123, shape=(), dtype=float64) 0.773\n",
      "linemoney\tcash\t9.15\n",
      "\n",
      "money cash\n",
      "tf.Tensor(0.5352017602510698, shape=(), dtype=float64) 0.915\n",
      "lineking\tqueen\t8.58\n",
      "\n",
      "king queen\n",
      "tf.Tensor(0.5020779201091106, shape=(), dtype=float64) 0.858\n",
      "lineking\trook\t5.92\n",
      "\n",
      "king rook\n",
      "tf.Tensor(0.5741072546643895, shape=(), dtype=float64) 0.592\n",
      "linebishop\trabbi\t6.69\n",
      "\n",
      "bishop rabbi\n",
      "tf.Tensor(0.5730219232204817, shape=(), dtype=float64) 0.669\n",
      "linefuck\tsex\t9.44\n",
      "\n",
      "fuck sex\n",
      "tf.Tensor(0.5623334316619379, shape=(), dtype=float64) 0.944\n",
      "linefootball\tsoccer\t9.03\n",
      "\n",
      "football soccer\n",
      "tf.Tensor(0.5073312333178561, shape=(), dtype=float64) 0.9029999999999999\n",
      "linefootball\tbasketball\t6.81\n",
      "\n",
      "football basketball\n",
      "tf.Tensor(0.5654032677954297, shape=(), dtype=float64) 0.6809999999999999\n",
      "linefootball\ttennis\t6.63\n",
      "\n",
      "football tennis\n",
      "tf.Tensor(0.521479099605326, shape=(), dtype=float64) 0.663\n",
      "lineArafat\tJackson\t2.50\n",
      "\n",
      "Arafat Jackson\n",
      "0 0.25\n",
      "linephysics\tchemistry\t7.35\n",
      "\n",
      "physics chemistry\n",
      "tf.Tensor(0.5960471178350563, shape=(), dtype=float64) 0.735\n",
      "linevodka\tgin\t8.46\n",
      "\n",
      "vodka gin\n",
      "tf.Tensor(0.5864535566261936, shape=(), dtype=float64) 0.8460000000000001\n",
      "linevodka\tbrandy\t8.13\n",
      "\n",
      "vodka brandy\n",
      "tf.Tensor(0.5810791480776911, shape=(), dtype=float64) 0.8130000000000001\n",
      "linedrink\teat\t6.87\n",
      "\n",
      "drink eat\n",
      "tf.Tensor(0.5815756923478433, shape=(), dtype=float64) 0.687\n",
      "linecar\tautomobile\t8.94\n",
      "\n",
      "car automobile\n",
      "tf.Tensor(0.626773071834234, shape=(), dtype=float64) 0.8939999999999999\n",
      "linegem\tjewel\t8.96\n",
      "\n",
      "gem jewel\n",
      "tf.Tensor(0.5445293962466575, shape=(), dtype=float64) 0.8960000000000001\n",
      "linejourney\tvoyage\t9.29\n",
      "\n",
      "journey voyage\n",
      "tf.Tensor(0.555677190198162, shape=(), dtype=float64) 0.9289999999999999\n",
      "lineboy\tlad\t8.83\n",
      "\n",
      "boy lad\n",
      "tf.Tensor(0.4656851178557925, shape=(), dtype=float64) 0.883\n",
      "linecoast\tshore\t9.10\n",
      "\n",
      "coast shore\n",
      "tf.Tensor(0.5278884146988454, shape=(), dtype=float64) 0.9099999999999999\n",
      "lineasylum\tmadhouse\t8.87\n",
      "\n",
      "asylum madhouse\n",
      "tf.Tensor(0.5217970589727442, shape=(), dtype=float64) 0.8869999999999999\n",
      "linemagician\twizard\t9.02\n",
      "\n",
      "magician wizard\n",
      "tf.Tensor(0.6128683040711088, shape=(), dtype=float64) 0.9019999999999999\n",
      "linemidday\tnoon\t9.29\n",
      "\n",
      "midday noon\n",
      "tf.Tensor(0.5515686172456328, shape=(), dtype=float64) 0.9289999999999999\n",
      "linefurnace\tstove\t8.79\n",
      "\n",
      "furnace stove\n",
      "tf.Tensor(0.5285911146214026, shape=(), dtype=float64) 0.8789999999999999\n",
      "linefood\tfruit\t7.52\n",
      "\n",
      "food fruit\n",
      "tf.Tensor(0.5641483072499793, shape=(), dtype=float64) 0.752\n",
      "linebird\tcock\t7.10\n",
      "\n",
      "bird cock\n",
      "tf.Tensor(0.40950537808908005, shape=(), dtype=float64) 0.71\n",
      "linebird\tcrane\t7.38\n",
      "\n",
      "bird crane\n",
      "tf.Tensor(0.5469491650786482, shape=(), dtype=float64) 0.738\n",
      "linefood\trooster\t4.42\n",
      "\n",
      "food rooster\n",
      "tf.Tensor(0.49536789806865317, shape=(), dtype=float64) 0.442\n",
      "linemoney\tdollar\t8.42\n",
      "\n",
      "money dollar\n",
      "tf.Tensor(0.596908396807438, shape=(), dtype=float64) 0.842\n",
      "linemoney\tcurrency\t9.04\n",
      "\n",
      "money currency\n",
      "tf.Tensor(0.5864145498547386, shape=(), dtype=float64) 0.9039999999999999\n",
      "linetiger\tjaguar\t8.00\n",
      "\n",
      "tiger jaguar\n",
      "tf.Tensor(0.5635937265307988, shape=(), dtype=float64) 0.8\n",
      "linetiger\tfeline\t8.00\n",
      "\n",
      "tiger feline\n",
      "tf.Tensor(0.5476787007092205, shape=(), dtype=float64) 0.8\n",
      "linetiger\tcarnivore\t7.08\n",
      "\n",
      "tiger carnivore\n",
      "tf.Tensor(0.5119160848835945, shape=(), dtype=float64) 0.708\n",
      "linetiger\tmammal\t6.85\n",
      "\n",
      "tiger mammal\n",
      "tf.Tensor(0.5765281060288232, shape=(), dtype=float64) 0.6849999999999999\n",
      "linetiger\tanimal\t7.00\n",
      "\n",
      "tiger animal\n",
      "tf.Tensor(0.5268872610129999, shape=(), dtype=float64) 0.7\n",
      "linetiger\torganism\t4.77\n",
      "\n",
      "tiger organism\n",
      "tf.Tensor(0.5217220193974428, shape=(), dtype=float64) 0.477\n",
      "linetiger\tfauna\t5.62\n",
      "\n",
      "tiger fauna\n",
      "tf.Tensor(0.5387844126959598, shape=(), dtype=float64) 0.562\n",
      "linepsychology\tpsychiatry\t8.08\n",
      "\n",
      "psychology psychiatry\n",
      "tf.Tensor(0.573427539182751, shape=(), dtype=float64) 0.808\n",
      "linepsychology\tscience\t6.71\n",
      "\n",
      "psychology science\n",
      "tf.Tensor(0.5256512025014792, shape=(), dtype=float64) 0.671\n",
      "linepsychology\tdiscipline\t5.58\n",
      "\n",
      "psychology discipline\n",
      "tf.Tensor(0.5767242587395293, shape=(), dtype=float64) 0.558\n",
      "lineplanet\tstar\t8.45\n",
      "\n",
      "planet star\n",
      "tf.Tensor(0.6940909464904025, shape=(), dtype=float64) 0.845\n",
      "lineplanet\tmoon\t8.08\n",
      "\n",
      "planet moon\n",
      "tf.Tensor(0.6158582970379755, shape=(), dtype=float64) 0.808\n",
      "lineplanet\tsun\t8.02\n",
      "\n",
      "planet sun\n",
      "tf.Tensor(0.6133102299435286, shape=(), dtype=float64) 0.8019999999999999\n",
      "lineprecedent\texample\t5.85\n",
      "\n",
      "precedent example\n",
      "tf.Tensor(0.5356532642126649, shape=(), dtype=float64) 0.585\n",
      "lineprecedent\tantecedent\t6.04\n",
      "\n",
      "precedent antecedent\n",
      "tf.Tensor(0.5154794626512839, shape=(), dtype=float64) 0.604\n",
      "linecup\ttableware\t6.85\n",
      "\n",
      "cup tableware\n",
      "tf.Tensor(0.5451052791069928, shape=(), dtype=float64) 0.6849999999999999\n",
      "linecup\tartifact\t2.92\n",
      "\n",
      "cup artifact\n",
      "tf.Tensor(0.5338160927182874, shape=(), dtype=float64) 0.292\n",
      "linecup\tobject\t3.69\n",
      "\n",
      "cup object\n",
      "tf.Tensor(0.5142883313646051, shape=(), dtype=float64) 0.369\n",
      "linecup\tentity\t2.15\n",
      "\n",
      "cup entity\n",
      "tf.Tensor(0.47395818359934344, shape=(), dtype=float64) 0.215\n",
      "linejaguar\tcat\t7.42\n",
      "\n",
      "jaguar cat\n",
      "tf.Tensor(0.5285963447945021, shape=(), dtype=float64) 0.742\n",
      "linejaguar\tcar\t7.27\n",
      "\n",
      "jaguar car\n",
      "tf.Tensor(0.5482176530014796, shape=(), dtype=float64) 0.727\n",
      "linemile\tkilometer\t8.66\n",
      "\n",
      "mile kilometer\n",
      "tf.Tensor(0.5732286619956564, shape=(), dtype=float64) 0.866\n",
      "lineskin\teye\t6.22\n",
      "\n",
      "skin eye\n",
      "tf.Tensor(0.5792810631722378, shape=(), dtype=float64) 0.622\n",
      "lineJapanese\tAmerican\t6.50\n",
      "\n",
      "Japanese American\n",
      "0 0.65\n",
      "linecentury\tyear\t7.59\n",
      "\n",
      "century year\n",
      "tf.Tensor(0.554604322415719, shape=(), dtype=float64) 0.759\n",
      "lineannouncement\tnews\t7.56\n",
      "\n",
      "announcement news\n",
      "tf.Tensor(0.539520827751639, shape=(), dtype=float64) 0.756\n",
      "linedoctor\tpersonnel\t5.00\n",
      "\n",
      "doctor personnel\n",
      "tf.Tensor(0.49411312252432255, shape=(), dtype=float64) 0.5\n",
      "lineHarvard\tYale\t8.13\n",
      "\n",
      "Harvard Yale\n",
      "0 0.8130000000000001\n",
      "linehospital\tinfrastructure\t4.63\n",
      "\n",
      "hospital infrastructure\n",
      "tf.Tensor(0.5936890323440788, shape=(), dtype=float64) 0.46299999999999997\n",
      "linelife\tdeath\t7.88\n",
      "\n",
      "life death\n",
      "tf.Tensor(0.5728865894050879, shape=(), dtype=float64) 0.788\n",
      "linetravel\tactivity\t5.00\n",
      "\n",
      "travel activity\n",
      "tf.Tensor(0.5635219309196289, shape=(), dtype=float64) 0.5\n",
      "linetype\tkind\t8.97\n",
      "\n",
      "type kind\n",
      "tf.Tensor(0.5757265259671481, shape=(), dtype=float64) 0.897\n",
      "linestreet\tplace\t6.44\n",
      "\n",
      "street place\n",
      "tf.Tensor(0.5087544112908646, shape=(), dtype=float64) 0.644\n",
      "linestreet\tavenue\t8.88\n",
      "\n",
      "street avenue\n",
      "tf.Tensor(0.5250406402640779, shape=(), dtype=float64) 0.8880000000000001\n",
      "linestreet\tblock\t6.88\n",
      "\n",
      "street block\n",
      "tf.Tensor(0.548772140124784, shape=(), dtype=float64) 0.688\n",
      "linecell\tphone\t7.81\n",
      "\n",
      "cell phone\n",
      "tf.Tensor(0.5519321328454614, shape=(), dtype=float64) 0.7809999999999999\n",
      "linedividend\tpayment\t7.63\n",
      "\n",
      "dividend payment\n",
      "tf.Tensor(0.5833715302727556, shape=(), dtype=float64) 0.763\n",
      "linecalculation\tcomputation\t8.44\n",
      "\n",
      "calculation computation\n",
      "tf.Tensor(0.5286609700418502, shape=(), dtype=float64) 0.844\n",
      "lineprofit\tloss\t7.63\n",
      "\n",
      "profit loss\n",
      "tf.Tensor(0.5483353231325625, shape=(), dtype=float64) 0.763\n",
      "linedollar\tyen\t7.78\n",
      "\n",
      "dollar yen\n",
      "tf.Tensor(0.5033954256709604, shape=(), dtype=float64) 0.778\n",
      "linedollar\tbuck\t9.22\n",
      "\n",
      "dollar buck\n",
      "tf.Tensor(0.4959849716457668, shape=(), dtype=float64) 0.922\n",
      "linephone\tequipment\t7.13\n",
      "\n",
      "phone equipment\n",
      "tf.Tensor(0.5185071367099995, shape=(), dtype=float64) 0.713\n",
      "lineliquid\twater\t7.89\n",
      "\n",
      "liquid water\n",
      "tf.Tensor(0.5276355021870469, shape=(), dtype=float64) 0.7889999999999999\n",
      "linemarathon\tsprint\t7.47\n",
      "\n",
      "marathon sprint\n",
      "tf.Tensor(0.44543105858867055, shape=(), dtype=float64) 0.747\n",
      "lineseafood\tfood\t8.34\n",
      "\n",
      "seafood food\n",
      "tf.Tensor(0.5227708823435778, shape=(), dtype=float64) 0.834\n",
      "lineseafood\tlobster\t8.70\n",
      "\n",
      "seafood lobster\n",
      "tf.Tensor(0.5599505507278735, shape=(), dtype=float64) 0.8699999999999999\n",
      "linelobster\tfood\t7.81\n",
      "\n",
      "lobster food\n",
      "tf.Tensor(0.5412190797178174, shape=(), dtype=float64) 0.7809999999999999\n",
      "linelobster\twine\t5.70\n",
      "\n",
      "lobster wine\n",
      "tf.Tensor(0.5950460629676132, shape=(), dtype=float64) 0.5700000000000001\n",
      "linechampionship\ttournament\t8.36\n",
      "\n",
      "championship tournament\n",
      "tf.Tensor(0.49368555606377973, shape=(), dtype=float64) 0.836\n",
      "lineman\twoman\t8.30\n",
      "\n",
      "man woman\n",
      "tf.Tensor(0.5279057810671289, shape=(), dtype=float64) 0.8300000000000001\n",
      "lineman\tgovernor\t5.25\n",
      "\n",
      "man governor\n",
      "tf.Tensor(0.5323634978080042, shape=(), dtype=float64) 0.525\n",
      "linemurder\tmanslaughter\t8.53\n",
      "\n",
      "murder manslaughter\n",
      "tf.Tensor(0.5313930368342094, shape=(), dtype=float64) 0.853\n",
      "lineopera\tperformance\t6.88\n",
      "\n",
      "opera performance\n",
      "tf.Tensor(0.5501337715651422, shape=(), dtype=float64) 0.688\n",
      "lineMexico\tBrazil\t7.44\n",
      "\n",
      "Mexico Brazil\n",
      "0 0.744\n",
      "lineglass\tmetal\t5.56\n",
      "\n",
      "glass metal\n",
      "tf.Tensor(0.5414770034032333, shape=(), dtype=float64) 0.5559999999999999\n",
      "linealuminum\tmetal\t7.83\n",
      "\n",
      "aluminum metal\n",
      "tf.Tensor(0.6627373782819894, shape=(), dtype=float64) 0.783\n",
      "linerock\tjazz\t7.59\n",
      "\n",
      "rock jazz\n",
      "tf.Tensor(0.556319702277182, shape=(), dtype=float64) 0.759\n",
      "linemuseum\ttheater\t7.19\n",
      "\n",
      "museum theater\n",
      "tf.Tensor(0.6066991414150452, shape=(), dtype=float64) 0.7190000000000001\n",
      "lineshower\tthunderstorm\t6.31\n",
      "\n",
      "shower thunderstorm\n",
      "tf.Tensor(0.6112612644100898, shape=(), dtype=float64) 0.631\n",
      "linemonk\toracle\t5.00\n",
      "\n",
      "monk oracle\n",
      "tf.Tensor(0.5132553487400607, shape=(), dtype=float64) 0.5\n",
      "linecup\tfood\t5.00\n",
      "\n",
      "cup food\n",
      "tf.Tensor(0.5773723882637931, shape=(), dtype=float64) 0.5\n",
      "linejournal\tassociation\t4.97\n",
      "\n",
      "journal association\n",
      "tf.Tensor(0.5654250548419579, shape=(), dtype=float64) 0.497\n",
      "linestreet\tchildren\t4.94\n",
      "\n",
      "street children\n",
      "tf.Tensor(0.5345621640094056, shape=(), dtype=float64) 0.49400000000000005\n",
      "linecar\tflight\t4.94\n",
      "\n",
      "car flight\n",
      "tf.Tensor(0.5412011583965011, shape=(), dtype=float64) 0.49400000000000005\n",
      "linespace\tchemistry\t4.88\n",
      "\n",
      "space chemistry\n",
      "tf.Tensor(0.5692300798227943, shape=(), dtype=float64) 0.488\n",
      "linesituation\tconclusion\t4.81\n",
      "\n",
      "situation conclusion\n",
      "tf.Tensor(0.4932595851845594, shape=(), dtype=float64) 0.481\n",
      "lineword\tsimilarity\t4.75\n",
      "\n",
      "word similarity\n",
      "tf.Tensor(0.5663134178157083, shape=(), dtype=float64) 0.475\n",
      "linepeace\tplan\t4.75\n",
      "\n",
      "peace plan\n",
      "tf.Tensor(0.5426634570347434, shape=(), dtype=float64) 0.475\n",
      "lineconsumer\tenergy\t4.75\n",
      "\n",
      "consumer energy\n",
      "tf.Tensor(0.5252215786137905, shape=(), dtype=float64) 0.475\n",
      "lineministry\tculture\t4.69\n",
      "\n",
      "ministry culture\n",
      "tf.Tensor(0.49565043411457893, shape=(), dtype=float64) 0.46900000000000003\n",
      "linesmart\tstudent\t4.62\n",
      "\n",
      "smart student\n",
      "tf.Tensor(0.5042651110487788, shape=(), dtype=float64) 0.462\n",
      "lineinvestigation\teffort\t4.59\n",
      "\n",
      "investigation effort\n",
      "tf.Tensor(0.5559532458028964, shape=(), dtype=float64) 0.45899999999999996\n",
      "lineimage\tsurface\t4.56\n",
      "\n",
      "image surface\n",
      "tf.Tensor(0.5529234859764227, shape=(), dtype=float64) 0.45599999999999996\n",
      "linelife\tterm\t4.50\n",
      "\n",
      "life term\n",
      "tf.Tensor(0.5787752279113614, shape=(), dtype=float64) 0.45\n",
      "linestart\tmatch\t4.47\n",
      "\n",
      "start match\n",
      "tf.Tensor(0.5434151113358946, shape=(), dtype=float64) 0.44699999999999995\n",
      "linecomputer\tnews\t4.47\n",
      "\n",
      "computer news\n",
      "tf.Tensor(0.5798671746978047, shape=(), dtype=float64) 0.44699999999999995\n",
      "lineboard\trecommendation\t4.47\n",
      "\n",
      "board recommendation\n",
      "tf.Tensor(0.5539331085291049, shape=(), dtype=float64) 0.44699999999999995\n",
      "linelad\tbrother\t4.46\n",
      "\n",
      "lad brother\n",
      "tf.Tensor(0.46097193132316944, shape=(), dtype=float64) 0.446\n",
      "lineobservation\tarchitecture\t4.38\n",
      "\n",
      "observation architecture\n",
      "tf.Tensor(0.569235625885752, shape=(), dtype=float64) 0.438\n",
      "linecoast\thill\t4.38\n",
      "\n",
      "coast hill\n",
      "tf.Tensor(0.4686149161833631, shape=(), dtype=float64) 0.438\n",
      "linedeployment\tdeparture\t4.25\n",
      "\n",
      "deployment departure\n",
      "tf.Tensor(0.5520773035501215, shape=(), dtype=float64) 0.425\n",
      "linebenchmark\tindex\t4.25\n",
      "\n",
      "benchmark index\n",
      "tf.Tensor(0.492028338856747, shape=(), dtype=float64) 0.425\n",
      "lineattempt\tpeace\t4.25\n",
      "\n",
      "attempt peace\n",
      "tf.Tensor(0.6144926633998116, shape=(), dtype=float64) 0.425\n",
      "lineconsumer\tconfidence\t4.13\n",
      "\n",
      "consumer confidence\n",
      "tf.Tensor(0.5496274301945104, shape=(), dtype=float64) 0.413\n",
      "linestart\tyear\t4.06\n",
      "\n",
      "start year\n",
      "tf.Tensor(0.5561564758763907, shape=(), dtype=float64) 0.40599999999999997\n",
      "linefocus\tlife\t4.06\n",
      "\n",
      "focus life\n",
      "tf.Tensor(0.6199948977248091, shape=(), dtype=float64) 0.40599999999999997\n",
      "linedevelopment\tissue\t3.97\n",
      "\n",
      "development issue\n",
      "tf.Tensor(0.5221897188466577, shape=(), dtype=float64) 0.397\n",
      "linetheater\thistory\t3.91\n",
      "\n",
      "theater history\n",
      "tf.Tensor(0.5976780709510476, shape=(), dtype=float64) 0.391\n",
      "linesituation\tisolation\t3.88\n",
      "\n",
      "situation isolation\n",
      "tf.Tensor(0.543081234417178, shape=(), dtype=float64) 0.388\n",
      "lineprofit\twarning\t3.88\n",
      "\n",
      "profit warning\n",
      "tf.Tensor(0.5225797661293158, shape=(), dtype=float64) 0.388\n",
      "linemedia\ttrading\t3.88\n",
      "\n",
      "media trading\n",
      "tf.Tensor(0.49583893629446785, shape=(), dtype=float64) 0.388\n",
      "linechance\tcredibility\t3.88\n",
      "\n",
      "chance credibility\n",
      "tf.Tensor(0.5717550601291965, shape=(), dtype=float64) 0.388\n",
      "lineprecedent\tinformation\t3.85\n",
      "\n",
      "precedent information\n",
      "tf.Tensor(0.5868855189137436, shape=(), dtype=float64) 0.385\n",
      "linearchitecture\tcentury\t3.78\n",
      "\n",
      "architecture century\n",
      "tf.Tensor(0.5635205227093181, shape=(), dtype=float64) 0.378\n",
      "linepopulation\tdevelopment\t3.75\n",
      "\n",
      "population development\n",
      "tf.Tensor(0.6041489217230629, shape=(), dtype=float64) 0.375\n",
      "linestock\tlive\t3.73\n",
      "\n",
      "stock live\n",
      "tf.Tensor(0.6466974645736113, shape=(), dtype=float64) 0.373\n",
      "linepeace\tatmosphere\t3.69\n",
      "\n",
      "peace atmosphere\n",
      "tf.Tensor(0.5599933863454233, shape=(), dtype=float64) 0.369\n",
      "linemorality\tmarriage\t3.69\n",
      "\n",
      "morality marriage\n",
      "tf.Tensor(0.583494080839779, shape=(), dtype=float64) 0.369\n",
      "lineminority\tpeace\t3.69\n",
      "\n",
      "minority peace\n",
      "tf.Tensor(0.5418332456151407, shape=(), dtype=float64) 0.369\n",
      "lineatmosphere\tlandscape\t3.69\n",
      "\n",
      "atmosphere landscape\n",
      "tf.Tensor(0.6847475869081177, shape=(), dtype=float64) 0.369\n",
      "linereport\tgain\t3.63\n",
      "\n",
      "report gain\n",
      "tf.Tensor(0.5418129608871528, shape=(), dtype=float64) 0.363\n",
      "linemusic\tproject\t3.63\n",
      "\n",
      "music project\n",
      "tf.Tensor(0.5439182593373786, shape=(), dtype=float64) 0.363\n",
      "lineseven\tseries\t3.56\n",
      "\n",
      "seven series\n",
      "tf.Tensor(0.5741203166008017, shape=(), dtype=float64) 0.356\n",
      "lineexperience\tmusic\t3.47\n",
      "\n",
      "experience music\n",
      "tf.Tensor(0.5192862335149304, shape=(), dtype=float64) 0.34700000000000003\n",
      "lineschool\tcenter\t3.44\n",
      "\n",
      "school center\n",
      "tf.Tensor(0.5193321734224035, shape=(), dtype=float64) 0.344\n",
      "linefive\tmonth\t3.38\n",
      "\n",
      "five month\n",
      "tf.Tensor(0.5334471732799686, shape=(), dtype=float64) 0.33799999999999997\n",
      "lineannouncement\tproduction\t3.38\n",
      "\n",
      "announcement production\n",
      "tf.Tensor(0.48940518193762583, shape=(), dtype=float64) 0.33799999999999997\n",
      "linemorality\timportance\t3.31\n",
      "\n",
      "morality importance\n",
      "tf.Tensor(0.4899689254155345, shape=(), dtype=float64) 0.331\n",
      "linemoney\toperation\t3.31\n",
      "\n",
      "money operation\n",
      "tf.Tensor(0.5678550138669014, shape=(), dtype=float64) 0.331\n",
      "linedelay\tnews\t3.31\n",
      "\n",
      "delay news\n",
      "tf.Tensor(0.6163271484686366, shape=(), dtype=float64) 0.331\n",
      "linegovernor\tinterview\t3.25\n",
      "\n",
      "governor interview\n",
      "tf.Tensor(0.5115031419548424, shape=(), dtype=float64) 0.325\n",
      "linepractice\tinstitution\t3.19\n",
      "\n",
      "practice institution\n",
      "tf.Tensor(0.5725151777080468, shape=(), dtype=float64) 0.319\n",
      "linecentury\tnation\t3.16\n",
      "\n",
      "century nation\n",
      "tf.Tensor(0.5503349359528589, shape=(), dtype=float64) 0.316\n",
      "linecoast\tforest\t3.15\n",
      "\n",
      "coast forest\n",
      "tf.Tensor(0.5610461125290346, shape=(), dtype=float64) 0.315\n",
      "lineshore\twoodland\t3.08\n",
      "\n",
      "shore woodland\n",
      "tf.Tensor(0.5490643922098262, shape=(), dtype=float64) 0.308\n",
      "linedrink\tcar\t3.04\n",
      "\n",
      "drink car\n",
      "tf.Tensor(0.5293481378777684, shape=(), dtype=float64) 0.304\n",
      "linepresident\tmedal\t3.00\n",
      "\n",
      "president medal\n",
      "tf.Tensor(0.5389451223769408, shape=(), dtype=float64) 0.3\n",
      "lineprejudice\trecognition\t3.00\n",
      "\n",
      "prejudice recognition\n",
      "tf.Tensor(0.5580951452901595, shape=(), dtype=float64) 0.3\n",
      "lineviewer\tserial\t2.97\n",
      "\n",
      "viewer serial\n",
      "tf.Tensor(0.5533948616099256, shape=(), dtype=float64) 0.29700000000000004\n",
      "linepeace\tinsurance\t2.94\n",
      "\n",
      "peace insurance\n",
      "tf.Tensor(0.5551849946577071, shape=(), dtype=float64) 0.294\n",
      "lineMars\twater\t2.94\n",
      "\n",
      "Mars water\n",
      "0 0.294\n",
      "linemedia\tgain\t2.88\n",
      "\n",
      "media gain\n",
      "tf.Tensor(0.5375941778310145, shape=(), dtype=float64) 0.288\n",
      "lineprecedent\tcognition\t2.81\n",
      "\n",
      "precedent cognition\n",
      "tf.Tensor(0.5430679968967012, shape=(), dtype=float64) 0.281\n",
      "lineannouncement\teffort\t2.75\n",
      "\n",
      "announcement effort\n",
      "tf.Tensor(0.515331580280293, shape=(), dtype=float64) 0.275\n",
      "lineline\tinsurance\t2.69\n",
      "\n",
      "line insurance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.5923497499209036, shape=(), dtype=float64) 0.269\n",
      "linecrane\timplement\t2.69\n",
      "\n",
      "crane implement\n",
      "tf.Tensor(0.5132470470588061, shape=(), dtype=float64) 0.269\n",
      "linedrink\tmother\t2.65\n",
      "\n",
      "drink mother\n",
      "tf.Tensor(0.5451387026323531, shape=(), dtype=float64) 0.265\n",
      "lineopera\tindustry\t2.63\n",
      "\n",
      "opera industry\n",
      "tf.Tensor(0.5427374035963063, shape=(), dtype=float64) 0.263\n",
      "linevolunteer\tmotto\t2.56\n",
      "\n",
      "volunteer motto\n",
      "tf.Tensor(0.5599584479004139, shape=(), dtype=float64) 0.256\n",
      "linelisting\tproximity\t2.56\n",
      "\n",
      "listing proximity\n",
      "tf.Tensor(0.5492234982789428, shape=(), dtype=float64) 0.256\n",
      "lineprecedent\tcollection\t2.50\n",
      "\n",
      "precedent collection\n",
      "tf.Tensor(0.5291102679241265, shape=(), dtype=float64) 0.25\n",
      "linecup\tarticle\t2.40\n",
      "\n",
      "cup article\n",
      "tf.Tensor(0.5006496105914163, shape=(), dtype=float64) 0.24\n",
      "linesign\trecess\t2.38\n",
      "\n",
      "sign recess\n",
      "tf.Tensor(0.5402832830839983, shape=(), dtype=float64) 0.238\n",
      "lineproblem\tairport\t2.38\n",
      "\n",
      "problem airport\n",
      "tf.Tensor(0.5667586626313645, shape=(), dtype=float64) 0.238\n",
      "linereason\thypertension\t2.31\n",
      "\n",
      "reason hypertension\n",
      "tf.Tensor(0.5752429784865487, shape=(), dtype=float64) 0.231\n",
      "linedirection\tcombination\t2.25\n",
      "\n",
      "direction combination\n",
      "tf.Tensor(0.5652734808578944, shape=(), dtype=float64) 0.225\n",
      "lineWednesday\tnews\t2.22\n",
      "\n",
      "Wednesday news\n",
      "0 0.22200000000000003\n",
      "lineglass\tmagician\t2.08\n",
      "\n",
      "glass magician\n",
      "tf.Tensor(0.5608944062941252, shape=(), dtype=float64) 0.20800000000000002\n",
      "linecemetery\twoodland\t2.08\n",
      "\n",
      "cemetery woodland\n",
      "tf.Tensor(0.5669882632058139, shape=(), dtype=float64) 0.20800000000000002\n",
      "linepossibility\tgirl\t1.94\n",
      "\n",
      "possibility girl\n",
      "tf.Tensor(0.5671062677427515, shape=(), dtype=float64) 0.194\n",
      "linecup\tsubstance\t1.92\n",
      "\n",
      "cup substance\n",
      "tf.Tensor(0.5260667811959926, shape=(), dtype=float64) 0.192\n",
      "lineforest\tgraveyard\t1.85\n",
      "\n",
      "forest graveyard\n",
      "tf.Tensor(0.5535681450501351, shape=(), dtype=float64) 0.185\n",
      "linestock\tegg\t1.81\n",
      "\n",
      "stock egg\n",
      "tf.Tensor(0.5788824963568596, shape=(), dtype=float64) 0.181\n",
      "linemonth\thotel\t1.81\n",
      "\n",
      "month hotel\n",
      "tf.Tensor(0.5599618873333141, shape=(), dtype=float64) 0.181\n",
      "lineenergy\tsecretary\t1.81\n",
      "\n",
      "energy secretary\n",
      "tf.Tensor(0.5090050996769634, shape=(), dtype=float64) 0.181\n",
      "lineprecedent\tgroup\t1.77\n",
      "\n",
      "precedent group\n",
      "tf.Tensor(0.55637355562042, shape=(), dtype=float64) 0.177\n",
      "lineproduction\thike\t1.75\n",
      "\n",
      "production hike\n",
      "tf.Tensor(0.5477744128242066, shape=(), dtype=float64) 0.175\n",
      "linestock\tphone\t1.62\n",
      "\n",
      "stock phone\n",
      "tf.Tensor(0.5519601088685073, shape=(), dtype=float64) 0.162\n",
      "lineholy\tsex\t1.62\n",
      "\n",
      "holy sex\n",
      "tf.Tensor(0.594865211501768, shape=(), dtype=float64) 0.162\n",
      "linestock\tCD\t1.31\n",
      "\n",
      "stock CD\n",
      "0 0.131\n",
      "linedrink\tear\t1.31\n",
      "\n",
      "drink ear\n",
      "tf.Tensor(0.4815225993169371, shape=(), dtype=float64) 0.131\n",
      "linedelay\tracism\t1.19\n",
      "\n",
      "delay racism\n",
      "tf.Tensor(0.5730485861048229, shape=(), dtype=float64) 0.119\n",
      "linestock\tlife\t0.92\n",
      "\n",
      "stock life\n",
      "tf.Tensor(0.5298863875742221, shape=(), dtype=float64) 0.092\n",
      "linestock\tjaguar\t0.92\n",
      "\n",
      "stock jaguar\n",
      "tf.Tensor(0.5282051278345764, shape=(), dtype=float64) 0.092\n",
      "linemonk\tslave\t0.92\n",
      "\n",
      "monk slave\n",
      "tf.Tensor(0.6107303953733926, shape=(), dtype=float64) 0.092\n",
      "linelad\twizard\t0.92\n",
      "\n",
      "lad wizard\n",
      "tf.Tensor(0.5660424252306407, shape=(), dtype=float64) 0.092\n",
      "linesugar\tapproach\t0.88\n",
      "\n",
      "sugar approach\n",
      "tf.Tensor(0.5385499168370379, shape=(), dtype=float64) 0.088\n",
      "linerooster\tvoyage\t0.62\n",
      "\n",
      "rooster voyage\n",
      "tf.Tensor(0.5848388024778154, shape=(), dtype=float64) 0.062\n",
      "linenoon\tstring\t0.54\n",
      "\n",
      "noon string\n",
      "tf.Tensor(0.5017411184496082, shape=(), dtype=float64) 0.054000000000000006\n",
      "linechord\tsmile\t0.54\n",
      "\n",
      "chord smile\n",
      "tf.Tensor(0.5535174555853062, shape=(), dtype=float64) 0.054000000000000006\n",
      "lineprofessor\tcucumber\t0.31\n",
      "\n",
      "professor cucumber\n",
      "tf.Tensor(0.5497508242812275, shape=(), dtype=float64) 0.031\n",
      "lineking\tcabbage\t0.23\n",
      "\n",
      "king cabbage\n",
      "tf.Tensor(0.6121406988052687, shape=(), dtype=float64) 0.023\n",
      "Average Distance between prediction and hand assigned is tf.Tensor(0.22702717355430302, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "with open(r'.\\datasets\\wordsim353_sim_rel\\wordsim_similarity_goldstandard.txt') as file:\n",
    "\n",
    "    losses = []\n",
    "    scores = []\n",
    "\n",
    "    lines = file.readlines()\n",
    "    sum_diff = 0\n",
    "    for line in lines:\n",
    "        if(len(line) <= 1):\n",
    "            pass\n",
    "\n",
    "        print(\"line\" + line)\n",
    "        word1, word2, score10 = line.split()\n",
    "        score10 = float(score10)\n",
    "        try:\n",
    "            print(word1,word2)\n",
    "            id1 = id_dict[word1]\n",
    "            id2 = id_dict[word2]\n",
    "            #print(id1)\n",
    "            #print(id2)\n",
    "            vector1 = matrix_normalized[id1,:]\n",
    "            vector2 = matrix_normalized[id2,:]\n",
    "            #print(vector1)\n",
    "            #print(vector2)\n",
    "            loss = sim_01(vector1,vector2)\n",
    "        except: \n",
    "            loss = 0\n",
    "        print(str(loss),str(score10/10.0))\n",
    "        sum_diff += abs((score10/10.0) - loss)\n",
    "        losses.append(loss)\n",
    "        scores.append(score10/10.0)\n",
    "    print('Average Distance between prediction and hand assigned is ' + str(sum_diff / len(lines)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b173bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "stats.spearmanr(losses, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be693689",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
