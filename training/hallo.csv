Optimizer,learning_rate,epoch,loss
ADAM,0.001,1,164634485.25
ADAM,0.001,2,161413558.07641602
ADAM,0.001,3,155732037.58642578
ADAM,0.001,4,148062624.59277344
ADAM,0.001,5,139245989.38964844
ADAM,0.001,6,130271991.12036133
ADAM,0.001,7,121895954.17553711
ADAM,0.001,8,114616893.24169922
ADAM,0.001,9,108618286.43334961
ADAM,0.001,10,103899005.87915039
