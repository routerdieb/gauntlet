Optimizer,learning_rate,epoch,loss
ADAM,0.01,1,242672797.66625977
ADAM,0.01,2,193726993.4523468
ADAM,0.01,3,79954536.0752716
