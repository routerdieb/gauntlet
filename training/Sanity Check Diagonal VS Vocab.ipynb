{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a55a713b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import h5py\n",
    "from Vocabulary import *\n",
    "co_filepath = 'S:\\\\base_coocurrence_hdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3f6593e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5006400\n",
      "148733\n"
     ]
    }
   ],
   "source": [
    "unfiltered_vocab = Vocabulary()\n",
    "unfiltered_vocab.load('..\\\\vocabs\\\\unfilteredbaseline')\n",
    "print(unfiltered_vocab.get_size())\n",
    "\n",
    "vocab = Vocabulary()\n",
    "vocab.load('..\\\\vocabs\\\\baseline')\n",
    "print(vocab.get_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db22f252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17cd8404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.000e+00, 9.700e+01, 8.904e+03, ..., 0.000e+00, 0.000e+00,\n",
       "       0.000e+00], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coocurrence[7,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65fc601c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0\n",
      "141.0\n",
      "[[8.0000e+00 1.2000e+02 3.5700e+02 ... 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [1.2000e+02 1.4100e+02 4.0660e+03 ... 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [3.5700e+02 4.0660e+03 1.7509e+04 ... 2.4000e+01 1.5000e+01 6.0000e+00]\n",
      " ...\n",
      " [0.0000e+00 0.0000e+00 2.4000e+01 ... 2.1000e+01 0.0000e+00 0.0000e+00]\n",
      " [0.0000e+00 0.0000e+00 1.5000e+01 ... 0.0000e+00 1.6000e+01 0.0000e+00]\n",
      " [0.0000e+00 0.0000e+00 6.0000e+00 ... 0.0000e+00 0.0000e+00 3.0000e+00]]\n",
      "supersonic transport\n",
      "2924\n",
      "83190\n"
     ]
    }
   ],
   "source": [
    "zeile = 0\n",
    "spalte = 0\n",
    "template = \"co_occurence_{i}_{j}.hdf5\".format(i=zeile,j=spalte)\n",
    "file_path =  r'S:\\base_coocurrence_hdf' + '\\\\' + template\n",
    "        \n",
    "tmp_hf = h5py.File(file_path, \"r+\")\n",
    "coocurrence = tmp_hf.get(\"co-ocurrence\")[:]\n",
    "if (spalte > zeile):\n",
    "    print('a')\n",
    "    coocurrence = np.transpose(coocurrence)\n",
    "#self.tf_co_occurences = tf.convert_to_tensor(coocurrence,dtype=tf.dtypes.float32)\n",
    "\n",
    "print(coocurrence[0,0])\n",
    "print(coocurrence[1,1])\n",
    "\n",
    "\n",
    "vocab_first = vocab.id2Word[0]\n",
    "vocab_second = vocab.id2Word[1]\n",
    "print(vocab_first,vocab_second)\n",
    "\n",
    "print(unfiltered_vocab.word_frequency[vocab_first])\n",
    "print(unfiltered_vocab.word_frequency[vocab_second])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70176081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145 1484\n",
      "90 1752\n",
      "51 1650\n",
      "98 1169\n",
      "12 557\n",
      "68 1027\n",
      "124 1432\n",
      "198 1326\n",
      "75 1183\n",
      "66 1518\n",
      "87 1601\n",
      "76 1555\n",
      "65 1471\n",
      "60 1121\n",
      "55 1278\n",
      "61 1477\n",
      "39 1690\n",
      "58 1487\n",
      "26 1209\n",
      "31 1368\n",
      "50 1436\n",
      "37 1015\n",
      "57 1204\n",
      "20 1318\n",
      "39 1322\n",
      "43 1088\n",
      "23 1244\n",
      "24 1233\n",
      "22 1313\n",
      "52 1208\n",
      "24 1200\n",
      "32 1151\n",
      "39 1140\n",
      "28 1180\n",
      "17 1180\n",
      "44 1210\n",
      "33 1065\n",
      "34 1213\n",
      "36 1114\n",
      "31 1011\n",
      "37 1095\n",
      "18 1144\n",
      "41 1182\n",
      "39 1011\n",
      "27 1218\n",
      "22 1139\n",
      "15 1126\n",
      "23 1094\n",
      "19 1001\n",
      "28 881\n",
      "29 1054\n",
      "18 1199\n",
      "28 997\n",
      "25 1328\n",
      "10 1190\n",
      "32 1031\n",
      "9 947\n",
      "13 1250\n",
      "22 1064\n",
      "21 963\n",
      "23 858\n",
      "38 977\n",
      "11 1136\n",
      "28 1086\n",
      "27 1025\n",
      "19 836\n",
      "12 1020\n",
      "21 969\n",
      "49 916\n",
      "53 1050\n",
      "11 475\n"
     ]
    }
   ],
   "source": [
    "path = '../coocurence data/'\n",
    "import collections\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "file_list = os.listdir(path)\n",
    "from Vocabulary import *\n",
    "from co_occurence import *\n",
    "from scipy.sparse import dok_matrix,csr_matrix,lil_matrix\n",
    "import scipy\n",
    "\n",
    "vocab = Vocabulary()\n",
    "vocab.load('../vocabs/baseline')\n",
    "size = vocab.get_size()\n",
    "\n",
    "capturer = Co_Occurence_Capturer()\n",
    "\n",
    "block_size = 20000 # must be int\n",
    "blocks_amount = math.ceil(vocab.get_size()/float(block_size))\n",
    "\n",
    "#init\n",
    "dict_of_dicts = {}\n",
    "for i in range(blocks_amount):\n",
    "    for j in range(blocks_amount):\n",
    "        dict_of_dicts[(i,j)]={}\n",
    "\n",
    "for file_name in file_list:\n",
    "    #print(file_name)\n",
    "    capturer.load_co_occurence(path + \"/\" + file_name)\n",
    "    coOcc_local = capturer.co_occurences\n",
    "    print(coOcc_local[0,0],coOcc_local[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffbe1a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2938 83462\n"
     ]
    }
   ],
   "source": [
    "path = r'..\\\\coocurrence_blocks\\\\'\n",
    "filename = 'block_0_0'\n",
    "\n",
    "with open(path+filename, 'rb+') as file:\n",
    "        co_occurences = cloudpickle.load(file)\n",
    "print(co_occurences[0,0],co_occurences[1,1])       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbe60b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
