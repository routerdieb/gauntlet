{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfd75792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipy\n",
      "  Downloading scipy-1.7.1-cp38-cp38-win_amd64.whl (33.7 MB)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in c:\\users\\weso\\anaconda3\\envs\\gaundlet-tf\\lib\\site-packages (from scipy) (1.19.5)\n",
      "Installing collected packages: scipy\n",
      "Successfully installed scipy-1.7.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25f0be31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1, 'b': 1, 'c': 1, 'd': 1, 'and': 1, 'then': 1, 'he': 1, 'was': 1, 'getting': 1, 'better': 1}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from Vocabulary import *\n",
    "import math\n",
    "import scipy\n",
    "\n",
    "sentence = '. , a b c d . , ! and then he was getting better . . , a'.split()\n",
    "\n",
    "vocab = Vocabulary()\n",
    "vocab.build_from_text(sentence)\n",
    "vocab.filter_just_symbol_tokens()\n",
    "print(vocab.word_frequency )\n",
    "vocab.assignIds(shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6daf836",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Co_Occurence_Capturer:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.co_occurences = {}\n",
    "        \n",
    "    def _assign_entrys(self,word_ids,context_ids,dist):\n",
    "        for word_id in word_ids:\n",
    "                for context_id in context_ids:\n",
    "                    tuple = (word_id,context_id)\n",
    "                    if tuple in self.co_occurences:\n",
    "                        self.co_occurences[tuple] += 1.0 / dist\n",
    "                    else:\n",
    "                        self.co_occurences[tuple] = 1.0 / dist\n",
    "\n",
    "\n",
    "    # Window lenght is one sided length\n",
    "    # The window is applied on the left and the right.\n",
    "    # A window size of 0 means, just the focus_word.\n",
    "    def capture_co_occurences(self,text, vocab, window_length,block_length):\n",
    "        amount_split = math.ceil(vocab.get_size() / float(block_length))\n",
    "        vocab.setBlock_parms(block_length)\n",
    "    \n",
    "        for x in range(amount_split):\n",
    "            for y in range(amount_split):\n",
    "                \n",
    "                context_ids = []\n",
    "                for focus_index,focus_word in enumerate(text):\n",
    "                    \n",
    "                    focus_ids = vocab.get_contrained_ids_text(focus_word,x)\n",
    "                    \n",
    "                    #left words\n",
    "                    window_left = []\n",
    "                    current_position = focus_index - 1\n",
    "                    while(len(window_left) < window_length and current_position >= 0):\n",
    "                        word = text[current_position]\n",
    "                        if( word in vocab.word2Id):#is not filtered out word\n",
    "                            window_left.insert(0,word)\n",
    "                        current_position -= 1\n",
    "                    for index,context_word in enumerate(window_left):\n",
    "                        dist = abs(len(window_left) - index)\n",
    "                        context_ids = vocab.get_contrained_ids_text(context_word,y)\n",
    "                        self._assign_entrys(focus_ids,context_ids,dist) \n",
    "                        \n",
    "                    #rigth words\n",
    "                    window_right = []\n",
    "                    current_position = focus_index + 1\n",
    "                    while(len(window_right) < window_length and current_position < len(text)):\n",
    "                        word = text[current_position]\n",
    "                        if( word in vocab.word2Id):\n",
    "                            window_right.append(word)\n",
    "                        current_position += 1\n",
    "                    \n",
    "                    for index,context_word in enumerate(window_right):\n",
    "                        dist = abs(1+ index)\n",
    "                        context_ids = vocab.get_contrained_ids_text(context_word,y)\n",
    "                        self._assign_entrys(focus_ids,context_ids,dist) \n",
    "                            \n",
    "        return self.co_occurences\n",
    "    \n",
    "    def save_coocurrences(self,file_name):\n",
    "        with open(file_name, 'wb') as file:\n",
    "            cloudpickle.dump(self.co_occurences, file)\n",
    "        self.co_occurences = {}\n",
    "\n",
    "    def load_co_occurence(self,name):\n",
    "        with open(name, 'rb+') as file:\n",
    "            self.co_occurences = cloudpickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "134feef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(vocab.get_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a0dbedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "capturer = Co_Occurence_Capturer()\n",
    "c = capturer.capture_co_occurences(sentence,vocab,3,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62e6be2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 0, 'b': 1, 'c': 2, 'd': 3, 'and': 4, 'then': 5, 'he': 6, 'was': 7, 'getting': 8, 'better': 9}\n",
      "{(0, 1): 1.0, (0, 2): 0.5, (0, 3): 0.3333333333333333, (1, 0): 1.0, (1, 2): 1.0, (1, 3): 0.5, (1, 4): 0.3333333333333333, (2, 0): 0.5, (2, 1): 1.0, (2, 3): 1.0, (2, 4): 0.5, (2, 5): 0.3333333333333333, (3, 0): 0.3333333333333333, (3, 1): 0.5, (3, 2): 1.0, (3, 4): 1.0, (3, 5): 0.5, (3, 6): 0.3333333333333333, (4, 1): 0.3333333333333333, (4, 2): 0.5, (4, 3): 1.0, (4, 5): 1.0, (4, 6): 0.5, (4, 7): 0.3333333333333333, (5, 2): 0.3333333333333333, (5, 3): 0.5, (5, 4): 1.0, (5, 6): 1.0, (5, 7): 0.5, (5, 8): 0.3333333333333333, (6, 3): 0.3333333333333333, (6, 4): 0.5, (6, 5): 1.0, (6, 7): 1.0, (6, 8): 0.5, (6, 9): 0.3333333333333333, (7, 4): 0.3333333333333333, (7, 5): 0.5, (7, 6): 1.0, (7, 8): 1.0, (7, 9): 0.5, (8, 5): 0.3333333333333333, (8, 6): 0.5, (8, 7): 1.0, (8, 9): 1.0, (9, 6): 0.3333333333333333, (9, 7): 0.5, (9, 8): 1.0}\n"
     ]
    }
   ],
   "source": [
    "print(vocab.word2Id)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbe5fe18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         1.         0.5        0.33333334 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [1.         0.         1.         0.5        0.33333334 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.5        1.         0.         1.         0.5        0.33333334\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.33333334 0.5        1.         0.         1.         0.5\n",
      "  0.33333334 0.         0.         0.        ]\n",
      " [0.         0.33333334 0.5        1.         0.         1.\n",
      "  0.5        0.33333334 0.         0.        ]\n",
      " [0.         0.         0.33333334 0.5        1.         0.\n",
      "  1.         0.5        0.33333334 0.        ]\n",
      " [0.         0.         0.         0.33333334 0.5        1.\n",
      "  0.         1.         0.5        0.33333334]\n",
      " [0.         0.         0.         0.         0.33333334 0.5\n",
      "  1.         0.         1.         0.5       ]\n",
      " [0.         0.         0.         0.         0.         0.33333334\n",
      "  0.5        1.         0.         1.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.33333334 0.5        1.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import dok_matrix\n",
    "S = dok_matrix((vocab.get_size(), vocab.get_size()), dtype=np.float32)\n",
    "S._update(c)\n",
    "print(S.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06959978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20fd762e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 1.  , 0.5 , 0.33, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [1.  , 0.  , 1.  , 0.5 , 0.33, 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.5 , 1.  , 0.  , 1.  , 0.5 , 0.33, 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.33, 0.5 , 1.  , 0.  , 1.  , 0.5 , 0.33, 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.33, 0.5 , 1.  , 0.  , 1.  , 0.5 , 0.33, 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.33, 0.5 , 1.  , 0.  , 1.  , 0.5 , 0.33, 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.33, 0.5 , 1.  , 0.  , 1.  , 0.5 , 0.33],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.33, 0.5 , 1.  , 0.  , 1.  , 0.5 ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.33, 0.5 , 1.  , 0.  , 1.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.33, 0.5 , 1.  , 0.  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S.toarray().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f71222",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
