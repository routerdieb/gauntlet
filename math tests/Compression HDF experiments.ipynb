{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9708b713",
   "metadata": {},
   "source": [
    "# The mirroring is quite computational expensive therefore the diagonal blocks get precomputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4a05187",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudpickle\n",
    "from scipy.sparse import dok_matrix\n",
    "from scipy.sparse import tril\n",
    "\n",
    "\n",
    "def load_dict(path,zeilen,spalten):\n",
    "    if(spalten > zeilen):\n",
    "        template = \"block_{i}_{j}\".format(i=spalten,j=zeilen)\n",
    "    else:\n",
    "        template = \"block_{i}_{j}\".format(i=zeilen,j=spalten)\n",
    "\n",
    "    file_path = path + '\\\\' + template\n",
    "    with open(file_path, 'rb+') as file:\n",
    "        co_occurences = cloudpickle.load(file)\n",
    "    \n",
    "    return co_occurences\n",
    "\n",
    "\n",
    "def load_co_occurence(path,zeilen,spalten):\n",
    "    co_occurences = load_dict(path,zeilen,spalten)\n",
    "    coocurrence = dok_matrix((20000,20000),dtype='i')\n",
    "    \n",
    "    coocurrence._update(co_occurences) # dok_matrix updates #7673 pull request\n",
    "\n",
    "    if spalten > zeilen :\n",
    "        print('transposing')\n",
    "        #this is now done in the training code, to decrease amount of non-empty files\n",
    "        #coocurrence = coocurrence.transpose()\n",
    "    \n",
    "    if spalten == zeilen:\n",
    "        print('mirroring')\n",
    "        #print(coocurrence.toarray())\n",
    "        coocurrence = coocurrence + tril(coocurrence,k=-1).transpose()\n",
    "    \n",
    "    return coocurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21741f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "hello\n",
      "output for progress 0,0\n",
      "mirroring\n",
      "<Closed HDF5 dataset>\n",
      "0 1\n",
      "0 2\n",
      "0 3\n",
      "0 4\n",
      "0 5\n",
      "0 6\n",
      "0 7\n",
      "1 0\n",
      "1 1\n",
      "1 2\n",
      "1 3\n",
      "1 4\n",
      "1 5\n",
      "1 6\n",
      "1 7\n",
      "2 0\n",
      "2 1\n",
      "2 2\n",
      "2 3\n",
      "2 4\n",
      "2 5\n",
      "2 6\n",
      "2 7\n",
      "3 0\n",
      "3 1\n",
      "3 2\n",
      "3 3\n",
      "3 4\n",
      "3 5\n",
      "3 6\n",
      "3 7\n",
      "4 0\n",
      "4 1\n",
      "4 2\n",
      "4 3\n",
      "4 4\n",
      "4 5\n",
      "4 6\n",
      "4 7\n",
      "5 0\n",
      "5 1\n",
      "5 2\n",
      "5 3\n",
      "5 4\n",
      "5 5\n",
      "5 6\n",
      "5 7\n",
      "6 0\n",
      "6 1\n",
      "6 2\n",
      "6 3\n",
      "6 4\n",
      "6 5\n",
      "6 6\n",
      "6 7\n",
      "7 0\n",
      "7 1\n",
      "7 2\n",
      "7 3\n",
      "7 4\n",
      "7 5\n",
      "7 6\n",
      "7 7\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import h5py\n",
    "\n",
    "\n",
    "path = '..\\coocurrence_blocks'\n",
    "path_hdf = r'S:\\\\base_coocurrence_hdf\\\\'\n",
    "regex = r'block_([0-9]{1,})_([0-9]{1,})'\n",
    "for file_name in os.listdir(path):\n",
    "    match = re.match(regex, file_name)\n",
    "    i     = match.group(1)\n",
    "    j     = match.group(2)\n",
    "    print(i,j)\n",
    "    if (i == '0' and j == '0'):\n",
    "        print('hello')\n",
    "        pass\n",
    "    else:\n",
    "        continue\n",
    "    print('output for progress ' + str(i)+','+str(j))\n",
    "    co_occurence_dok = load_co_occurence(path,i,j)\n",
    "    co_occurence_np  = co_occurence_dok.toarray()\n",
    "    f = h5py.File( path_hdf +'./co_occurence_{i}_{j}_gzip.hdf5'.format(i=i,j=j), \"w\")#plus experiment name\n",
    "    co_occurence_hdf = f.create_dataset(\"co-ocurrence\", (20000, 20000),compression='gzip')\n",
    "    co_occurence_hdf[:,:] =  co_occurence_np\n",
    "    f.close()\n",
    "    print(co_occurence_hdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f46ee9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "hello\n",
      "output for progress 0,0\n",
      "mirroring\n",
      "<Closed HDF5 dataset>\n",
      "0 1\n",
      "0 2\n",
      "0 3\n",
      "0 4\n",
      "0 5\n",
      "0 6\n",
      "0 7\n",
      "1 0\n",
      "1 1\n",
      "1 2\n",
      "1 3\n",
      "1 4\n",
      "1 5\n",
      "1 6\n",
      "1 7\n",
      "2 0\n",
      "2 1\n",
      "2 2\n",
      "2 3\n",
      "2 4\n",
      "2 5\n",
      "2 6\n",
      "2 7\n",
      "3 0\n",
      "3 1\n",
      "3 2\n",
      "3 3\n",
      "3 4\n",
      "3 5\n",
      "3 6\n",
      "3 7\n",
      "4 0\n",
      "4 1\n",
      "4 2\n",
      "4 3\n",
      "4 4\n",
      "4 5\n",
      "4 6\n",
      "4 7\n",
      "5 0\n",
      "5 1\n",
      "5 2\n",
      "5 3\n",
      "5 4\n",
      "5 5\n",
      "5 6\n",
      "5 7\n",
      "6 0\n",
      "6 1\n",
      "6 2\n",
      "6 3\n",
      "6 4\n",
      "6 5\n",
      "6 6\n",
      "6 7\n",
      "7 0\n",
      "7 1\n",
      "7 2\n",
      "7 3\n",
      "7 4\n",
      "7 5\n",
      "7 6\n",
      "7 7\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "path = '..\\coocurrence_blocks'\n",
    "path_hdf = r'S:\\\\base_coocurrence_hdf\\\\'\n",
    "regex = r'block_([0-9]{1,})_([0-9]{1,})'\n",
    "for file_name in os.listdir(path):\n",
    "    match = re.match(regex, file_name)\n",
    "    i     = match.group(1)\n",
    "    j     = match.group(2)\n",
    "    print(i,j)\n",
    "    if (i == '0' and j == '0'):\n",
    "        print('hello')\n",
    "        pass\n",
    "    else:\n",
    "        continue\n",
    "    print('output for progress ' + str(i)+','+str(j))\n",
    "    co_occurence_dok = load_co_occurence(path,i,j)\n",
    "    co_occurence_np  = co_occurence_dok.toarray()\n",
    "    f = h5py.File( path_hdf +'./co_occurence_{i}_{j}_lzf.hdf5'.format(i=i,j=j), \"w\")#plus experiment name\n",
    "    co_occurence_hdf = f.create_dataset(\"co-ocurrence\", (20000, 20000),compression='lzf')\n",
    "    co_occurence_hdf[:,:] =  co_occurence_np\n",
    "    f.close()\n",
    "    print(co_occurence_hdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8662dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "hello\n",
      "output for progress 0,0\n",
      "mirroring\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'co_occurence_hdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-b4a80ed4c2ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mco_occurence_np\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mco_occurence_dok\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test_{i}_{j}.np'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mco_occurence_np\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mco_occurence_hdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'co_occurence_hdf' is not defined"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "path = 'S:\\\\tmp\\\\coocurrence_blocks'\n",
    "path_hdf = r'S:\\\\base_coocurrence_hdf\\\\'\n",
    "regex = r'block_([0-9]{1,})_([0-9]{1,})'\n",
    "for file_name in os.listdir(path):\n",
    "    match = re.match(regex, file_name)\n",
    "    i     = match.group(1)\n",
    "    j     = match.group(2)\n",
    "    print(i,j)\n",
    "    if (i == '0' and j == '0'):\n",
    "        print('hello')\n",
    "        pass\n",
    "    else:\n",
    "        continue\n",
    "    print('output for progress ' + str(i)+','+str(j))\n",
    "    co_occurence_dok = load_co_occurence(path,i,j)\n",
    "    co_occurence_np  = co_occurence_dok.toarray()\n",
    "    np.save('test_{i}_{j}.np'.format(i=i,j=j),co_occurence_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a4422d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time in seconds: 0.6707384586334229\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "startTime = time.time()\n",
    "\n",
    "template = \"co_occurence_{i}_{j}.hdf5\".format(i=1,j=1)\n",
    "tmp_hf = h5py.File(path_hdf + template, \"r+\")\n",
    "coocurrence = tmp_hf.get(\"co-ocurrence\")[:]\n",
    "tf_co_occurences = tf.convert_to_tensor(coocurrence[:],dtype=tf.dtypes.float32)\n",
    "tmp_hf.close()\n",
    "\n",
    "executionTime = (time.time() - startTime)\n",
    "print('Execution time in seconds: ' + str(executionTime))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2eaee701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time in seconds: 6.035322189331055\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "startTime = time.time()\n",
    "\n",
    "template = \"co_occurence_{i}_{j}_gzip.hdf5\".format(i=0,j=0)\n",
    "tmp_hf = h5py.File(path_hdf + template, \"r+\")\n",
    "tf_co_occurences = tf.convert_to_tensor(tmp_hf.get(\"co-ocurrence\")[:],dtype=tf.dtypes.float32)\n",
    "tmp_hf.close()\n",
    "\n",
    "executionTime = (time.time() - startTime)\n",
    "print('Execution time in seconds: ' + str(executionTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b588e9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time in seconds: 4.649369955062866\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "startTime = time.time()\n",
    "\n",
    "template = \"co_occurence_{i}_{j}_lzf.hdf5\".format(i=0,j=0)\n",
    "tmp_hf = h5py.File(path_hdf + template, \"r+\")\n",
    "tf_co_occurences = tf.convert_to_tensor(tmp_hf.get(\"co-ocurrence\")[:],dtype=tf.dtypes.float32)\n",
    "tmp_hf.close()\n",
    "\n",
    "executionTime = (time.time() - startTime)\n",
    "print('Execution time in seconds: ' + str(executionTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bafee12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time in seconds: 3.9026272296905518\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "startTime = time.time()\n",
    "\n",
    "array = np.load(path_hdf +'test_{i}_{j}.np.npy'.format(i=0,j=0))\n",
    "tf_co_occurences = tf.convert_to_tensor(array[:])\n",
    "\n",
    "executionTime = (time.time() - startTime)\n",
    "print('Execution time in seconds: ' + str(executionTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3729bfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_hdf + 'test_0_0.tensor', 'wb+') as file:\n",
    "            cloudpickle.dump(tf_co_occurences, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0f037e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time in seconds: 0.5051162242889404\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "startTime = time.time()\n",
    "\n",
    "with open(path_hdf + 'test_0_0.tensor', 'rb') as file:\n",
    "            tensor = cloudpickle.load(file)\n",
    "\n",
    "\n",
    "executionTime = (time.time() - startTime)\n",
    "print('Execution time in seconds: ' + str(executionTime))\n",
    "print(type(tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b361bcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
