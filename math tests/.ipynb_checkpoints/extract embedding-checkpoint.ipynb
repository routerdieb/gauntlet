{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd3e258a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"    \n",
    "import tensorflow as tf\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from Vocabulary import *\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e7d5a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#only for nomalised a and b\n",
    "def fast_cosine(a,b):\n",
    "    return np.dot(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85748970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191\n",
      "tf.Tensor(-0.90751576, shape=(), dtype=float32)\n",
      "tf.Tensor(-0.26243383, shape=(), dtype=float32)\n",
      "tf.Tensor(-0.30956408, shape=(), dtype=float32)\n",
      "tf.Tensor(-0.5044129, shape=(), dtype=float32)\n",
      "tf.Tensor(-0.22656062, shape=(), dtype=float32)\n",
      "tf.Tensor(-0.3765081, shape=(), dtype=float32)\n",
      "tf.Tensor(-0.33438247, shape=(), dtype=float32)\n",
      "tf.Tensor(-0.5544299, shape=(), dtype=float32)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.float32' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-d758f0bc0888>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmin_word\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'small'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'smaller'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'weak'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'big'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'bigger'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'small'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'germany'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'berlin'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'france'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-d758f0bc0888>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(a, a_star, b)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword2Id\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mword_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweights_normalized\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_ids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfast_cosine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mword_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[0mmin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.float32' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "vocab = Vocabulary()\n",
    "vocab.load('../vocabs/text8_filtered100')\n",
    "\n",
    "matrix_nr = vocab.get_ids(['man'])[0]\n",
    "print(matrix_nr)\n",
    "\n",
    "#hdf_file = h5py.File('testRunCleanSplitted300.hdf5', 'r')\n",
    "hdf_file = h5py.File('S:\\\\testRunCleanSplitted300.hdf5','r')\n",
    "weights = hdf_file.get('weights')\n",
    "weights = weights[:]\n",
    "context_weights = hdf_file.get('context-weights')\n",
    "\n",
    "cosine_loss = tf.keras.losses.CosineSimilarity(axis=0)\n",
    "\n",
    "def compare_words(word1,word2):\n",
    "    id1 = vocab.get_ids([word1])[0]\n",
    "    id2 = vocab.get_ids([word2])[0]\n",
    "    return cosine_loss(weights[id1],weights[id2])\n",
    "\n",
    "\n",
    "print(compare_words('the','a'))\n",
    "print(compare_words('boat','fish'))\n",
    "print(compare_words('strong','stronger'))\n",
    "#print(compare_words('C','D'))\n",
    "print(compare_words('man','woman'))\n",
    "print(compare_words('the','president'))\n",
    "print(compare_words('stronger','weaker'))\n",
    "print(compare_words('berlin','paris'))\n",
    "print(compare_words('germany','france'))\n",
    "\n",
    "weights_normalized = tf.nn.l2_normalize(weights,axis = 0)\n",
    "def predict(a,a_star,b):\n",
    "    if( a in vocab.word2Id and b in vocab.word2Id and a_star in vocab.word2Id):\n",
    "        pass\n",
    "    else:\n",
    "        return \"\"\n",
    "    id_a = vocab.get_ids([a])[0]\n",
    "    id_b = vocab.get_ids([b])[0]\n",
    "    id_a_star = vocab.get_ids([a_star])[0]\n",
    "    weight_a = weights_normalized[id_a]\n",
    "    weight_b = weights_normalized[id_b]\n",
    "    weight_a_star = weights_normalized[id_a_star]\n",
    "    vector = weight_b + ( weight_a_star - weight_a)\n",
    "    min = -1\n",
    "    min_word = ''\n",
    "    for word in vocab.word2Id:\n",
    "        word_weights = weights_normalized[vocab.get_ids([word])[0]]\n",
    "        loss = fast_cosine(vector,word_weights)#.numpy()\n",
    "        if(min == -1):\n",
    "            min = loss\n",
    "            min_word = word\n",
    "        elif(min > loss):\n",
    "            min = loss\n",
    "            min_word = word\n",
    "    print(min)\n",
    "    return min_word\n",
    "\n",
    "print(predict('small','smaller','weak'))\n",
    "print(predict('big','bigger','small'))\n",
    "print(predict('germany','berlin','france'))\n",
    "print(predict('one','two','three'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d710c364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('smaller', -1.0000002), ('larger', -0.7289822), ('large', -0.5226358), ('small', -0.5163931), ('than', -0.5097976), ('slightly', -0.4922008), ('less', -0.49216217)]\n",
      "[('computer', -0.9999999), ('computers', -0.59070754), ('software', -0.5282564), ('systems', -0.48256886), ('video', -0.4663046), ('hardware', -0.43653536), ('technology', -0.42260754)]\n"
     ]
    }
   ],
   "source": [
    "# Function to insert element\n",
    "def insert(list, tuple):\n",
    "    (word,n) = tuple\n",
    "    if(len(list) == 0):\n",
    "        list = [(word,n)]\n",
    "    # Searching for the position\n",
    "    for i in range(len(list)):\n",
    "        (word_i,n_i) = list[i]\n",
    "        if n_i > n:\n",
    "            index = i\n",
    "            break\n",
    "      \n",
    "    # Inserting n in the list\n",
    "    list = list[:i] + [(word,n)] + list[i:]\n",
    "    return list\n",
    "\n",
    "\n",
    "def find_nearest_k(searched_word,k):\n",
    "    list = []\n",
    "    searched_vector = weights[vocab.get_ids([searched_word])[0]]\n",
    "    \n",
    "    for word in vocab.word2Id:\n",
    "        word_weights = weights[vocab.get_ids([word])[0]]\n",
    "        loss = cosine_loss(searched_vector,word_weights).numpy()\n",
    "        list = insert(list,(word,loss))\n",
    "        if len(list)>k:\n",
    "            list = list[0:k+1]\n",
    "    return list[0:k]\n",
    "\n",
    "print(find_nearest_k('smaller',7))\n",
    "print(find_nearest_k('computer',7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07972b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('president', -1.0),\n",
       " ('vice', -0.5031545),\n",
       " ('elected', -0.4648685),\n",
       " ('administration', -0.4533813),\n",
       " ('presidents', -0.43571424),\n",
       " ('prime', -0.43489614),\n",
       " ('minister', -0.43397298)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_nearest_k('president',7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a87eba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('france', -0.9999999),\n",
       " ('italy', -0.58509463),\n",
       " ('french', -0.58080566),\n",
       " ('germany', -0.5544299),\n",
       " ('spain', -0.5457665),\n",
       " ('paris', -0.5070268),\n",
       " ('kingdom', -0.4944514)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_nearest_k('france',7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b0bbca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find_nearest_k('three',7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbaf3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.7095763\n",
      "-0.65637636\n",
      "-0.67009336\n",
      "-0.6646427\n",
      "-0.68805254\n",
      "-0.68913597\n",
      "-0.65073097\n",
      "-0.64831984\n",
      "-0.69174975\n",
      "-0.66770744\n",
      "-0.6682843\n",
      "-0.6932311\n",
      "-0.67108285\n",
      "-0.6102568\n",
      "-0.63872945\n",
      "-0.6497289\n",
      "-0.63305575\n",
      "-0.640862\n",
      "-0.6240151\n",
      "-0.5917627\n",
      "-0.62497383\n",
      "-0.65631676\n",
      "-0.6048439\n",
      "-0.59660935\n",
      "-0.639133\n",
      "-0.6301321\n",
      "-0.6197914\n",
      "-0.6521325\n",
      "-0.65358686\n",
      "-0.61134654\n",
      "-0.57691354\n",
      "-0.680525\n",
      "-0.61431926\n",
      "-0.5972918\n",
      "-0.5904699\n",
      "-0.6195754\n",
      "-0.62561816\n",
      "-0.6248478\n",
      "-0.64027965\n",
      "-0.58779126\n",
      "-0.6474025\n",
      "-0.62124795\n",
      "-0.65247965\n",
      "-0.64541817\n",
      "-0.6058355\n",
      "-0.5583976\n",
      "-0.64744735\n",
      "-0.6490003\n",
      "-0.6480483\n",
      "-0.6771327\n",
      "-0.6513148\n",
      "-0.66714203\n",
      "-0.67789865\n",
      "-0.69110715\n",
      "-0.6642778\n",
      "-0.66047406\n",
      "-0.6415509\n",
      "-0.66565806\n",
      "-0.6823051\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-c0fded368e6e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma_star\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb_star\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma_star\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mb_star\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"hurray\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma_star\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb_star\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-94a679004074>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(a, a_star, b)\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[0mword_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_ids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0mword_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml2_normalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcosine_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mword_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mmin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\losses.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[0mcall_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m       \u001b[0mlosses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m       return losses_utils.compute_weighted_loss(\n\u001b[0m\u001b[0;32m    157\u001b[0m           losses, sample_weight, reduction=self._get_reduction())\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\utils\\losses_utils.py\u001b[0m in \u001b[0;36mcompute_weighted_loss\u001b[1;34m(losses, sample_weight, reduction, name)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m     \u001b[1;31m# Apply reduction function to the individual weighted losses.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreduce_weighted_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweighted_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    318\u001b[0m     \u001b[1;31m# Convert the result back to the input type.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\utils\\losses_utils.py\u001b[0m in \u001b[0;36mreduce_weighted_loss\u001b[1;34m(weighted_losses, reduction)\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweighted_losses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 259\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweighted_losses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    260\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreduction\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mReductionV2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSUM_OVER_BATCH_SIZE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m       \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_safe_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_num_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweighted_losses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mreduce_sum\u001b[1;34m(input_tensor, axis, keepdims, name)\u001b[0m\n\u001b[0;32m   2117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2118\u001b[0m   return reduce_sum_with_dims(input_tensor, axis, keepdims, name,\n\u001b[1;32m-> 2119\u001b[1;33m                               _ReductionDims(input_tensor, axis))\n\u001b[0m\u001b[0;32m   2120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36m_ReductionDims\u001b[1;34m(x, axis)\u001b[0m\n\u001b[0;32m   1957\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1958\u001b[0m       \u001b[1;31m# Otherwise, we rely on Range and Rank to do the right thing at run-time.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1959\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1960\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mrange\u001b[1;34m(start, limit, delta, dtype, name)\u001b[0m\n\u001b[0;32m   1927\u001b[0m     \u001b[0mdelta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minferred_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1928\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1929\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1931\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36m_range\u001b[1;34m(start, limit, delta, name)\u001b[0m\n\u001b[0;32m   7357\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7358\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7359\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m   7360\u001b[0m         _ctx, \"Range\", name, start, limit, delta)\n\u001b[0;32m   7361\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "count_sucess = 0\n",
    "count_unsucessful = 0\n",
    "with open(r'..\\datasets\\miklov Analogies.txt') as file:\n",
    "    for line in file:\n",
    "        if line.startswith(\":\"):\n",
    "            pass\n",
    "        else:\n",
    "            a,a_star,b,b_star = line.split(\" \")\n",
    "            if(predict(a,a_star,b) == b_star):\n",
    "                print(\"hurray\")\n",
    "                print(a,a_star,b,b_star)\n",
    "                count_sucess += 1\n",
    "            else:\n",
    "                count_unsucessful += 1\n",
    "print(count_sucess,count_unsucessful)\n",
    "print(count_sucess/count_unsucessful * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945f3c08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
