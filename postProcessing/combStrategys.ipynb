{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f73fc034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"    \n",
    "import tensorflow as tf\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from Vocabulary import *\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2b0080",
   "metadata": {},
   "source": [
    "# Next block contains all parameters, which need to be set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d7d2dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configure this block\n",
    "embedding_path = r\"D:\\\\mixed\\\\\"\n",
    "embedding_name = 'ner_mixed_150w'\n",
    "outlocation = \"D:\\\\MixS1\\\\\"\n",
    "New_emb_Name_path = outlocation+embedding_name + '_combined'#later added with String _strategyX\n",
    "unfiltered_vocab = Vocabulary()\n",
    "unfiltered_vocab.load(r\"C:\\Users\\weso\\Desktop\\gauntlet\\vocabs\\unfilteredvocab_ner_mixed\")\n",
    "dimensions = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c69bc11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "617537\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "id_dict = {}\n",
    "word_dict = {}\n",
    "\n",
    "matrix = []\n",
    "full_path = os.path.join(embedding_path,embedding_name)\n",
    "with open(full_path, 'r' , encoding=\"utf-8\")  as f:\n",
    "    lines = f.readlines()\n",
    "    vocab_size = len(lines)\n",
    "    \n",
    "    matrix = np.zeros((vocab_size,dimensions),dtype=float)\n",
    "    for line in lines:\n",
    "        values = line.split()\n",
    "        word = values[0].strip()\n",
    "        id = len(id_dict)\n",
    "        id_dict[word]=id\n",
    "        word_dict[id] = word\n",
    "        vector = np.asarray(values[1:], \"double\")\n",
    "        matrix[id_dict[word],:] = vector\n",
    "print(len(id_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46cf62ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260468\n",
      "['duck\\x04org', 'duck', 'duck\\x04work_of_art', 'duck\\x04gpe', 'duck\\x04fac', 'duck\\x04person', 'duck\\x04loc', 'duck\\x04']\n",
      "['the\\x04money', 'the\\x04work_of_art', 'the\\x04person', 'the\\x04law', 'the\\x04gpe', 'the\\x04fac', 'the', 'the\\x04event', 'the\\x04time', 'the\\x04product', 'the\\x04date', 'the\\x04loc', 'the\\x04org', 'the\\x04', 'the\\x04norp', 'the\\x04cardinal', 'the\\x04percent', 'the\\x04quantity']\n",
      "['bank\\x04date', 'bank\\x04fac', 'bank\\x04gpe', 'bank\\x04org', 'bank\\x04event', 'bank', 'bank\\x04loc', 'bank\\x04work_of_art', 'bank\\x04', 'bank\\x04person']\n",
      "---------\n",
      "{'ppv': ['ppv\\x04', 'ppv', 'ppv\\x04org'], 'ingraham': ['ingraham', 'ingraham\\x04person', 'ingraham\\x\n",
      "['splashdown\\x04', 'splashdown']\n"
     ]
    }
   ],
   "source": [
    "#find all variants of a word, without the tag rep\n",
    "def group_all_words(id_dict):\n",
    "    groups = {}\n",
    "    for word in id_dict:\n",
    "        #print(word)\n",
    "        if is_tagged_word(word):\n",
    "            #print('is tagged')\n",
    "            baseword = word.split(chr(4))[0]\n",
    "            #print(baseword)\n",
    "            if baseword in groups:\n",
    "                groups[baseword].append(word)\n",
    "            else:\n",
    "                groups[baseword] = [word]\n",
    "        elif word.startswith(chr(4)):#exclude tags\n",
    "            pass\n",
    "        else:\n",
    "            if word in groups:\n",
    "                groups[word].append(word)\n",
    "            else:\n",
    "                groups[word] = [word]\n",
    "    return groups\n",
    "\n",
    "def is_tagged_word(word):\n",
    "    return not word.startswith(chr(4)) and str(chr(4)) in word\n",
    "\n",
    "groups = group_all_words(id_dict)\n",
    "print(len(groups))\n",
    "print(groups['duck'])\n",
    "print(groups['the'])\n",
    "print(groups['bank'])\n",
    "print('---------')\n",
    "print(str(groups)[:100])\n",
    "print(groups[\"splashdown\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf49e0b1",
   "metadata": {},
   "source": [
    "# helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01fd5a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count(word):\n",
    "    return unfiltered_vocab.word_frequency[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72408844",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_new_embedding(embedding,path):\n",
    "    with open(path,'w+',encoding='utf8') as file:\n",
    "        for id,word in enumerate(embedding):\n",
    "            if(id % 1000 == 0):\n",
    "                print(id,len(embedding))\n",
    "            \n",
    "            file.write(word)\n",
    "            vector = embedding[word]\n",
    "            for coord in vector:\n",
    "                file.write(' '+str(coord))\n",
    "            file.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690ae310",
   "metadata": {},
   "source": [
    "# Strategy 1 weighted Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b80da522",
   "metadata": {},
   "outputs": [],
   "source": [
    "#requires tag rep\n",
    "def mult_strat_weighted(word_groups,normalise_before_mult):\n",
    "    emb = {}\n",
    "    \n",
    "    if(normalise_before_mult):\n",
    "        matrix_copy = tf.nn.l2_normalize(matrix,axis = 1)\n",
    "    else:\n",
    "        matrix_copy = matrix\n",
    "        \n",
    "    for word_key in groups:\n",
    "\n",
    "        base_count = 0 # total apearance of the baseword\n",
    "        for word in word_groups[word_key]:\n",
    "            if(word.startswith(chr(4))):#no rep for tags\n",
    "                continue\n",
    "            c = get_count(word)\n",
    "            base_count += c\n",
    "        \n",
    "        emb_sum = 0\n",
    "        for word in word_groups[word_key]:\n",
    "            if chr(4) in word:\n",
    "                if(word.startswith(chr(4))):#no rep for tags\n",
    "                    continue\n",
    "                baseword ,tag  = word.split(chr(4))\n",
    "                id_word = id_dict[word]\n",
    "                #id_tag  = id_dict[chr(4)+tag]\n",
    "                #emb_sum += (get_count(word)/base_count)*(matrix_copy[id_word] * matrix_copy[id_tag])\n",
    "                emb_sum += (get_count(word)/base_count) * (matrix_copy[id_word])\n",
    "            else:#only in mixed embedding add the base unscaled\n",
    "                emb_sum += (get_count(word)/base_count) * matrix_copy[id_dict[word]]\n",
    "        emb[baseword] = emb_sum\n",
    "    return emb\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bd49a34",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 195699\n",
      "1000 195699\n",
      "2000 195699\n",
      "3000 195699\n",
      "4000 195699\n",
      "5000 195699\n",
      "6000 195699\n",
      "7000 195699\n",
      "8000 195699\n",
      "9000 195699\n",
      "10000 195699\n",
      "11000 195699\n",
      "12000 195699\n",
      "13000 195699\n",
      "14000 195699\n",
      "15000 195699\n",
      "16000 195699\n",
      "17000 195699\n",
      "18000 195699\n",
      "19000 195699\n",
      "20000 195699\n",
      "21000 195699\n",
      "22000 195699\n",
      "23000 195699\n",
      "24000 195699\n",
      "25000 195699\n",
      "26000 195699\n",
      "27000 195699\n",
      "28000 195699\n",
      "29000 195699\n",
      "30000 195699\n",
      "31000 195699\n",
      "32000 195699\n",
      "33000 195699\n",
      "34000 195699\n",
      "35000 195699\n",
      "36000 195699\n",
      "37000 195699\n",
      "38000 195699\n",
      "39000 195699\n",
      "40000 195699\n",
      "41000 195699\n",
      "42000 195699\n",
      "43000 195699\n",
      "44000 195699\n",
      "45000 195699\n",
      "46000 195699\n",
      "47000 195699\n",
      "48000 195699\n",
      "49000 195699\n",
      "50000 195699\n",
      "51000 195699\n",
      "52000 195699\n",
      "53000 195699\n",
      "54000 195699\n",
      "55000 195699\n",
      "56000 195699\n",
      "57000 195699\n",
      "58000 195699\n",
      "59000 195699\n",
      "60000 195699\n",
      "61000 195699\n",
      "62000 195699\n",
      "63000 195699\n",
      "64000 195699\n",
      "65000 195699\n",
      "66000 195699\n",
      "67000 195699\n",
      "68000 195699\n",
      "69000 195699\n",
      "70000 195699\n",
      "71000 195699\n",
      "72000 195699\n",
      "73000 195699\n",
      "74000 195699\n",
      "75000 195699\n",
      "76000 195699\n",
      "77000 195699\n",
      "78000 195699\n",
      "79000 195699\n",
      "80000 195699\n",
      "81000 195699\n",
      "82000 195699\n",
      "83000 195699\n",
      "84000 195699\n",
      "85000 195699\n",
      "86000 195699\n",
      "87000 195699\n",
      "88000 195699\n",
      "89000 195699\n",
      "90000 195699\n",
      "91000 195699\n",
      "92000 195699\n",
      "93000 195699\n",
      "94000 195699\n",
      "95000 195699\n",
      "96000 195699\n",
      "97000 195699\n",
      "98000 195699\n",
      "99000 195699\n",
      "100000 195699\n",
      "101000 195699\n",
      "102000 195699\n",
      "103000 195699\n",
      "104000 195699\n",
      "105000 195699\n",
      "106000 195699\n",
      "107000 195699\n",
      "108000 195699\n",
      "109000 195699\n",
      "110000 195699\n",
      "111000 195699\n",
      "112000 195699\n",
      "113000 195699\n",
      "114000 195699\n",
      "115000 195699\n",
      "116000 195699\n",
      "117000 195699\n",
      "118000 195699\n",
      "119000 195699\n",
      "120000 195699\n",
      "121000 195699\n",
      "122000 195699\n",
      "123000 195699\n",
      "124000 195699\n",
      "125000 195699\n",
      "126000 195699\n",
      "127000 195699\n",
      "128000 195699\n",
      "129000 195699\n",
      "130000 195699\n",
      "131000 195699\n",
      "132000 195699\n",
      "133000 195699\n",
      "134000 195699\n",
      "135000 195699\n",
      "136000 195699\n",
      "137000 195699\n",
      "138000 195699\n",
      "139000 195699\n",
      "140000 195699\n",
      "141000 195699\n",
      "142000 195699\n",
      "143000 195699\n",
      "144000 195699\n",
      "145000 195699\n",
      "146000 195699\n",
      "147000 195699\n",
      "148000 195699\n",
      "149000 195699\n",
      "150000 195699\n",
      "151000 195699\n",
      "152000 195699\n",
      "153000 195699\n",
      "154000 195699\n",
      "155000 195699\n",
      "156000 195699\n",
      "157000 195699\n",
      "158000 195699\n",
      "159000 195699\n",
      "160000 195699\n",
      "161000 195699\n",
      "162000 195699\n",
      "163000 195699\n",
      "164000 195699\n",
      "165000 195699\n",
      "166000 195699\n",
      "167000 195699\n",
      "168000 195699\n",
      "169000 195699\n",
      "170000 195699\n",
      "171000 195699\n",
      "172000 195699\n",
      "173000 195699\n",
      "174000 195699\n",
      "175000 195699\n",
      "176000 195699\n",
      "177000 195699\n",
      "178000 195699\n",
      "179000 195699\n",
      "180000 195699\n",
      "181000 195699\n",
      "182000 195699\n",
      "183000 195699\n",
      "184000 195699\n",
      "185000 195699\n",
      "186000 195699\n",
      "187000 195699\n",
      "188000 195699\n",
      "189000 195699\n",
      "190000 195699\n",
      "191000 195699\n",
      "192000 195699\n",
      "193000 195699\n",
      "194000 195699\n",
      "195000 195699\n"
     ]
    }
   ],
   "source": [
    "emb1 = mult_strat_weighted(groups,False)\n",
    "save_new_embedding(emb1,New_emb_Name_path+\"_Strat1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9743c0ee",
   "metadata": {},
   "source": [
    "# Strategy 3 AddTagRep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bcacff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#requires tag rep\n",
    "def add_tag_rep_strat(word_groups,normalise_before_mult):\n",
    "    emb = {}\n",
    "    \n",
    "    if(normalise_before_mult):\n",
    "        matrix_copy = tf.nn.l2_normalize(matrix,axis = 1)\n",
    "    else:\n",
    "        matrix_copy = matrix\n",
    "        \n",
    "    for word_key in groups:\n",
    "        \n",
    "        base_count = 0 # total apearance of the baseword\n",
    "        for word in word_groups[word_key]:\n",
    "            if(word.startswith(chr(4))):#no rep for tags\n",
    "                continue\n",
    "            c = get_count(word)\n",
    "            base_count += c\n",
    "        \n",
    "        emb_sum = 0\n",
    "        for word in word_groups[word_key]:\n",
    "            if(word.startswith(chr(4))):#no rep for tags\n",
    "                continue\n",
    "            if chr(4) in word:\n",
    "                baseword ,tag  = word.split(chr(4))\n",
    "                id_word = id_dict[word]\n",
    "                #id_tag  = id_dict[chr(4)+tag]\n",
    "                #emb_sum += (get_count(word)/base_count)*(matrix_copy[id_word] * matrix_copy[id_tag])\n",
    "                emb_sum += (get_count(word)/base_count)*(matrix_copy[id_word] + matrix_copy[id_tag])\n",
    "            else:#only in mixed embedding add the base unscaled\n",
    "                emb_sum += matrix_copy[id_dict[word]] * (get_count(word)/base_count)\n",
    "        emb[baseword] = emb_sum\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d75f7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb3 = add_tag_rep_strat(groups,False)\n",
    "save_new_embedding(emb3,New_emb_Name_base+\"_Strat3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb0d28d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
